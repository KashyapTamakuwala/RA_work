{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# import openai\n",
    "import time\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import tiktoken\n",
    "# from openai.embeddings_utils import get_embedding\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "transformers.logging.set_verbosity_error()\n",
    "#from bertviz import model_view, head_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ba63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_sentence_data.csv')\n",
    "test_data = pd.read_csv('test_sentence_data.csv')\n",
    "val_data = pd.read_csv('val_sentence_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca71759",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = train_data.loc[train_data['Status'] == 0][0:10]\n",
    "t1 = train_data.loc[train_data['Status'] == 1][0:10]\n",
    "frames = [t0, t1]\n",
    "  \n",
    "train_data = pd.concat(frames)\n",
    "train_data=train_data.sample(frac = 1)\n",
    "\n",
    "\n",
    "t0 = test_data.loc[test_data['Status'] == 0][0:10]\n",
    "t1 = test_data.loc[test_data['Status'] == 1][0:10]\n",
    "frames = [t0, t1]\n",
    "  \n",
    "test_data = pd.concat(frames)\n",
    "test_data=test_data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad20c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55044</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>training neural networks to synthesize robust ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.pdf.json</td>\n",
       "      <td>\\nthus far, to evaluate the efficacy of neural...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>304.pdf.json</td>\n",
       "      <td>however, models that make use of this strateg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55051</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>this makes it difficult to reason about what ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55052</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>\\none common strategy to improve generalizatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            File_id                                           Sentence  Status\n",
       "55044  502.pdf.json  training neural networks to synthesize robust ...       0\n",
       "3      304.pdf.json  \\nthus far, to evaluate the efficacy of neural...       1\n",
       "9      304.pdf.json   however, models that make use of this strateg...       1\n",
       "55051  502.pdf.json   this makes it difficult to reason about what ...       0\n",
       "55052  502.pdf.json  \\none common strategy to improve generalizatio...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93cb1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/bert-base-nli-mean-tokens\"\n",
    "model = AutoModel.from_pretrained(model_name, output_attentions=True)  # Configure model to return attention values\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def bert(text):\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = tokenizer.encode(text, return_tensors='pt')  # Tokenize input text\n",
    "\n",
    "        outputs = model(inputs)  # Run model\n",
    "        attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs[0]) \n",
    "        sentence_embeddings = mean_pooling(outputs, encoded_input['attention_mask'])\n",
    "        return sentence_embeddings.detach().numpy()[0].tolist(),attention,tokens\n",
    "    except:\n",
    "        t=torch.full((1, 768), -1).numpy()[0].tolist()\n",
    "        return t,-1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a786ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['embeddings'], train_data['attention'], train_data['tokens'] = zip(*[bert(x) for x in train_data['Sentence']])\n",
    "\n",
    "test_data['embeddings'], test_data['attention'], test_data['tokens'] = zip(*[bert(x) for x in test_data['Sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e828ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Status</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>attention</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55044</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>training neural networks to synthesize robust ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3189399540424347, -0.2120111733675003, 0.58...</td>\n",
       "      <td>([[tensor([[0.0434, 0.0313, 0.0194, 0.0346, 0....</td>\n",
       "      <td>[[CLS], training, neural, networks, to, synth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.pdf.json</td>\n",
       "      <td>\\nthus far, to evaluate the efficacy of neural...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.22580105066299438, 0.8819662928581238, 0.6...</td>\n",
       "      <td>([[tensor([[0.0161, 0.0119, 0.0109,  ..., 0.01...</td>\n",
       "      <td>[[CLS], thus, far, ,, to, evaluate, the, effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>304.pdf.json</td>\n",
       "      <td>however, models that make use of this strateg...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1685861498117447, -0.3472355902194977, 1.61...</td>\n",
       "      <td>([[tensor([[0.0432, 0.0586, 0.0389, 0.0146, 0....</td>\n",
       "      <td>[[CLS], however, ,, models, that, make, use, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55051</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>this makes it difficult to reason about what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.20485571026802063, 0.1942422091960907, 1.02...</td>\n",
       "      <td>([[tensor([[0.0506, 0.0582, 0.0199, 0.0552, 0....</td>\n",
       "      <td>[[CLS], this, makes, it, difficult, to, reason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55052</th>\n",
       "      <td>502.pdf.json</td>\n",
       "      <td>\\none common strategy to improve generalizatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.4726422429084778, -0.29828211665153503, 1....</td>\n",
       "      <td>([[tensor([[0.0340, 0.0601, 0.0187, 0.0254, 0....</td>\n",
       "      <td>[[CLS], one, common, strategy, to, improve, ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            File_id                                           Sentence  \\\n",
       "55044  502.pdf.json  training neural networks to synthesize robust ...   \n",
       "3      304.pdf.json  \\nthus far, to evaluate the efficacy of neural...   \n",
       "9      304.pdf.json   however, models that make use of this strateg...   \n",
       "55051  502.pdf.json   this makes it difficult to reason about what ...   \n",
       "55052  502.pdf.json  \\none common strategy to improve generalizatio...   \n",
       "\n",
       "       Status                                         embeddings  \\\n",
       "55044       0  [0.3189399540424347, -0.2120111733675003, 0.58...   \n",
       "3           1  [-0.22580105066299438, 0.8819662928581238, 0.6...   \n",
       "9           1  [0.1685861498117447, -0.3472355902194977, 1.61...   \n",
       "55051       0  [0.20485571026802063, 0.1942422091960907, 1.02...   \n",
       "55052       0  [-0.4726422429084778, -0.29828211665153503, 1....   \n",
       "\n",
       "                                               attention  \\\n",
       "55044  ([[tensor([[0.0434, 0.0313, 0.0194, 0.0346, 0....   \n",
       "3      ([[tensor([[0.0161, 0.0119, 0.0109,  ..., 0.01...   \n",
       "9      ([[tensor([[0.0432, 0.0586, 0.0389, 0.0146, 0....   \n",
       "55051  ([[tensor([[0.0506, 0.0582, 0.0199, 0.0552, 0....   \n",
       "55052  ([[tensor([[0.0340, 0.0601, 0.0187, 0.0254, 0....   \n",
       "\n",
       "                                                  tokens  \n",
       "55044  [[CLS], training, neural, networks, to, synth,...  \n",
       "3      [[CLS], thus, far, ,, to, evaluate, the, effic...  \n",
       "9      [[CLS], however, ,, models, that, make, use, o...  \n",
       "55051  [[CLS], this, makes, it, difficult, to, reason...  \n",
       "55052  [[CLS], one, common, strategy, to, improve, ge...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ee198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_view(train_data['attention'][0], train_data['tokens'][0])  # Display model view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5fffa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head_view(train_data['attention'][0], train_data['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a27813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3189399540424347,\n",
       " -0.2120111733675003,\n",
       " 0.5892661213874817,\n",
       " 0.47461968660354614,\n",
       " -0.2805885672569275,\n",
       " -0.04401398450136185,\n",
       " 0.4509320557117462,\n",
       " -0.5321618318557739,\n",
       " 0.9889230132102966,\n",
       " -0.5384123921394348,\n",
       " 0.21799714863300323,\n",
       " 0.4650745391845703,\n",
       " 0.545346736907959,\n",
       " 0.274621844291687,\n",
       " -0.9002418518066406,\n",
       " 0.07171375304460526,\n",
       " 0.8405423760414124,\n",
       " -1.0200188159942627,\n",
       " 0.09160549938678741,\n",
       " -0.48537304997444153,\n",
       " -0.21207354962825775,\n",
       " 0.08328301459550858,\n",
       " 0.046449191868305206,\n",
       " -0.043165452778339386,\n",
       " 0.24641211330890656,\n",
       " -0.056924037635326385,\n",
       " -0.5269643664360046,\n",
       " -0.445924311876297,\n",
       " 0.20761819183826447,\n",
       " 0.31089669466018677,\n",
       " -0.304706335067749,\n",
       " 0.0420294813811779,\n",
       " -0.4118236005306244,\n",
       " -0.3456064760684967,\n",
       " -0.3048211932182312,\n",
       " 0.8224318623542786,\n",
       " 1.4471275806427002,\n",
       " 0.1354876607656479,\n",
       " 0.3440203368663788,\n",
       " 0.11017918586730957,\n",
       " 0.2280081957578659,\n",
       " -0.3091297149658203,\n",
       " 0.3675878942012787,\n",
       " 0.6526841521263123,\n",
       " -0.4775177538394928,\n",
       " -0.4601874053478241,\n",
       " -0.27216285467147827,\n",
       " 0.0899745523929596,\n",
       " 0.6264161467552185,\n",
       " -1.0678104162216187,\n",
       " -1.3195968866348267,\n",
       " 0.2576971650123596,\n",
       " 0.4579865634441376,\n",
       " 0.658195972442627,\n",
       " -0.581457793712616,\n",
       " 0.03123614564538002,\n",
       " 1.2345998287200928,\n",
       " -1.4537642002105713,\n",
       " 0.4149969220161438,\n",
       " -0.16672907769680023,\n",
       " -0.3489722013473511,\n",
       " 0.18790775537490845,\n",
       " 0.7574313879013062,\n",
       " 0.12511035799980164,\n",
       " -0.641041100025177,\n",
       " 0.19334042072296143,\n",
       " 0.3132869303226471,\n",
       " -0.4213426113128662,\n",
       " -0.9729703068733215,\n",
       " -0.7837669849395752,\n",
       " -0.02231702394783497,\n",
       " 0.03192268684506416,\n",
       " -0.3797109127044678,\n",
       " -0.012218385934829712,\n",
       " -0.7804392576217651,\n",
       " -0.25216996669769287,\n",
       " 0.629039466381073,\n",
       " 0.7625383734703064,\n",
       " 1.2668917179107666,\n",
       " 0.5815403461456299,\n",
       " -0.7285976409912109,\n",
       " 0.4219290316104889,\n",
       " -0.14043530821800232,\n",
       " -0.1852828860282898,\n",
       " 0.9370958209037781,\n",
       " 0.1797882318496704,\n",
       " 0.6085586547851562,\n",
       " 0.7905179262161255,\n",
       " -1.0594329833984375,\n",
       " 0.29954153299331665,\n",
       " 0.29202476143836975,\n",
       " 0.23402264714241028,\n",
       " 0.5587683320045471,\n",
       " -0.5433176159858704,\n",
       " -0.7633535265922546,\n",
       " 0.4320049285888672,\n",
       " -0.46011993288993835,\n",
       " 0.22775599360466003,\n",
       " 0.571195125579834,\n",
       " 1.0355405807495117,\n",
       " 0.1423696130514145,\n",
       " 0.13987499475479126,\n",
       " -0.10851114988327026,\n",
       " 0.004876189399510622,\n",
       " -0.06930746138095856,\n",
       " 0.2596895098686218,\n",
       " 0.13781984150409698,\n",
       " 0.22693073749542236,\n",
       " -1.1454203128814697,\n",
       " 0.3527391254901886,\n",
       " -0.07174650579690933,\n",
       " 0.5007936358451843,\n",
       " -0.04391365125775337,\n",
       " -0.3423704504966736,\n",
       " -0.442618727684021,\n",
       " 0.3280028700828552,\n",
       " -1.104631781578064,\n",
       " 0.27701663970947266,\n",
       " 0.17116571962833405,\n",
       " 0.1958557814359665,\n",
       " 0.6150981187820435,\n",
       " 0.9643912315368652,\n",
       " -0.4757698178291321,\n",
       " 0.12810957431793213,\n",
       " 0.14896027743816376,\n",
       " -0.16985902190208435,\n",
       " 0.672166645526886,\n",
       " 0.788425624370575,\n",
       " 0.3958883285522461,\n",
       " 0.16153638064861298,\n",
       " 0.0923033356666565,\n",
       " 0.5997964143753052,\n",
       " 0.5842874646186829,\n",
       " -0.8764147758483887,\n",
       " -0.5027300715446472,\n",
       " 0.05315864831209183,\n",
       " -0.08332314342260361,\n",
       " 0.694473147392273,\n",
       " -0.367107629776001,\n",
       " 0.4679970145225525,\n",
       " -0.4666214883327484,\n",
       " -0.14893949031829834,\n",
       " 1.182640790939331,\n",
       " -0.15796209871768951,\n",
       " 0.17346127331256866,\n",
       " -0.22202973067760468,\n",
       " 0.397737592458725,\n",
       " -0.4686071276664734,\n",
       " -0.5603639483451843,\n",
       " -0.22450517117977142,\n",
       " -0.9581780433654785,\n",
       " 0.9569461345672607,\n",
       " -0.777249276638031,\n",
       " 0.008005835115909576,\n",
       " -0.4231632351875305,\n",
       " 0.12634043395519257,\n",
       " -0.3485327363014221,\n",
       " 0.14196941256523132,\n",
       " -0.08933939039707184,\n",
       " 0.4802091717720032,\n",
       " -0.5070340037345886,\n",
       " 0.7461373209953308,\n",
       " -0.674737274646759,\n",
       " -0.34240373969078064,\n",
       " 0.21572911739349365,\n",
       " -0.3317040801048279,\n",
       " 1.0388243198394775,\n",
       " -0.6337620615959167,\n",
       " 0.6777253150939941,\n",
       " 1.0378206968307495,\n",
       " 0.9253057837486267,\n",
       " 0.24737964570522308,\n",
       " 0.18749170005321503,\n",
       " -0.25081029534339905,\n",
       " 0.32676395773887634,\n",
       " -0.4561719298362732,\n",
       " 0.30189719796180725,\n",
       " -1.2418015003204346,\n",
       " -0.04048473760485649,\n",
       " -0.847565770149231,\n",
       " -0.09667481482028961,\n",
       " 0.1775398999452591,\n",
       " 0.4750518202781677,\n",
       " 0.11588001251220703,\n",
       " -0.5920515656471252,\n",
       " -0.6622316837310791,\n",
       " 0.20574629306793213,\n",
       " -0.29144608974456787,\n",
       " -0.38816529512405396,\n",
       " -0.7826886177062988,\n",
       " 0.01578284427523613,\n",
       " -0.03654885292053223,\n",
       " 0.9263872504234314,\n",
       " -0.7788491249084473,\n",
       " 0.44515928626060486,\n",
       " 0.9536901116371155,\n",
       " -0.1997372955083847,\n",
       " 1.5108191967010498,\n",
       " -0.8235505223274231,\n",
       " 0.024952493607997894,\n",
       " 0.8587613701820374,\n",
       " -0.7791628837585449,\n",
       " -0.22963029146194458,\n",
       " -0.2364446371793747,\n",
       " -0.6917707324028015,\n",
       " 0.5224442481994629,\n",
       " 0.9003480076789856,\n",
       " -0.25866228342056274,\n",
       " -1.168060064315796,\n",
       " -1.2315958738327026,\n",
       " -0.2856534719467163,\n",
       " 0.26834893226623535,\n",
       " -0.05997253581881523,\n",
       " 0.000984695740044117,\n",
       " 0.5877690315246582,\n",
       " -0.023844338953495026,\n",
       " -0.1630381941795349,\n",
       " 0.04914192482829094,\n",
       " 1.7833442687988281,\n",
       " 0.9224608540534973,\n",
       " 1.5279970169067383,\n",
       " -0.32555776834487915,\n",
       " 0.30875101685523987,\n",
       " 0.877565860748291,\n",
       " -0.3404892683029175,\n",
       " 1.1009619235992432,\n",
       " 0.5350480675697327,\n",
       " -0.11895095556974411,\n",
       " 0.056844279170036316,\n",
       " 0.6359974145889282,\n",
       " 0.08529231697320938,\n",
       " -0.3961338698863983,\n",
       " -0.6522517800331116,\n",
       " -0.34606197476387024,\n",
       " -0.6202027201652527,\n",
       " -0.4386708438396454,\n",
       " -0.647293746471405,\n",
       " -0.20471008121967316,\n",
       " 0.9791003465652466,\n",
       " -0.15587922930717468,\n",
       " -0.049202270805835724,\n",
       " 0.950053334236145,\n",
       " -0.4104369580745697,\n",
       " 0.9411776661872864,\n",
       " -0.43958765268325806,\n",
       " -0.8208590149879456,\n",
       " 0.5684493184089661,\n",
       " -0.12631277740001678,\n",
       " -0.2644081711769104,\n",
       " -0.41583123803138733,\n",
       " -0.979884922504425,\n",
       " 0.28413844108581543,\n",
       " 0.5095652341842651,\n",
       " -0.35223355889320374,\n",
       " -0.020866552367806435,\n",
       " 0.0836169570684433,\n",
       " -0.29850471019744873,\n",
       " -0.49829569458961487,\n",
       " -0.33229535818099976,\n",
       " -0.18682901561260223,\n",
       " 0.2668617069721222,\n",
       " 0.5538247227668762,\n",
       " -0.8807048797607422,\n",
       " -0.17815439403057098,\n",
       " -0.24242427945137024,\n",
       " -0.22000953555107117,\n",
       " 0.0963638424873352,\n",
       " -0.7447674870491028,\n",
       " -0.4415383040904999,\n",
       " 0.24983055889606476,\n",
       " 0.46193069219589233,\n",
       " -0.8606978058815002,\n",
       " -0.18840134143829346,\n",
       " 0.21243922412395477,\n",
       " -0.4046194553375244,\n",
       " -0.35046297311782837,\n",
       " 0.6513296961784363,\n",
       " -0.28874218463897705,\n",
       " -0.13939349353313446,\n",
       " 0.37133312225341797,\n",
       " -0.6041088104248047,\n",
       " 0.7276725769042969,\n",
       " -1.1800061464309692,\n",
       " -0.15341731905937195,\n",
       " -0.5764927864074707,\n",
       " 0.27120885252952576,\n",
       " 0.1544630527496338,\n",
       " -0.2421264946460724,\n",
       " -0.02027575671672821,\n",
       " -0.45219576358795166,\n",
       " -0.20227500796318054,\n",
       " 1.0304536819458008,\n",
       " -0.9391169548034668,\n",
       " -0.7162334322929382,\n",
       " 0.7867901921272278,\n",
       " -0.007396856788545847,\n",
       " -0.040303319692611694,\n",
       " -0.4953734874725342,\n",
       " -0.11217282712459564,\n",
       " 0.13550519943237305,\n",
       " -0.9512295722961426,\n",
       " 0.41581326723098755,\n",
       " -0.9197094440460205,\n",
       " 0.18164213001728058,\n",
       " -0.5319122076034546,\n",
       " 0.3557819724082947,\n",
       " 0.4515479505062103,\n",
       " 0.27244821190834045,\n",
       " 0.20970378816127777,\n",
       " -0.1068793460726738,\n",
       " -0.19949831068515778,\n",
       " 0.27349352836608887,\n",
       " -0.7101492881774902,\n",
       " -0.2137138545513153,\n",
       " -0.388354629278183,\n",
       " -0.22528821229934692,\n",
       " 0.1702502816915512,\n",
       " -1.3277515172958374,\n",
       " 0.5030688643455505,\n",
       " -0.08933049440383911,\n",
       " -0.9163341522216797,\n",
       " 0.7308838963508606,\n",
       " 0.23723313212394714,\n",
       " 0.4498045742511749,\n",
       " 0.17079222202301025,\n",
       " 0.9020918011665344,\n",
       " 0.36774370074272156,\n",
       " -0.1798153668642044,\n",
       " -0.43630605936050415,\n",
       " 0.38447752594947815,\n",
       " 0.5045890808105469,\n",
       " -0.9720320105552673,\n",
       " -0.19651161134243011,\n",
       " 0.2894459664821625,\n",
       " -0.08297707885503769,\n",
       " 0.5911421775817871,\n",
       " -1.4291365146636963,\n",
       " -0.5807181000709534,\n",
       " -0.214350625872612,\n",
       " -0.7905987501144409,\n",
       " 0.18113365769386292,\n",
       " -0.49136579036712646,\n",
       " -0.7155468463897705,\n",
       " 0.6839979290962219,\n",
       " 0.8986948728561401,\n",
       " -0.2734872102737427,\n",
       " 0.21045830845832825,\n",
       " -0.7485950589179993,\n",
       " -0.5700197219848633,\n",
       " -0.04524342343211174,\n",
       " 0.6679873466491699,\n",
       " 0.0641411691904068,\n",
       " -0.12471578270196915,\n",
       " 0.17608487606048584,\n",
       " -0.7118109464645386,\n",
       " -0.34456688165664673,\n",
       " 0.24722349643707275,\n",
       " 0.787781298160553,\n",
       " -0.662251353263855,\n",
       " 0.06095975264906883,\n",
       " 0.2697906494140625,\n",
       " 0.7167235016822815,\n",
       " -0.3802121579647064,\n",
       " -0.9795747399330139,\n",
       " 0.8283516764640808,\n",
       " -0.336591899394989,\n",
       " 0.01137729175388813,\n",
       " 0.04394572600722313,\n",
       " 0.18296849727630615,\n",
       " 0.3860817849636078,\n",
       " -0.5314639210700989,\n",
       " -1.0708627700805664,\n",
       " -0.37163013219833374,\n",
       " -0.17865607142448425,\n",
       " -0.09090352058410645,\n",
       " -0.3416706621646881,\n",
       " -0.9965320825576782,\n",
       " 0.1697358340024948,\n",
       " 0.2034522294998169,\n",
       " -0.3615696430206299,\n",
       " 0.7362637519836426,\n",
       " -0.3071448802947998,\n",
       " 0.5856980085372925,\n",
       " -1.1284470558166504,\n",
       " 0.10767275840044022,\n",
       " -0.7819460034370422,\n",
       " 0.4608474373817444,\n",
       " 0.8794426918029785,\n",
       " -0.10029932111501694,\n",
       " 0.1408526599407196,\n",
       " 0.3279528021812439,\n",
       " -0.12075117975473404,\n",
       " 0.4710141122341156,\n",
       " -0.48090291023254395,\n",
       " -0.34497618675231934,\n",
       " -0.15034419298171997,\n",
       " -0.1414230465888977,\n",
       " 0.5356125831604004,\n",
       " -0.147953599691391,\n",
       " 0.31061872839927673,\n",
       " 0.256111741065979,\n",
       " 0.16507190465927124,\n",
       " 1.2456616163253784,\n",
       " 0.18689659237861633,\n",
       " 0.6424062848091125,\n",
       " 0.6374887824058533,\n",
       " -0.36176547408103943,\n",
       " 0.3716966509819031,\n",
       " -0.5732135772705078,\n",
       " -0.6253346800804138,\n",
       " -0.5832267999649048,\n",
       " 0.23776079714298248,\n",
       " 0.21976865828037262,\n",
       " 0.44649702310562134,\n",
       " -0.3141475021839142,\n",
       " -0.2054516077041626,\n",
       " 0.194604754447937,\n",
       " -1.244413137435913,\n",
       " -0.4390333592891693,\n",
       " 0.05258268862962723,\n",
       " -0.5999941825866699,\n",
       " 0.06443599611520767,\n",
       " -0.3434101641178131,\n",
       " 0.18307769298553467,\n",
       " -0.171138197183609,\n",
       " 1.0311906337738037,\n",
       " 0.2093116044998169,\n",
       " -0.8440844416618347,\n",
       " -0.701927661895752,\n",
       " 0.2145552635192871,\n",
       " 1.1099207401275635,\n",
       " -0.10797569900751114,\n",
       " -1.080298662185669,\n",
       " -0.03674252703785896,\n",
       " -0.032114170491695404,\n",
       " -0.4784563183784485,\n",
       " -0.22605162858963013,\n",
       " -0.8555252552032471,\n",
       " 1.016052484512329,\n",
       " 0.24155136942863464,\n",
       " 0.18690574169158936,\n",
       " -0.2952037453651428,\n",
       " -0.4545939266681671,\n",
       " -0.07505668699741364,\n",
       " 0.07185874134302139,\n",
       " 0.9729262590408325,\n",
       " 0.06307077407836914,\n",
       " 0.22822673618793488,\n",
       " 0.6972891688346863,\n",
       " -0.04792352020740509,\n",
       " 0.5809929966926575,\n",
       " -0.175499826669693,\n",
       " -0.5356870293617249,\n",
       " 0.512505292892456,\n",
       " 0.3667792081832886,\n",
       " 1.197015404701233,\n",
       " -0.5102673172950745,\n",
       " -0.431501567363739,\n",
       " -0.041323378682136536,\n",
       " -0.593450665473938,\n",
       " 0.037002477794885635,\n",
       " 0.3100695312023163,\n",
       " 0.06149691715836525,\n",
       " -0.06814676523208618,\n",
       " 1.1101964712142944,\n",
       " 0.09916246682405472,\n",
       " 0.06029201298952103,\n",
       " -0.28164154291152954,\n",
       " -0.28417909145355225,\n",
       " 0.05319366976618767,\n",
       " -0.006628269795328379,\n",
       " -0.18344086408615112,\n",
       " -0.3320082128047943,\n",
       " 0.5744044780731201,\n",
       " 0.5690749287605286,\n",
       " 0.04045693576335907,\n",
       " -1.3420628309249878,\n",
       " 0.6333674192428589,\n",
       " -0.0009994847932830453,\n",
       " -0.4089409112930298,\n",
       " 0.2533247768878937,\n",
       " -0.08963030576705933,\n",
       " 0.12898996472358704,\n",
       " -0.029776664450764656,\n",
       " -0.5944938659667969,\n",
       " 0.02117018960416317,\n",
       " -0.47173696756362915,\n",
       " 0.7910040020942688,\n",
       " 0.2009974867105484,\n",
       " -0.6814826130867004,\n",
       " 0.6270892024040222,\n",
       " -0.3846293091773987,\n",
       " -0.15912778675556183,\n",
       " -0.6211775541305542,\n",
       " -0.4958381652832031,\n",
       " -0.21834541857242584,\n",
       " -0.5311804413795471,\n",
       " 0.28012701869010925,\n",
       " 0.12930630147457123,\n",
       " 0.7228758931159973,\n",
       " 1.3647661209106445,\n",
       " 0.47041401267051697,\n",
       " 0.6841099858283997,\n",
       " 0.050105173140764236,\n",
       " 1.479294776916504,\n",
       " 0.16625487804412842,\n",
       " 0.26193687319755554,\n",
       " -1.0852824449539185,\n",
       " -0.10223151743412018,\n",
       " -0.1790933758020401,\n",
       " 0.13730472326278687,\n",
       " 0.14089567959308624,\n",
       " 0.3229072391986847,\n",
       " -0.24919584393501282,\n",
       " 0.04981113225221634,\n",
       " -0.4516046643257141,\n",
       " -0.2700121998786926,\n",
       " -0.36036428809165955,\n",
       " -0.49640774726867676,\n",
       " -0.5771880149841309,\n",
       " -0.41512879729270935,\n",
       " -0.43759864568710327,\n",
       " 0.0807327851653099,\n",
       " -0.13507024943828583,\n",
       " 0.2343994379043579,\n",
       " 0.3412818908691406,\n",
       " 0.5789270997047424,\n",
       " 0.6186124086380005,\n",
       " -0.3161643445491791,\n",
       " -0.3715324401855469,\n",
       " -0.3690738081932068,\n",
       " 0.559198260307312,\n",
       " -0.05769826099276543,\n",
       " 0.2237551510334015,\n",
       " -1.1473395824432373,\n",
       " -0.06114614009857178,\n",
       " -0.14355646073818207,\n",
       " -0.6610766649246216,\n",
       " 0.286803662776947,\n",
       " -1.2573113441467285,\n",
       " 0.059163231402635574,\n",
       " 0.3824150860309601,\n",
       " -0.31424611806869507,\n",
       " -0.48528018593788147,\n",
       " -0.5265408754348755,\n",
       " 0.19374831020832062,\n",
       " 0.7256450653076172,\n",
       " 0.25637611746788025,\n",
       " -0.1144239753484726,\n",
       " 0.724584698677063,\n",
       " -0.519792377948761,\n",
       " 0.834230899810791,\n",
       " 0.11138768494129181,\n",
       " -0.4845502972602844,\n",
       " -0.8440518379211426,\n",
       " -0.47927120327949524,\n",
       " -0.9663207530975342,\n",
       " -0.7077674269676208,\n",
       " -0.39476239681243896,\n",
       " -0.15015347301959991,\n",
       " 0.7339842915534973,\n",
       " 1.259050965309143,\n",
       " 0.03517214581370354,\n",
       " 0.8684879541397095,\n",
       " -0.2239082008600235,\n",
       " -1.626869797706604,\n",
       " 0.1954638659954071,\n",
       " -0.47309648990631104,\n",
       " -0.14666388928890228,\n",
       " -1.1937742233276367,\n",
       " 0.6852227449417114,\n",
       " -0.989477813243866,\n",
       " 0.6589699983596802,\n",
       " 0.2619715929031372,\n",
       " -0.22913138568401337,\n",
       " -0.8628250956535339,\n",
       " -0.02314719744026661,\n",
       " -0.5525700449943542,\n",
       " -1.1863863468170166,\n",
       " 0.05424421280622482,\n",
       " 0.4925558865070343,\n",
       " 0.7514826655387878,\n",
       " -0.7151600122451782,\n",
       " -0.1002546027302742,\n",
       " 0.6305997967720032,\n",
       " -0.41182607412338257,\n",
       " 0.023712385445833206,\n",
       " 0.21722333133220673,\n",
       " -0.007845370098948479,\n",
       " -0.09917499870061874,\n",
       " 0.3642338216304779,\n",
       " -0.484091579914093,\n",
       " -0.07856704294681549,\n",
       " 0.10296420007944107,\n",
       " 0.12744948267936707,\n",
       " -0.051561228930950165,\n",
       " 0.45288005471229553,\n",
       " -0.20487165451049805,\n",
       " 0.6520445942878723,\n",
       " -0.4153814911842346,\n",
       " -0.2634356915950775,\n",
       " -0.47532835602760315,\n",
       " -1.2340564727783203,\n",
       " -0.23959305882453918,\n",
       " -0.8281534910202026,\n",
       " -0.33253246545791626,\n",
       " -0.6183074712753296,\n",
       " 0.02179359272122383,\n",
       " -0.5131669044494629,\n",
       " 0.840206503868103,\n",
       " 0.6619738340377808,\n",
       " -1.4220043420791626,\n",
       " 0.5607022643089294,\n",
       " 0.4342235326766968,\n",
       " 0.02624884992837906,\n",
       " -0.9527572393417358,\n",
       " -0.5879629850387573,\n",
       " -0.5612305402755737,\n",
       " -0.03727657347917557,\n",
       " 0.5327164530754089,\n",
       " 0.8294118046760559,\n",
       " 0.061484456062316895,\n",
       " 0.32983821630477905,\n",
       " -0.13660980761051178,\n",
       " 0.16765543818473816,\n",
       " -1.1800249814987183,\n",
       " 0.5631272196769714,\n",
       " 0.35090747475624084,\n",
       " -0.094153493642807,\n",
       " 0.7600609660148621,\n",
       " 0.49384742975234985,\n",
       " 0.4592093527317047,\n",
       " 0.1565210372209549,\n",
       " 0.35375428199768066,\n",
       " 0.07448409497737885,\n",
       " -0.3097591996192932,\n",
       " -0.0906917005777359,\n",
       " 0.7445105910301208,\n",
       " 0.4890329837799072,\n",
       " -0.6763707399368286,\n",
       " -0.7866621613502502,\n",
       " -0.07478643953800201,\n",
       " 0.04014294221997261,\n",
       " 0.8752624988555908,\n",
       " 0.26122987270355225,\n",
       " -0.10338016599416733,\n",
       " -0.0677742138504982,\n",
       " 0.3024751842021942,\n",
       " 0.3908044695854187,\n",
       " 0.44124189019203186,\n",
       " -0.03451751917600632,\n",
       " 0.939572811126709,\n",
       " -0.182987242937088,\n",
       " -0.3467811942100525,\n",
       " 0.6198431849479675,\n",
       " -0.34483036398887634,\n",
       " -1.0315321683883667,\n",
       " 0.26271528005599976,\n",
       " 0.8189728856086731,\n",
       " 0.0323777012526989,\n",
       " 0.42030760645866394,\n",
       " 0.3967903256416321,\n",
       " 0.16054701805114746,\n",
       " -0.09570310264825821,\n",
       " 0.636830747127533,\n",
       " -0.11035998910665512,\n",
       " 0.11998311430215836,\n",
       " 0.0499705970287323,\n",
       " 1.2602930068969727,\n",
       " -0.1963960975408554,\n",
       " 0.3466263711452484,\n",
       " -0.33277440071105957,\n",
       " -1.1112096309661865,\n",
       " -0.2978655695915222,\n",
       " 0.8571319580078125,\n",
       " -0.4817976653575897,\n",
       " 1.0934216976165771,\n",
       " 0.0857914611697197,\n",
       " -0.9859558939933777,\n",
       " -0.27773115038871765,\n",
       " -0.05318485572934151,\n",
       " -0.2448091208934784,\n",
       " -0.26042723655700684,\n",
       " -0.5754688382148743,\n",
       " 0.017430249601602554,\n",
       " 0.05855660140514374,\n",
       " -1.255846381187439,\n",
       " -0.6428495645523071,\n",
       " 0.49065640568733215,\n",
       " 0.428577184677124,\n",
       " 0.1259811967611313,\n",
       " -0.5090103149414062,\n",
       " -0.9713522791862488,\n",
       " -0.589808464050293,\n",
       " -0.16386187076568604,\n",
       " -0.6920415163040161,\n",
       " -0.3446207642555237,\n",
       " 0.30037689208984375,\n",
       " -0.7157727479934692,\n",
       " -0.6899812817573547,\n",
       " 0.4959896206855774,\n",
       " 1.3493791818618774,\n",
       " -0.361710786819458,\n",
       " -0.33444005250930786,\n",
       " -0.5473898649215698,\n",
       " -0.02486930601298809,\n",
       " -0.2301354855298996,\n",
       " 0.48327621817588806,\n",
       " 0.509707510471344,\n",
       " -0.319550096988678,\n",
       " 0.15308624505996704,\n",
       " 1.3671703338623047,\n",
       " 0.297437846660614,\n",
       " 0.5641810297966003,\n",
       " -0.14516176283359528,\n",
       " 0.6846044063568115,\n",
       " -0.25187602639198303,\n",
       " -0.7253152132034302,\n",
       " -0.43231964111328125,\n",
       " 0.14688289165496826,\n",
       " 0.052286386489868164,\n",
       " -0.05288379639387131,\n",
       " -0.005610809661448002,\n",
       " -0.5711718201637268,\n",
       " 0.7131295800209045,\n",
       " 0.7153456807136536,\n",
       " 0.06376025825738907,\n",
       " -0.29133161902427673,\n",
       " 0.03639279678463936,\n",
       " -0.5886542201042175,\n",
       " 1.7897629737854004,\n",
       " -0.08941937237977982,\n",
       " -0.4868966042995453,\n",
       " 0.3950316905975342,\n",
       " 0.53440922498703,\n",
       " 0.00889359787106514,\n",
       " -0.8790048956871033,\n",
       " -0.8418764472007751,\n",
       " -0.19843396544456482,\n",
       " 0.29245176911354065,\n",
       " -0.21647365391254425,\n",
       " 1.1279882192611694,\n",
       " -0.18719203770160675,\n",
       " -0.09611101448535919,\n",
       " 0.2693411409854889,\n",
       " -0.7846118211746216,\n",
       " 0.3349786102771759,\n",
       " -0.036696821451187134,\n",
       " 0.24317212402820587,\n",
       " -0.1444840282201767,\n",
       " 0.7999016046524048,\n",
       " 0.7480331063270569,\n",
       " -0.04898510500788689,\n",
       " 0.04703257232904434,\n",
       " 0.3196304440498352,\n",
       " -0.13909687101840973,\n",
       " -0.660930871963501,\n",
       " -0.2906121611595154,\n",
       " -0.1967487782239914,\n",
       " 0.39152902364730835,\n",
       " -0.3855173587799072,\n",
       " -2.202908754348755,\n",
       " -1.1624975204467773,\n",
       " -0.023190027102828026,\n",
       " 0.07281207293272018,\n",
       " -0.7533610463142395,\n",
       " -1.8158562183380127,\n",
       " 0.37792545557022095]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e837518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf',probability=True)\n",
    "clf.fit(train_data['embeddings'].tolist(), train_data['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0690f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_test = test_data['Status'].tolist()\n",
    "y_pred = clf.predict(test_data['embeddings'].tolist())\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7826a1c",
   "metadata": {},
   "source": [
    "## AutomodelClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Prepare the data\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = MyCustomDataset('train.txt', tokenizer)\n",
    "val_dataset = MyCustomDataset('val.txt', tokenizer)\n",
    "\n",
    "# Define the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Train the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,                     # the instantiated Transformers model to be trained\n",
    "    args=training_args,              # training arguments, defined above\n",
    "    train_dataset=train_dataset,     # training dataset\n",
    "    eval_dataset=val_dataset,        # evaluation dataset\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "test_dataset = MyCustomDataset('test.txt', tokenizer)\n",
    "eval_results = trainer.evaluate(test_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a928b8",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4326a585",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'itemfreq' from 'scipy.stats' (/Users/admin/anaconda3/envs/Ra/lib/python3.8/site-packages/scipy/stats/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextExplainer\n",
      "File \u001b[0;32m~/anaconda3/envs/Ra/lib/python3.8/site-packages/eli5/lime/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     TextExplainer,\n\u001b[1;32m      4\u001b[0m     _train_local_classifier\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/Ra/lib/python3.8/site-packages/eli5/lime/lime.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sklearn_version\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msamplers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtextutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TOKEN_PATTERN, CHAR_TOKEN_PATTERN\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msamplers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskingTextSamplers\n",
      "File \u001b[0;32m~/anaconda3/envs/Ra/lib/python3.8/site-packages/eli5/lime/samplers.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m itemfreq\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, clone\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'itemfreq' from 'scipy.stats' (/Users/admin/anaconda3/envs/Ra/lib/python3.8/site-packages/scipy/stats/__init__.py)"
     ]
    }
   ],
   "source": [
    "from eli5.lime import TextExplainer\n",
    "\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a5da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
