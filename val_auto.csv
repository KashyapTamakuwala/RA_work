Sentence,Status
 u varies with the number of vertices in the graph,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
g,0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 ,0
"
the npi accesses an external environment, q, which varies according to the task",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 we found that changing the npi training traces is a simple way to enable this,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 the degree for any vertex in the dag is variable,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
we describe the details of the npi model relevant to our contributions",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
training setup",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 our experiments use a small number of training examples,1
", the verification set",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
we now report on generalization for the varying tasks,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
 reset represents a −∞ value,0
"
algorithm 2 shows the topological sort task of interest",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 these pointers are referred to as bubble pointers,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
3,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
base cases and reduction rules for bubble sort",0
" twc-1409915, darpa under grant no",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 18: push lo and p− 1 to slo and shi,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
bubble sort",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
3,1
g,0
" as with the others, we apply the procedure described in section 3",1
" as with the others, we apply the procedure described in section 3",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
 we choose to implement a topological sort task for graphs,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
g,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 the maximum problem length in this training set is 3 (e,1
"
arg 2 (increment or decrement): up, down
swap",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 ,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
move",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
5,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
bubble sort",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 ,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" , a1a0 + b1b0} are added properly",1
 ,0
 ,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
quicksort",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 ,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
", the trace corresponding to the array [3,2])",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
 u varies with the number of vertices in the graph,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 we outline how to construct this set,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
"
we describe the details of the npi model relevant to our contributions",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 the maximum problem length in this training set is 3 (e,1
"
move",1
 ,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
g,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"
we propose and describe our verification procedure",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
6,0
 we created a program set that reflects the semantics of algorithm 2,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
g,0
", an array for quicksort or a dag for topological sort)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" in future work, we seek to enable more tasks with recursive structure",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
 b1b0 where no carry operations occur,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
 almost all architectures train on program input/output pairs,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
", to change the value of phi) none described belowstack",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
", the verification set",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
to perform the verification as described here, it is critical to construct v correctly",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
g,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"
for addition, we analytically determine the verification set",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
we propose and describe our verification procedure",1
 18: push lo and p− 1 to slo and shi,1
" in this architecture, we consider a core controller, e",1
e,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
", to change the value of phi) none described belowstack",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" , n , where the dag contains n vertices",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 recursion can be implemented differently for different neural programming models,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 our experiments use a small number of training examples,1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 the maximum problem length in this training set is 3 (e,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 this algorithm is a variant of depth first search,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" however, our concept of recursion for neural programs is general",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" however, our concept of recursion for neural programs is general",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
g,0
"
bubble sort",0
" , a1a0 + b1b0} are added properly",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
we propose and describe our verification procedure",0
 this verification phase only needs to be performed once after training,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 ,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
"
as in line 13 of the right-hand side of figure 1",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
", the trace corresponding to the problem “109 + 101”)",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
g,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" each time a subprogram is called, the stack depth increases",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 npi then outputs the return probability and next program and arguments to execute,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
arg 2 (increment or decrement): up, down
swap",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
 the training set for addition contains 200 traces,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 this verification phase only needs to be performed once after training,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"
move",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 we found that changing the npi training traces is a simple way to enable this,0
 almost all architectures train on program input/output pairs,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
5,1
5,1
 the core controller acts as a dispatcher for the programs,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"
training setup",1
 ,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
base cases and reduction rules for addition",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
base cases and reduction rules for addition",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
3,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
topological sort",0
g,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
base cases and reduction rules for quicksort",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
5,0
" as aforementioned, the npi model naturally supports recursion",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" fa8750-15-2-0104, and berkeley deep drive",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" , n , where the dag contains n vertices",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
"
base cases and reduction rules for bubble sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 b1b0 where no carry operations occur,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" in future work, we seek to enable more tasks with recursive structure",0
as mentioned in section 2,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
grade-school addition",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
bubble sort",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
g,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
base cases and reduction rules for topological sort",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
move",1
g,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
base cases and reduction rules for quicksort",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
 ,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
g,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
move",0
"
grade school addition",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
arg 2 (increment or decrement): up, down
swap",0
" as aforementioned, the npi model naturally supports recursion",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
grade school addition",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
", the trace corresponding to the problem “109 + 101”)",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
6,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" fa8750-15-2-0104, and berkeley deep drive",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
quicksort",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 we created a program set that reflects the semantics of algorithm 2,0
 b1b0 where no carry operations occur,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 ,0
"
we experiment with two levels of recursion—partial and full",0
"
the three environment observations aid with control flow in algorithm 2",1
" on the other hand, the recursive programs have learned the true program semantics",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 recursion enables provably perfect generalization,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" et+1 ∼ fenv(et, pt, at)",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
 ,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" each time a subprogram is called, the stack depth increases",1
" twc-1409915, darpa under grant no",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
we propose and describe our verification procedure",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" in particular, recursion can be implemented as a program calling itself",1
g,0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 b1b0 where no carry operations occur,1
"1; and for bubble sort, appendix a",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 figure 2 shows examples of traces for the different versions of bubble sort,1
", an lstm in npi’s case, but possibly other networks in different cases",0
 we outline how to construct this set,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 ,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
 there is a (changing) list of neural programs used to accomplish a given task,1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 the degree for any vertex in the dag is variable,1
" in this architecture, we consider a core controller, e",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
", the verification set",0
 we outline how to construct this set,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
to perform the verification as described here, it is critical to construct v correctly",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
for addition, we analytically determine the verification set",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 our experiments use a small number of training examples,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
", to change the value of vactive) none described below move move a pointer (e",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 u varies with the number of vertices in the graph,1
" as aforementioned, the npi model naturally supports recursion",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
3,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
g,1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
we experiment with two levels of recursion—partial and full",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 ,1
 the degree for any vertex in the dag is variable,0
 recursion enables provably perfect generalization,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"1; and for bubble sort, appendix a",0
"
base cases and reduction rules for quicksort",0
we now report on generalization for the varying tasks,0
"
base cases and reduction rules for quicksort",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
grade-school addition",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
g,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
training setup",1
 the environment and return probability are omitted for readability,1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 our experiments use a small number of training examples,1
 we choose to implement a topological sort task for graphs,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
base cases and reduction rules for bubble sort",0
" , n , where the dag contains n vertices",0
"
base cases and reduction rules for addition",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
3,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" on the other hand, the recursive programs have learned the true program semantics",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" in particular, recursion can be implemented as a program calling itself",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 our experiments use a small number of training examples,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
"
the three environment observations aid with control flow in algorithm 2",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" in future work, we seek to enable more tasks with recursive structure",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
g,0
5,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 the core controller acts as a dispatcher for the programs,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
we describe the details of the npi model relevant to our contributions",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
grade-school addition",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
", qstacklo or qstackhi) or to pointer (e",1
 we outline how to construct this set,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" in future work, we seek to enable more tasks with recursive structure",1
" fa8750-15-2-0104, and berkeley deep drive",0
 these pointers are referred to as bubble pointers,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" fa8750-15-2-0104, and berkeley deep drive",0
g,1
g,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
quicksort",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
g,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 3: begin traversing from vertex 1 in the dag,1
 this verification phase only needs to be performed once after training,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" et+1 ∼ fenv(et, pt, at)",0
g,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
g,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
this material is in part based upon work supported by the national science foundation under grant no,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 ,1
", an array for quicksort or a dag for topological sort)",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" as with the others, we apply the procedure described in section 3",0
 we choose to implement a topological sort task for graphs,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" , n , where the dag contains n vertices",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
bubble sort",1
"
algorithm 2 shows the topological sort task of interest",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
we propose and describe our verification procedure",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
e,0
"
bubble sort",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
"1; and for bubble sort, appendix a",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
move",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
3 to construct v and then empirically create a verification set which covers v ,1
", the trace corresponding to the problem “109 + 101”)",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
training setup",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
 ,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
3,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
move",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
g,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 a1a0 + bnbn−1 ,0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
 ,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
 this algorithm is a variant of depth first search,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 the original version of the bubblesort implementation exposes the values within the array,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
3,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
we describe the details of the npi model relevant to our contributions",1
"
quicksort",1
"
arg 2 (increment or decrement): up, down
swap",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
 the degree for any vertex in the dag is variable,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 this algorithm is a variant of depth first search,1
"
in this general neural programming architecture, we show it is easy to support recursion",1
as mentioned in section 2,1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 the core controller acts as a dispatcher for the programs,1
"
move",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
g,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
bubble sort",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
g,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 the original version of the bubblesort implementation exposes the values within the array,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 the maximum problem length in this training set is 3 (e,1
 there is a (changing) list of neural programs used to accomplish a given task,0
"
base cases and reduction rules for quicksort",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
", the trace corresponding to the problem “109 + 101”)",1
g,0
"
inside bubble and reset, there are two operations that can be made recursive",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
for addition, we analytically determine the verification set",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
3,1
", to change the value of vactive) none described below move move a pointer (e",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
move",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" as aforementioned, the npi model naturally supports recursion",1
 our experiments use a small number of training examples,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
6,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
base cases and reduction rules for bubble sort",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
algorithm 2 shows the topological sort task of interest",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
g,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
this material is in part based upon work supported by the national science foundation under grant no,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 npi then outputs the return probability and next program and arguments to execute,1
 ,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 recursion can be implemented differently for different neural programming models,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
g,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
 there is a (changing) list of neural programs used to accomplish a given task,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" in future work, we seek to enable more tasks with recursive structure",1
" et+1 ∼ fenv(et, pt, at)",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
move",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
arg 2 (increment or decrement): up, down
swap",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
 recursion enables provably perfect generalization,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
we describe the details of the npi model relevant to our contributions",0
" in this architecture, we consider a core controller, e",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
", the verification set",0
" in all experiments, α is set to 0",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
3,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" , n , where the dag contains n vertices",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
g,1
", the trace corresponding to the problem “109 + 101”)",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
base cases and reduction rules for addition",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 ,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" , a1a0 + b1b0} are added properly",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
", to change the value of phi) none described belowstack",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
base cases and reduction rules for addition",0
 ,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 ,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
move",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" however, our concept of recursion for neural programs is general",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
g,0
"
grade school addition",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
g,1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 almost all architectures train on program input/output pairs,1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
algorithm 2 shows the topological sort task of interest",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 the first is the actual model architecture,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"1; and for bubble sort, appendix a",0
g,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 18: push lo and p− 1 to slo and shi,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
 the core controller acts as a dispatcher for the programs,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
bubble sort",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
 these pointers are referred to as bubble pointers,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
6,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 the degree for any vertex in the dag is variable,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
we propose and describe our verification procedure",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"
bubble sort",1
 the training set for addition contains 200 traces,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
bubble sort",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
quicksort",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" for each length, we test each program on 30 randomly generated problems",1
 3: begin traversing from vertex 1 in the dag,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" , a1a0 + b1b0} are added properly",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" for each length, we test each program on 30 randomly generated problems",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" as with the others, we apply the procedure described in section 3",0
 we choose to implement a topological sort task for graphs,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" lshift moves the four pointers to the left, to move to the next column",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 npi then outputs the return probability and next program and arguments to execute,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
base cases and reduction rules for topological sort",0
" on the other hand, the recursive programs have learned the true program semantics",0
3,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
bubble sort",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 the environment and return probability are omitted for readability,1
g,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
 ,0
 indentation indicates the stack is one level deeper than before,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
base cases and reduction rules for bubble sort",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" in all experiments, α is set to 0",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 3: begin traversing from vertex 1 in the dag,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 ,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
the three environment observations aid with control flow in algorithm 2",0
g,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
g,0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 recursion can be implemented differently for different neural programming models,1
" on the other hand, the recursive programs have learned the true program semantics",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" twc-1409915, darpa under grant no",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
 we choose to implement a topological sort task for graphs,1
 the program terminates when seeing no numbers in the current column,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" lshift moves the four pointers to the left, to move to the next column",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 npi then outputs the return probability and next program and arguments to execute,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" we call this set of inputs the verification set, sv ",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 recursion can be implemented differently for different neural programming models,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 ,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" on the other hand, the recursive programs have learned the true program semantics",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
as in line 13 of the right-hand side of figure 1",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
this material is in part based upon work supported by the national science foundation under grant no,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 ,1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 we adapt machinery from the original paper slightly to fit our needs,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
 u varies with the number of vertices in the graph,1
 the degree for any vertex in the dag is variable,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
as in line 13 of the right-hand side of figure 1",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
e,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 ,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" in particular, recursion can be implemented as a program calling itself",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
3,1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
base cases and reduction rules for addition",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
3,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
algorithm 2 shows the topological sort task of interest",0
" on the other hand, the recursive programs have learned the true program semantics",1
 b1b0 where no carry operations occur,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
grade school addition",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" however, our concept of recursion for neural programs is general",0
", qstacklo or qstackhi) or to pointer (e",1
" as aforementioned, the npi model naturally supports recursion",0
" that is to say, the network does not learn the true program semantics",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 recursion enables provably perfect generalization,1
" , n , where the dag contains n vertices",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 ,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" each time a subprogram is called, the stack depth increases",0
", to color a vertex) or variable (e",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
g,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 we choose to implement a topological sort task for graphs,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
 recursion can be implemented differently for different neural programming models,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
we propose and describe our verification procedure",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
 18: push lo and p− 1 to slo and shi,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 u varies with the number of vertices in the graph,1
"
topological sort",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
e,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 ,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 npi then outputs the return probability and next program and arguments to execute,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 3: begin traversing from vertex 1 in the dag,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 the degree for any vertex in the dag is variable,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 our experiments use a small number of training examples,1
g,0
 we adapt machinery from the original paper slightly to fit our needs,1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
g,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
g,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 npi then outputs the return probability and next program and arguments to execute,0
", to color a vertex) or variable (e",0
" , a1a0 + b1b0} are added properly",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" we call this set of inputs the verification set, sv ",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" et+1 ∼ fenv(et, pt, at)",1
" in all experiments, α is set to 0",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 the training set for addition contains 200 traces,0
"
grade-school addition",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 our experiments use a small number of training examples,1
e,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
e,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 u varies with the number of vertices in the graph,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 the environment and return probability are omitted for readability,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
we propose and describe our verification procedure",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 we created a program set that reflects the semantics of algorithm 2,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
3,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" , n , where the dag contains n vertices",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
inside bubble and reset, there are two operations that can be made recursive",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
g,1
 recursion enables provably perfect generalization,0
 reset represents a −∞ value,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" as aforementioned, the npi model naturally supports recursion",1
 there is a (changing) list of neural programs used to accomplish a given task,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 b1b0 where no carry operations occur,0
 the core controller acts as a dispatcher for the programs,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
as in line 13 of the right-hand side of figure 1",0
"
the npi accesses an external environment, q, which varies according to the task",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
training setup",0
3 to construct v and then empirically create a verification set which covers v ,0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
", to change the value of vactive) none described below move move a pointer (e",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 we outline how to construct this set,0
"
we describe the details of the npi model relevant to our contributions",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"
quicksort",1
" in all experiments, α is set to 0",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 the program terminates when seeing no numbers in the current column,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
we experiment with two levels of recursion—partial and full",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
base cases and reduction rules for bubble sort",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"1; and for bubble sort, appendix a",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
6,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
 we outline how to construct this set,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
 recursion enables provably perfect generalization,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 3: begin traversing from vertex 1 in the dag,0
", the trace corresponding to the problem “109 + 101”)",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
g,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" for each length, we test each program on 30 randomly generated problems",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" lshift moves the four pointers to the left, to move to the next column",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
g,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
3,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
we now report on generalization for the varying tasks,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" fa8750-15-2-0104, and berkeley deep drive",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 the original version of the bubblesort implementation exposes the values within the array,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" in future work, we seek to enable more tasks with recursive structure",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
g,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
grade-school addition",1
 we outline how to construct this set,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 the environment and return probability are omitted for readability,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
", to color a vertex) or variable (e",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
g,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
5,1
 ,1
"
quicksort",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" for each length, we test each program on 30 randomly generated problems",0
" for each length, we test each program on 30 randomly generated problems",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
", the trace corresponding to the problem “109 + 101”)",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 recursion enables provably perfect generalization,1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" however, our concept of recursion for neural programs is general",0
" , n , where the dag contains n vertices",0
 ,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" in all experiments, α is set to 0",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" as with the others, we apply the procedure described in section 3",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
6,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
", the trace corresponding to the array [3,2])",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
 ,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
e,1
6,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 this makes it difficult to reason about what the model will do when given complex inputs,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
quicksort",0
" for each length, we test each program on 30 randomly generated problems",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 we outline how to construct this set,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
", to change the value of vactive) none described below move move a pointer (e",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 this verification phase only needs to be performed once after training,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
"
as in line 13 of the right-hand side of figure 1",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
g,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
", to change the value of vactive) none described below move move a pointer (e",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
 3: begin traversing from vertex 1 in the dag,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 this verification phase only needs to be performed once after training,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 the degree for any vertex in the dag is variable,0
 the training set for addition contains 200 traces,1
3,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
6,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" as aforementioned, the npi model naturally supports recursion",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 ,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
training setup",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
as in line 13 of the right-hand side of figure 1",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
 18: push lo and p− 1 to slo and shi,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 the original version of the bubblesort implementation exposes the values within the array,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" on the other hand, the recursive programs have learned the true program semantics",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
as mentioned in section 2,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
we experiment with two levels of recursion—partial and full",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" as aforementioned, the npi model naturally supports recursion",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" as with the others, we apply the procedure described in section 3",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" however, our concept of recursion for neural programs is general",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
this material is in part based upon work supported by the national science foundation under grant no,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" in this architecture, we consider a core controller, e",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 ,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
", to change the value of phi) none described belowstack",0
", to change the value of phi) none described belowstack",1
we now report on generalization for the varying tasks,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 our experiments use a small number of training examples,1
 this algorithm is a variant of depth first search,0
g,1
"
we propose and describe our verification procedure",1
 indentation indicates the stack is one level deeper than before,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
3,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"
we propose and describe our verification procedure",1
g,0
g,0
", to color a vertex) or variable (e",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" , n , where the dag contains n vertices",1
 we outline how to construct this set,1
", an lstm in npi’s case, but possibly other networks in different cases",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 the training set for addition contains 200 traces,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
g,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" each time a subprogram is called, the stack depth increases",1
e,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
grade-school addition",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
", to change the value of phi) none described belowstack",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 the maximum problem length in this training set is 3 (e,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
g,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
 ,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
training setup",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
base cases and reduction rules for bubble sort",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
", to color a vertex) or variable (e",1
"
quicksort",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
move",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
"
the npi accesses an external environment, q, which varies according to the task",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" however, our concept of recursion for neural programs is general",0
 this algorithm is a variant of depth first search,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" we call this set of inputs the verification set, sv ",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 this verification phase only needs to be performed once after training,0
 we found that changing the npi training traces is a simple way to enable this,0
 the original version of the bubblesort implementation exposes the values within the array,0
 almost all architectures train on program input/output pairs,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
the npi accesses an external environment, q, which varies according to the task",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
this material is in part based upon work supported by the national science foundation under grant no,1
as mentioned in section 2,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 the original version of the bubblesort implementation exposes the values within the array,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 ,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
quicksort",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
", to color a vertex) or variable (e",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"1; and for bubble sort, appendix a",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
base cases and reduction rules for quicksort",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
algorithm 2 shows the topological sort task of interest",1
 the maximum problem length in this training set is 3 (e,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"1; and for bubble sort, appendix a",1
g,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 ,0
"
the npi accesses an external environment, q, which varies according to the task",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
grade-school addition",1
" twc-1409915, darpa under grant no",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" twc-1409915, darpa under grant no",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
6,0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
5,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 we created a program set that reflects the semantics of algorithm 2,0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 the degree for any vertex in the dag is variable,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
g,1
" in future work, we seek to enable more tasks with recursive structure",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 we choose to implement a topological sort task for graphs,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
e,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" et+1 ∼ fenv(et, pt, at)",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
bubble sort",0
"
we propose and describe our verification procedure",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 ,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
", the trace corresponding to the problem “109 + 101”)",0
e,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 almost all architectures train on program input/output pairs,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
base cases and reduction rules for quicksort",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
topological sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
3,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
g,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" each time a subprogram is called, the stack depth increases",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 we outline how to construct this set,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
quicksort",0
 3: begin traversing from vertex 1 in the dag,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 the program terminates when seeing no numbers in the current column,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 this verification phase only needs to be performed once after training,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
we propose and describe our verification procedure",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" we call this set of inputs the verification set, sv ",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" that is to say, the network does not learn the true program semantics",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
g,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
 the core controller acts as a dispatcher for the programs,1
g,1
"
for addition, we analytically determine the verification set",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
the npi accesses an external environment, q, which varies according to the task",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" in all experiments, α is set to 0",0
", to change the value of phi) none described belowstack",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 indentation indicates the stack is one level deeper than before,0
", the verification set",0
 we adapt machinery from the original paper slightly to fit our needs,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
 3: begin traversing from vertex 1 in the dag,0
" twc-1409915, darpa under grant no",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 ,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 ,1
 our experiments use a small number of training examples,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 ,0
" , a1a0 + b1b0} are added properly",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
3,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
g,0
 we outline how to construct this set,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
quicksort",1
", to change the value of vactive) none described below move move a pointer (e",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 the degree for any vertex in the dag is variable,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
", to change the value of vactive) none described below move move a pointer (e",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
we experiment with two levels of recursion—partial and full",1
 the degree for any vertex in the dag is variable,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" in this architecture, we consider a core controller, e",0
 we choose to implement a topological sort task for graphs,1
", the verification set",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 ,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 ,1
", an array for quicksort or a dag for topological sort)",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 this verification phase only needs to be performed once after training,1
" as aforementioned, the npi model naturally supports recursion",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 3: begin traversing from vertex 1 in the dag,0
" in future work, we seek to enable more tasks with recursive structure",1
 ,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
the three environment observations aid with control flow in algorithm 2",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
2,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
the three environment observations aid with control flow in algorithm 2",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" in all experiments, α is set to 0",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" lshift moves the four pointers to the left, to move to the next column",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 recursion enables provably perfect generalization,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
", the trace corresponding to the problem “109 + 101”)",0
 we created a program set that reflects the semantics of algorithm 2,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 ,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 this verification phase only needs to be performed once after training,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
topological sort",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
we now report on generalization for the varying tasks,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
 our experiments use a small number of training examples,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" as with the others, we apply the procedure described in section 3",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
the three environment observations aid with control flow in algorithm 2",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
 we choose to implement a topological sort task for graphs,0
"
base cases and reduction rules for addition",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 the first is the actual model architecture,1
 the program terminates when seeing no numbers in the current column,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 the original version of the bubblesort implementation exposes the values within the array,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" we call this set of inputs the verification set, sv ",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
g,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" each time a subprogram is called, the stack depth increases",0
 npi then outputs the return probability and next program and arguments to execute,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
 we adapt machinery from the original paper slightly to fit our needs,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
5,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" in future work, we seek to enable more tasks with recursive structure",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 a1a0 + bnbn−1 ,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
3 to construct v and then empirically create a verification set which covers v ,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
g,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
3,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 we created a program set that reflects the semantics of algorithm 2,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
 the maximum problem length in this training set is 3 (e,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"
topological sort",0
 the degree for any vertex in the dag is variable,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 reset represents a −∞ value,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
grade-school addition",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
3,1
 recursion enables provably perfect generalization,1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 ,1
g,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" lshift moves the four pointers to the left, to move to the next column",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 almost all architectures train on program input/output pairs,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 recursion enables provably perfect generalization,0
e,0
"
we describe the details of the npi model relevant to our contributions",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 18: push lo and p− 1 to slo and shi,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
bubble sort",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" as with the others, we apply the procedure described in section 3",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
5,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 ,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" in particular, recursion can be implemented as a program calling itself",1
 this algorithm is a variant of depth first search,1
 recursion can be implemented differently for different neural programming models,1
 we outline how to construct this set,0
"
move",1
 ,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
g,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
3 to construct v and then empirically create a verification set which covers v ,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 ,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" in future work, we seek to enable more tasks with recursive structure",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
", the trace corresponding to the problem “109 + 101”)",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
", to color a vertex) or variable (e",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 the maximum problem length in this training set is 3 (e,0
"
topological sort",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
g,1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
", the trace corresponding to the problem “109 + 101”)",0
"
the three environment observations aid with control flow in algorithm 2",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 our experiments use a small number of training examples,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
", an array for quicksort or a dag for topological sort)",1
"
base cases and reduction rules for quicksort",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
this material is in part based upon work supported by the national science foundation under grant no,1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
bubble sort",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 ,0
we now report on generalization for the varying tasks,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
base cases and reduction rules for addition",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
g,0
g,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
the npi accesses an external environment, q, which varies according to the task",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" in this architecture, we consider a core controller, e",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
grade school addition",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 recursion enables provably perfect generalization,0
"1; and for bubble sort, appendix a",1
"
base cases and reduction rules for addition",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" in particular, recursion can be implemented as a program calling itself",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
", the trace corresponding to the problem “109 + 101”)",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
 recursion enables provably perfect generalization,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 recursion can be implemented differently for different neural programming models,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"
as in line 13 of the right-hand side of figure 1",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 almost all architectures train on program input/output pairs,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
", qstacklo or qstackhi) or to pointer (e",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
g,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
training setup",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" that is to say, the network does not learn the true program semantics",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 our experiments use a small number of training examples,0
"
base cases and reduction rules for bubble sort",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
grade-school addition",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 u varies with the number of vertices in the graph,0
"
the three environment observations aid with control flow in algorithm 2",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
", qstacklo or qstackhi) or to pointer (e",1
g,1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
we experiment with two levels of recursion—partial and full",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 18: push lo and p− 1 to slo and shi,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
", the verification set",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
", to color a vertex) or variable (e",1
" in all experiments, α is set to 0",1
"
for addition, we analytically determine the verification set",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
the three environment observations aid with control flow in algorithm 2",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" in particular, recursion can be implemented as a program calling itself",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
 ,1
g,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
as mentioned in section 2,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" that is to say, the network does not learn the true program semantics",0
5,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
grade school addition",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 18: push lo and p− 1 to slo and shi,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
quicksort",1
"
arg 2 (increment or decrement): up, down
swap",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
g,0
" we call this set of inputs the verification set, sv ",0
" however, our concept of recursion for neural programs is general",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
3,0
 ,1
"
as in line 13 of the right-hand side of figure 1",0
 almost all architectures train on program input/output pairs,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
 almost all architectures train on program input/output pairs,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
we now report on generalization for the varying tasks,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" each time a subprogram is called, the stack depth increases",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 b1b0 where no carry operations occur,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
2,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
as mentioned in section 2,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" for each length, we test each program on 30 randomly generated problems",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
", the verification set",0
 we created a program set that reflects the semantics of algorithm 2,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 the core controller acts as a dispatcher for the programs,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
this material is in part based upon work supported by the national science foundation under grant no,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 the program terminates when seeing no numbers in the current column,0
", the verification set",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 we adapt machinery from the original paper slightly to fit our needs,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
training setup",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
base cases and reduction rules for topological sort",1
" et+1 ∼ fenv(et, pt, at)",0
" we call this set of inputs the verification set, sv ",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" however, our concept of recursion for neural programs is general",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
", the trace corresponding to the problem “109 + 101”)",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 we outline how to construct this set,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
3,0
we now report on generalization for the varying tasks,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 indentation indicates the stack is one level deeper than before,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
", to change the value of phi) none described belowstack",0
 the degree for any vertex in the dag is variable,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
6,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" in this architecture, we consider a core controller, e",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
g,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
quicksort",1
"1; and for bubble sort, appendix a",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
 the original version of the bubblesort implementation exposes the values within the array,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
we experiment with two levels of recursion—partial and full",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
 we choose to implement a topological sort task for graphs,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
we describe the details of the npi model relevant to our contributions",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
g,1
", an lstm in npi’s case, but possibly other networks in different cases",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" we call this set of inputs the verification set, sv ",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
 ,0
" in all experiments, α is set to 0",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
g,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
base cases and reduction rules for bubble sort",0
 reset represents a −∞ value,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
quicksort",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 ,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
 b1b0 where no carry operations occur,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 ,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 the maximum problem length in this training set is 3 (e,0
" each time a subprogram is called, the stack depth increases",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" et+1 ∼ fenv(et, pt, at)",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
2,0
"
topological sort",0
e,0
 3: begin traversing from vertex 1 in the dag,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
", to change the value of phi) none described belowstack",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
bubble sort",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 18: push lo and p− 1 to slo and shi,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
", qstacklo or qstackhi) or to pointer (e",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 the training set for addition contains 200 traces,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
the npi accesses an external environment, q, which varies according to the task",1
 we choose to implement a topological sort task for graphs,0
 ,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 these pointers are referred to as bubble pointers,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 the degree for any vertex in the dag is variable,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 we found that changing the npi training traces is a simple way to enable this,1
"
as in line 13 of the right-hand side of figure 1",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
as mentioned in section 2,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
 this algorithm is a variant of depth first search,0
 the program terminates when seeing no numbers in the current column,1
"
arg 2 (increment or decrement): up, down
swap",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 almost all architectures train on program input/output pairs,1
"
we propose and describe our verification procedure",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"
grade school addition",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
inside bubble and reset, there are two operations that can be made recursive",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
we now report on generalization for the varying tasks,0
 ,1
g,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" however, our concept of recursion for neural programs is general",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
 npi then outputs the return probability and next program and arguments to execute,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
topological sort",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
we now report on generalization for the varying tasks,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
g,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
base cases and reduction rules for quicksort",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" lshift moves the four pointers to the left, to move to the next column",1
"
the npi accesses an external environment, q, which varies according to the task",0
3,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 the first is the actual model architecture,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
to perform the verification as described here, it is critical to construct v correctly",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 this verification phase only needs to be performed once after training,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 these pointers are referred to as bubble pointers,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
", an array for quicksort or a dag for topological sort)",0
g,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
base cases and reduction rules for quicksort",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
grade-school addition",1
"
base cases and reduction rules for bubble sort",0
 reset represents a −∞ value,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"
base cases and reduction rules for bubble sort",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
g,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
algorithm 2 shows the topological sort task of interest",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
 reset represents a −∞ value,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" , n , where the dag contains n vertices",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
g,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 3: begin traversing from vertex 1 in the dag,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"
base cases and reduction rules for topological sort",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 3: begin traversing from vertex 1 in the dag,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" , a1a0 + b1b0} are added properly",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 ,1
"
quicksort",0
as mentioned in section 2,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
5,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
g,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
to perform the verification as described here, it is critical to construct v correctly",1
3,0
 figure 2 shows examples of traces for the different versions of bubble sort,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
this material is in part based upon work supported by the national science foundation under grant no,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"1; and for bubble sort, appendix a",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" for each length, we test each program on 30 randomly generated problems",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 ,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
quicksort",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" for each length, we test each program on 30 randomly generated problems",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
training setup",0
"
base cases and reduction rules for addition",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
3 to construct v and then empirically create a verification set which covers v ,0
 there is a (changing) list of neural programs used to accomplish a given task,0
 this verification phase only needs to be performed once after training,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" each time a subprogram is called, the stack depth increases",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
we propose and describe our verification procedure",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 reset represents a −∞ value,1
g,0
 the maximum problem length in this training set is 3 (e,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 we adapt machinery from the original paper slightly to fit our needs,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 the environment and return probability are omitted for readability,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 recursion can be implemented differently for different neural programming models,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
g,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
e,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" in particular, recursion can be implemented as a program calling itself",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 almost all architectures train on program input/output pairs,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
base cases and reduction rules for quicksort",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
", an array for quicksort or a dag for topological sort)",0
"1; and for bubble sort, appendix a",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
the three environment observations aid with control flow in algorithm 2",0
 ,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" twc-1409915, darpa under grant no",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
 this verification phase only needs to be performed once after training,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 recursion can be implemented differently for different neural programming models,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
 this algorithm is a variant of depth first search,1
" as aforementioned, the npi model naturally supports recursion",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
 the training set for addition contains 200 traces,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
3 to construct v and then empirically create a verification set which covers v ,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" using this modification, we constructed a verification set consisting of one array of size 10",1
 3: begin traversing from vertex 1 in the dag,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" in future work, we seek to enable more tasks with recursive structure",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" on the other hand, the recursive programs have learned the true program semantics",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
2,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
", to color a vertex) or variable (e",0
"
we describe the details of the npi model relevant to our contributions",0
 indentation indicates the stack is one level deeper than before,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 the training set for addition contains 200 traces,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
we now report on generalization for the varying tasks,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 indentation indicates the stack is one level deeper than before,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 ,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
base cases and reduction rules for quicksort",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
quicksort",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
", an array for quicksort or a dag for topological sort)",0
"
algorithm 2 shows the topological sort task of interest",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" lshift moves the four pointers to the left, to move to the next column",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
 ,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
base cases and reduction rules for addition",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" twc-1409915, darpa under grant no",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 3: begin traversing from vertex 1 in the dag,1
 this algorithm is a variant of depth first search,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
base cases and reduction rules for quicksort",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" as aforementioned, the npi model naturally supports recursion",1
"
the npi accesses an external environment, q, which varies according to the task",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
g,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 ,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
base cases and reduction rules for topological sort",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
 ,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
the three environment observations aid with control flow in algorithm 2",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
g,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 this algorithm is a variant of depth first search,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 the degree for any vertex in the dag is variable,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 the training set for addition contains 200 traces,1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
3 to construct v and then empirically create a verification set which covers v ,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" in this architecture, we consider a core controller, e",1
" in this architecture, we consider a core controller, e",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
", the verification set",1
"
quicksort",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
2,0
g,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
", an array for quicksort or a dag for topological sort)",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
we experiment with two levels of recursion—partial and full",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 these pointers are referred to as bubble pointers,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 npi then outputs the return probability and next program and arguments to execute,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" twc-1409915, darpa under grant no",1
 our experiments use a small number of training examples,1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" et+1 ∼ fenv(et, pt, at)",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" twc-1409915, darpa under grant no",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 we found that changing the npi training traces is a simple way to enable this,0
 figure 2 shows examples of traces for the different versions of bubble sort,1
" for each length, we test each program on 30 randomly generated problems",0
g,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
"
quicksort",1
"
arg 2 (increment or decrement): up, down
swap",1
6,0
 ,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 indentation indicates the stack is one level deeper than before,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
we now report on generalization for the varying tasks,1
g,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
 we found that changing the npi training traces is a simple way to enable this,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 the original version of the bubblesort implementation exposes the values within the array,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
as in line 13 of the right-hand side of figure 1",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" that is to say, the network does not learn the true program semantics",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" on the other hand, the recursive programs have learned the true program semantics",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
base cases and reduction rules for topological sort",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" in particular, recursion can be implemented as a program calling itself",0
"
we describe the details of the npi model relevant to our contributions",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 the training set for addition contains 200 traces,0
"
to perform the verification as described here, it is critical to construct v correctly",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
bubble sort",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 ,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" however, our concept of recursion for neural programs is general",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
g,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 the maximum problem length in this training set is 3 (e,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
we describe the details of the npi model relevant to our contributions",1
 we choose to implement a topological sort task for graphs,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
2,1
 this verification phase only needs to be performed once after training,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
 u varies with the number of vertices in the graph,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
this material is in part based upon work supported by the national science foundation under grant no,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
g,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
g,1
" that is to say, the network does not learn the true program semantics",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 a1a0 + bnbn−1 ,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
6,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" we call this set of inputs the verification set, sv ",0
 ,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
move",0
 our experiments use a small number of training examples,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" for each length, we test each program on 30 randomly generated problems",0
 18: push lo and p− 1 to slo and shi,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
grade-school addition",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 the maximum problem length in this training set is 3 (e,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 we created a program set that reflects the semantics of algorithm 2,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
to perform the verification as described here, it is critical to construct v correctly",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
e,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 the first is the actual model architecture,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
bubble sort",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
g,0
 the core controller acts as a dispatcher for the programs,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
e,0
"
arg 2 (increment or decrement): up, down
swap",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 the first is the actual model architecture,1
" that is to say, the network does not learn the true program semantics",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 b1b0 where no carry operations occur,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
", to change the value of vactive) none described below move move a pointer (e",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
 a1a0 + bnbn−1 ,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
as in line 13 of the right-hand side of figure 1",1
"
quicksort",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
to perform the verification as described here, it is critical to construct v correctly",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" et+1 ∼ fenv(et, pt, at)",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
", to change the value of vactive) none described below move move a pointer (e",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
g,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
 we found that changing the npi training traces is a simple way to enable this,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" each time a subprogram is called, the stack depth increases",0
g,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
6,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
 ,1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 almost all architectures train on program input/output pairs,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
 this algorithm is a variant of depth first search,1
g,1
 ,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
g,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
algorithm 2 shows the topological sort task of interest",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" for each length, we test each program on 30 randomly generated problems",0
 we outline how to construct this set,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
we now report on generalization for the varying tasks,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"
base cases and reduction rules for quicksort",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"
we describe the details of the npi model relevant to our contributions",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
bubble sort",1
"
the three environment observations aid with control flow in algorithm 2",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" as with the others, we apply the procedure described in section 3",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 ,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
g,1
" fa8750-15-2-0104, and berkeley deep drive",1
"
we describe the details of the npi model relevant to our contributions",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
as mentioned in section 2,0
", qstacklo or qstackhi) or to pointer (e",1
 ,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
", to change the value of vactive) none described below move move a pointer (e",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 indentation indicates the stack is one level deeper than before,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
3,1
 we choose to implement a topological sort task for graphs,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
 we adapt machinery from the original paper slightly to fit our needs,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 recursion enables provably perfect generalization,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 ,1
 we outline how to construct this set,1
3,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
 u varies with the number of vertices in the graph,0
g,0
"
base cases and reduction rules for quicksort",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 ,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
move",0
 we outline how to construct this set,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
g,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
 the environment and return probability are omitted for readability,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 these pointers are referred to as bubble pointers,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
g,1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
"
grade-school addition",1
 ,0
" et+1 ∼ fenv(et, pt, at)",1
 npi then outputs the return probability and next program and arguments to execute,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" in future work, we seek to enable more tasks with recursive structure",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" et+1 ∼ fenv(et, pt, at)",0
" however, our concept of recursion for neural programs is general",0
"
we experiment with two levels of recursion—partial and full",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" we call this set of inputs the verification set, sv ",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" as with the others, we apply the procedure described in section 3",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" however, our concept of recursion for neural programs is general",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 we adapt machinery from the original paper slightly to fit our needs,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
to perform the verification as described here, it is critical to construct v correctly",1
3,1
3,0
", qstacklo or qstackhi) or to pointer (e",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 18: push lo and p− 1 to slo and shi,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
g,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
bubble sort",1
" , n , where the dag contains n vertices",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
e,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"
we propose and describe our verification procedure",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
e,1
 we outline how to construct this set,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 we created a program set that reflects the semantics of algorithm 2,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
", qstacklo or qstackhi) or to pointer (e",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
g,0
"
move",1
3,1
3,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 this algorithm is a variant of depth first search,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 we found that changing the npi training traces is a simple way to enable this,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
grade school addition",1
"
to perform the verification as described here, it is critical to construct v correctly",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
 a1a0 + bnbn−1 ,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
", qstacklo or qstackhi) or to pointer (e",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
 reset represents a −∞ value,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
move",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
grade-school addition",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 ,0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
 almost all architectures train on program input/output pairs,0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
base cases and reduction rules for quicksort",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
the three environment observations aid with control flow in algorithm 2",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
", the trace corresponding to the array [3,2])",0
g,0
"
base cases and reduction rules for topological sort",1
" lshift moves the four pointers to the left, to move to the next column",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
", the verification set",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" in this architecture, we consider a core controller, e",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 ,1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
we propose and describe our verification procedure",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 npi then outputs the return probability and next program and arguments to execute,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 we found that changing the npi training traces is a simple way to enable this,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 we outline how to construct this set,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"
as in line 13 of the right-hand side of figure 1",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
bubble sort",1
 ,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
g,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 our experiments use a small number of training examples,0
3,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
algorithm 2 shows the topological sort task of interest",0
", the verification set",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" on the other hand, the recursive programs have learned the true program semantics",0
"
base cases and reduction rules for topological sort",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
g,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" as with the others, we apply the procedure described in section 3",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" , a1a0 + b1b0} are added properly",1
 npi then outputs the return probability and next program and arguments to execute,1
3,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
training setup",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
for addition, we analytically determine the verification set",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
", to color a vertex) or variable (e",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 the program terminates when seeing no numbers in the current column,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" on the other hand, the recursive programs have learned the true program semantics",0
 the maximum problem length in this training set is 3 (e,0
"
quicksort",1
 ,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
", an array for quicksort or a dag for topological sort)",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" for each length, we test each program on 30 randomly generated problems",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
arg 2 (increment or decrement): up, down
swap",0
 ,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 the environment and return probability are omitted for readability,1
 ,0
 we created a program set that reflects the semantics of algorithm 2,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" on the other hand, the recursive programs have learned the true program semantics",1
e,0
"
inside bubble and reset, there are two operations that can be made recursive",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
g,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
", an array for quicksort or a dag for topological sort)",0
 ,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
this material is in part based upon work supported by the national science foundation under grant no,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" in all experiments, α is set to 0",1
"
bubble sort",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 the environment and return probability are omitted for readability,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
 the core controller acts as a dispatcher for the programs,0
 figure 2 shows examples of traces for the different versions of bubble sort,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
", qstacklo or qstackhi) or to pointer (e",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
base cases and reduction rules for quicksort",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
training setup",1
g,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" et+1 ∼ fenv(et, pt, at)",0
g,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
quicksort",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
move",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
base cases and reduction rules for quicksort",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
", to change the value of phi) none described belowstack",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
as in line 13 of the right-hand side of figure 1",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" in this architecture, we consider a core controller, e",1
" as with the others, we apply the procedure described in section 3",0
 we found that changing the npi training traces is a simple way to enable this,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
 the program terminates when seeing no numbers in the current column,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"1; and for bubble sort, appendix a",0
" fa8750-15-2-0104, and berkeley deep drive",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
grade-school addition",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 there is a (changing) list of neural programs used to accomplish a given task,1
 the program terminates when seeing no numbers in the current column,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
6,0
"
algorithm 2 shows the topological sort task of interest",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
move",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" , a1a0 + b1b0} are added properly",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 ,1
 recursion enables provably perfect generalization,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
6,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
to perform the verification as described here, it is critical to construct v correctly",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
as in line 13 of the right-hand side of figure 1",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" for each length, we test each program on 30 randomly generated problems",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 this algorithm is a variant of depth first search,1
e,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"
we experiment with two levels of recursion—partial and full",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
 our experiments use a small number of training examples,0
e,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
e,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" lshift moves the four pointers to the left, to move to the next column",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"
move",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
as mentioned in section 2,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
base cases and reduction rules for quicksort",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
", to color a vertex) or variable (e",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
 the core controller acts as a dispatcher for the programs,0
 the program terminates when seeing no numbers in the current column,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 we created a program set that reflects the semantics of algorithm 2,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
g,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 we created a program set that reflects the semantics of algorithm 2,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" in particular, recursion can be implemented as a program calling itself",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
base cases and reduction rules for topological sort",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
2,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
topological sort",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
for addition, we analytically determine the verification set",0
" that is to say, the network does not learn the true program semantics",1
"
training setup",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 the core controller acts as a dispatcher for the programs,1
 the program terminates when seeing no numbers in the current column,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we call this set of inputs the verification set, sv ",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
base cases and reduction rules for bubble sort",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" twc-1409915, darpa under grant no",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 ,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
we now report on generalization for the varying tasks,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
", to change the value of phi) none described belowstack",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 the original version of the bubblesort implementation exposes the values within the array,1
 npi then outputs the return probability and next program and arguments to execute,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" lshift moves the four pointers to the left, to move to the next column",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 the program terminates when seeing no numbers in the current column,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
", the verification set",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
g,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
", to color a vertex) or variable (e",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
g,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
for addition, we analytically determine the verification set",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
algorithm 2 shows the topological sort task of interest",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
grade school addition",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
this material is in part based upon work supported by the national science foundation under grant no,0
", to change the value of vactive) none described below move move a pointer (e",0
"
bubble sort",1
"1; and for bubble sort, appendix a",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
g,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 we choose to implement a topological sort task for graphs,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
g,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" for each length, we test each program on 30 randomly generated problems",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 recursion can be implemented differently for different neural programming models,0
 the first is the actual model architecture,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
e,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
algorithm 2 shows the topological sort task of interest",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
3,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 we outline how to construct this set,0
g,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
 the first is the actual model architecture,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
base cases and reduction rules for quicksort",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 this algorithm is a variant of depth first search,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" however, our concept of recursion for neural programs is general",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
", to color a vertex) or variable (e",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
g,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" lshift moves the four pointers to the left, to move to the next column",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
we describe the details of the npi model relevant to our contributions",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
", to change the value of vactive) none described below move move a pointer (e",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 indentation indicates the stack is one level deeper than before,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
we describe the details of the npi model relevant to our contributions",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 we created a program set that reflects the semantics of algorithm 2,1
"
we experiment with two levels of recursion—partial and full",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
 the training set for addition contains 200 traces,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 the degree for any vertex in the dag is variable,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 the maximum problem length in this training set is 3 (e,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
g,1
", an array for quicksort or a dag for topological sort)",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
quicksort",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
 ,0
 ,1
g,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
topological sort",1
 ,1
g,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 18: push lo and p− 1 to slo and shi,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 this algorithm is a variant of depth first search,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
g,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" in particular, recursion can be implemented as a program calling itself",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 b1b0 where no carry operations occur,1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 the degree for any vertex in the dag is variable,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
 we created a program set that reflects the semantics of algorithm 2,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
g,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" in future work, we seek to enable more tasks with recursive structure",1
 we adapt machinery from the original paper slightly to fit our needs,0
" we call this set of inputs the verification set, sv ",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
 ,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
topological sort",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
g,0
", qstacklo or qstackhi) or to pointer (e",0
" , a1a0 + b1b0} are added properly",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"
base cases and reduction rules for topological sort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
base cases and reduction rules for topological sort",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" as with the others, we apply the procedure described in section 3",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 u varies with the number of vertices in the graph,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
g,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" lshift moves the four pointers to the left, to move to the next column",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
as in line 13 of the right-hand side of figure 1",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" et+1 ∼ fenv(et, pt, at)",1
"
bubble sort",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
2,0
", an array for quicksort or a dag for topological sort)",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
g,0
5,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
base cases and reduction rules for bubble sort",1
e,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" in future work, we seek to enable more tasks with recursive structure",0
" , n , where the dag contains n vertices",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 these pointers are referred to as bubble pointers,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
 recursion enables provably perfect generalization,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
arg 2 (increment or decrement): up, down
swap",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
the npi accesses an external environment, q, which varies according to the task",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
5,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 ,0
3,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
base cases and reduction rules for addition",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
base cases and reduction rules for topological sort",0
 the program terminates when seeing no numbers in the current column,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 these pointers are referred to as bubble pointers,1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
 almost all architectures train on program input/output pairs,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" for each length, we test each program on 30 randomly generated problems",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 almost all architectures train on program input/output pairs,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
as in line 13 of the right-hand side of figure 1",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
 we created a program set that reflects the semantics of algorithm 2,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
 this verification phase only needs to be performed once after training,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 recursion can be implemented differently for different neural programming models,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
3,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
 recursion can be implemented differently for different neural programming models,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" in all experiments, α is set to 0",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
", to change the value of phi) none described belowstack",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 this verification phase only needs to be performed once after training,1
 ,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" in this architecture, we consider a core controller, e",1
", the trace corresponding to the array [3,2])",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
6,1
 this verification phase only needs to be performed once after training,1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
g,1
"
we describe the details of the npi model relevant to our contributions",1
2,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
g,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 almost all architectures train on program input/output pairs,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
6,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" lshift moves the four pointers to the left, to move to the next column",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
for addition, we analytically determine the verification set",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
as mentioned in section 2,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
 the core controller acts as a dispatcher for the programs,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
bubble sort",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" fa8750-15-2-0104, and berkeley deep drive",1
 ,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" as with the others, we apply the procedure described in section 3",0
" , a1a0 + b1b0} are added properly",1
"
the three environment observations aid with control flow in algorithm 2",1
 there is a (changing) list of neural programs used to accomplish a given task,1
g,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"
base cases and reduction rules for bubble sort",1
 the degree for any vertex in the dag is variable,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
6,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
 npi then outputs the return probability and next program and arguments to execute,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 ,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" we call this set of inputs the verification set, sv ",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" in particular, recursion can be implemented as a program calling itself",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
the npi accesses an external environment, q, which varies according to the task",0
 almost all architectures train on program input/output pairs,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 ,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
this material is in part based upon work supported by the national science foundation under grant no,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 we created a program set that reflects the semantics of algorithm 2,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
 npi then outputs the return probability and next program and arguments to execute,1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" in particular, recursion can be implemented as a program calling itself",1
", to change the value of phi) none described belowstack",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 ,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" for each length, we test each program on 30 randomly generated problems",0
"
move",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
g,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 recursion can be implemented differently for different neural programming models,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
as mentioned in section 2,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
grade school addition",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
", an array for quicksort or a dag for topological sort)",1
 recursion enables provably perfect generalization,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 ,1
 the degree for any vertex in the dag is variable,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" each time a subprogram is called, the stack depth increases",0
g,0
", qstacklo or qstackhi) or to pointer (e",1
"
base cases and reduction rules for addition",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
we now report on generalization for the varying tasks,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
3,1
" for each length, we test each program on 30 randomly generated problems",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" fa8750-15-2-0104, and berkeley deep drive",0
e,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
grade school addition",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
3,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
", to change the value of vactive) none described below move move a pointer (e",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" that is to say, the network does not learn the true program semantics",1
 ,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 we found that changing the npi training traces is a simple way to enable this,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" for each length, we test each program on 30 randomly generated problems",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
", to color a vertex) or variable (e",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
move",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
g,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" in this architecture, we consider a core controller, e",0
 18: push lo and p− 1 to slo and shi,0
e,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 we adapt machinery from the original paper slightly to fit our needs,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" we call this set of inputs the verification set, sv ",1
"
grade school addition",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 a1a0 + bnbn−1 ,0
g,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 recursion can be implemented differently for different neural programming models,0
", the verification set",1
 ,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
e,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
2,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" lshift moves the four pointers to the left, to move to the next column",0
"
base cases and reduction rules for quicksort",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 the core controller acts as a dispatcher for the programs,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
 we choose to implement a topological sort task for graphs,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 ,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" as with the others, we apply the procedure described in section 3",0
 we created a program set that reflects the semantics of algorithm 2,0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
"
bubble sort",0
" each time a subprogram is called, the stack depth increases",1
" in all experiments, α is set to 0",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 ,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
 the environment and return probability are omitted for readability,1
 our experiments use a small number of training examples,0
"
we experiment with two levels of recursion—partial and full",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 a1a0 + bnbn−1 ,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
quicksort",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" in particular, recursion can be implemented as a program calling itself",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 the environment and return probability are omitted for readability,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 u varies with the number of vertices in the graph,0
g,1
"
move",1
" as aforementioned, the npi model naturally supports recursion",1
5,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 u varies with the number of vertices in the graph,0
 a1a0 + bnbn−1 ,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
quicksort",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
6,1
5,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 the environment and return probability are omitted for readability,0
", to change the value of phi) none described belowstack",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
 the core controller acts as a dispatcher for the programs,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 ,1
 the degree for any vertex in the dag is variable,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
algorithm 2 shows the topological sort task of interest",0
"
we describe the details of the npi model relevant to our contributions",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 the program terminates when seeing no numbers in the current column,0
 we adapt machinery from the original paper slightly to fit our needs,0
"
for addition, we analytically determine the verification set",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 ,0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
g,0
" twc-1409915, darpa under grant no",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
grade school addition",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
g,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 reset represents a −∞ value,0
g,1
g,1
" in this architecture, we consider a core controller, e",0
"
quicksort",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
 recursion can be implemented differently for different neural programming models,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 this algorithm is a variant of depth first search,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"
arg 2 (increment or decrement): up, down
swap",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
as mentioned in section 2,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 the first is the actual model architecture,1
"
quicksort",1
"
we propose and describe our verification procedure",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"
algorithm 2 shows the topological sort task of interest",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
g,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" , a1a0 + b1b0} are added properly",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
as mentioned in section 2,0
" in all experiments, α is set to 0",0
 the program terminates when seeing no numbers in the current column,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for each length, we test each program on 30 randomly generated problems",1
g,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 the first is the actual model architecture,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
", an array for quicksort or a dag for topological sort)",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
g,0
 ,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" as aforementioned, the npi model naturally supports recursion",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" , n , where the dag contains n vertices",1
 this verification phase only needs to be performed once after training,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 the degree for any vertex in the dag is variable,1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
 the program terminates when seeing no numbers in the current column,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" as aforementioned, the npi model naturally supports recursion",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 reset represents a −∞ value,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
3 to construct v and then empirically create a verification set which covers v ,0
"
grade school addition",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
g,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 the first is the actual model architecture,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
", the trace corresponding to the problem “109 + 101”)",1
"
the npi accesses an external environment, q, which varies according to the task",0
g,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" as with the others, we apply the procedure described in section 3",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
 this verification phase only needs to be performed once after training,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 the program terminates when seeing no numbers in the current column,1
" each time a subprogram is called, the stack depth increases",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
g,0
 npi then outputs the return probability and next program and arguments to execute,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 reset represents a −∞ value,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" we call this set of inputs the verification set, sv ",0
 b1b0 where no carry operations occur,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
", the trace corresponding to the problem “109 + 101”)",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 this algorithm is a variant of depth first search,0
 b1b0 where no carry operations occur,1
 ,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 we created a program set that reflects the semantics of algorithm 2,1
g,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" on the other hand, the recursive programs have learned the true program semantics",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
5,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 ,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
we now report on generalization for the varying tasks,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
 b1b0 where no carry operations occur,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 these pointers are referred to as bubble pointers,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
g,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" , n , where the dag contains n vertices",1
" fa8750-15-2-0104, and berkeley deep drive",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" on the other hand, the recursive programs have learned the true program semantics",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
", the trace corresponding to the array [3,2])",0
 we found that changing the npi training traces is a simple way to enable this,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 recursion enables provably perfect generalization,1
 ,1
 u varies with the number of vertices in the graph,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 these pointers are referred to as bubble pointers,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 we found that changing the npi training traces is a simple way to enable this,1
3,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
g,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 almost all architectures train on program input/output pairs,0
 ,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
for addition, we analytically determine the verification set",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
 ,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 the program terminates when seeing no numbers in the current column,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 18: push lo and p− 1 to slo and shi,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
e,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
g,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
", the trace corresponding to the array [3,2])",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
", the trace corresponding to the array [3,2])",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
", to change the value of vactive) none described below move move a pointer (e",0
"
base cases and reduction rules for topological sort",0
this material is in part based upon work supported by the national science foundation under grant no,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
", to change the value of vactive) none described below move move a pointer (e",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
grade school addition",1
 the first is the actual model architecture,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
as mentioned in section 2,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
"
we experiment with two levels of recursion—partial and full",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
as mentioned in section 2,1
"
the npi accesses an external environment, q, which varies according to the task",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 reset represents a −∞ value,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
", the trace corresponding to the problem “109 + 101”)",1
g,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 ,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" et+1 ∼ fenv(et, pt, at)",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
quicksort",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" , a1a0 + b1b0} are added properly",1
"
arg 2 (increment or decrement): up, down
swap",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
g,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 this algorithm is a variant of depth first search,0
 ,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" each time a subprogram is called, the stack depth increases",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
 reset represents a −∞ value,0
 this verification phase only needs to be performed once after training,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 ,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
g,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 the maximum problem length in this training set is 3 (e,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" , n , where the dag contains n vertices",1
" , a1a0 + b1b0} are added properly",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 the training set for addition contains 200 traces,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" on the other hand, the recursive programs have learned the true program semantics",0
"
arg 2 (increment or decrement): up, down
swap",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
grade-school addition",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
move",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 we found that changing the npi training traces is a simple way to enable this,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 the program terminates when seeing no numbers in the current column,1
"
algorithm 2 shows the topological sort task of interest",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
as in line 13 of the right-hand side of figure 1",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
for addition, we analytically determine the verification set",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
 a1a0 + bnbn−1 ,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
g,1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 this algorithm is a variant of depth first search,0
"
base cases and reduction rules for addition",1
 reset represents a −∞ value,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" as with the others, we apply the procedure described in section 3",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" on the other hand, the recursive programs have learned the true program semantics",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
3,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
"
bubble sort",1
 the environment and return probability are omitted for readability,1
"1; and for bubble sort, appendix a",0
 we adapt machinery from the original paper slightly to fit our needs,1
"
bubble sort",0
" in this architecture, we consider a core controller, e",1
g,0
"
the three environment observations aid with control flow in algorithm 2",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
", the verification set",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
quicksort",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
algorithm 2 shows the topological sort task of interest",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 this algorithm is a variant of depth first search,1
e,1
 we created a program set that reflects the semantics of algorithm 2,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
", an lstm in npi’s case, but possibly other networks in different cases",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
", an array for quicksort or a dag for topological sort)",0
 reset represents a −∞ value,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" however, our concept of recursion for neural programs is general",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" as with the others, we apply the procedure described in section 3",0
2,0
"
base cases and reduction rules for addition",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
as in line 13 of the right-hand side of figure 1",1
 the maximum problem length in this training set is 3 (e,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"1; and for bubble sort, appendix a",1
"
bubble sort",1
"
we describe the details of the npi model relevant to our contributions",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
e,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
as mentioned in section 2,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 ,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 ,1
e,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 ,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
 this algorithm is a variant of depth first search,1
" , n , where the dag contains n vertices",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
 ,1
"
for addition, we analytically determine the verification set",0
 ,1
 the environment and return probability are omitted for readability,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 ,1
3 to construct v and then empirically create a verification set which covers v ,1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" that is to say, the network does not learn the true program semantics",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
the npi accesses an external environment, q, which varies according to the task",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" et+1 ∼ fenv(et, pt, at)",0
 ,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
3,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 reset represents a −∞ value,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
inside bubble and reset, there are two operations that can be made recursive",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
topological sort",0
 ,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
quicksort",0
 the maximum problem length in this training set is 3 (e,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
topological sort",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 u varies with the number of vertices in the graph,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 this verification phase only needs to be performed once after training,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
grade-school addition",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
the three environment observations aid with control flow in algorithm 2",1
"
we describe the details of the npi model relevant to our contributions",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
e,1
", the trace corresponding to the problem “109 + 101”)",1
" twc-1409915, darpa under grant no",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
 the first is the actual model architecture,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
g,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
3,0
"
base cases and reduction rules for addition",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 ,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 a1a0 + bnbn−1 ,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"1; and for bubble sort, appendix a",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 recursion can be implemented differently for different neural programming models,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 these pointers are referred to as bubble pointers,0
 npi then outputs the return probability and next program and arguments to execute,0
g,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"1; and for bubble sort, appendix a",1
"
we experiment with two levels of recursion—partial and full",0
 ,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" that is to say, the network does not learn the true program semantics",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
", the verification set",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
g,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
for addition, we analytically determine the verification set",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 ,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" in particular, recursion can be implemented as a program calling itself",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
3,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
g,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
base cases and reduction rules for addition",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
", the verification set",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 ,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 we found that changing the npi training traces is a simple way to enable this,1
 a1a0 + bnbn−1 ,1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
e,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 almost all architectures train on program input/output pairs,0
 ,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" in this architecture, we consider a core controller, e",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
3,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 the degree for any vertex in the dag is variable,1
we now report on generalization for the varying tasks,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 reset represents a −∞ value,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
g,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 the program terminates when seeing no numbers in the current column,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" that is to say, the network does not learn the true program semantics",0
 the first is the actual model architecture,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
 npi then outputs the return probability and next program and arguments to execute,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 these pointers are referred to as bubble pointers,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
g,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
to perform the verification as described here, it is critical to construct v correctly",0
3,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 we choose to implement a topological sort task for graphs,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"1; and for bubble sort, appendix a",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
 b1b0 where no carry operations occur,0
"
base cases and reduction rules for topological sort",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" for each length, we test each program on 30 randomly generated problems",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
algorithm 2 shows the topological sort task of interest",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" in future work, we seek to enable more tasks with recursive structure",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
g,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
g,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"1; and for bubble sort, appendix a",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 the core controller acts as a dispatcher for the programs,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
", to color a vertex) or variable (e",1
g,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 the first is the actual model architecture,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 ,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
e,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 our experiments use a small number of training examples,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
 the original version of the bubblesort implementation exposes the values within the array,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 our experiments use a small number of training examples,1
 ,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" , n , where the dag contains n vertices",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 indentation indicates the stack is one level deeper than before,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" in all experiments, α is set to 0",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
", an lstm in npi’s case, but possibly other networks in different cases",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
", to change the value of phi) none described belowstack",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
we describe the details of the npi model relevant to our contributions",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" each time a subprogram is called, the stack depth increases",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 the program terminates when seeing no numbers in the current column,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
we experiment with two levels of recursion—partial and full",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
quicksort",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
move",1
" we call this set of inputs the verification set, sv ",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
grade school addition",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" lshift moves the four pointers to the left, to move to the next column",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 indentation indicates the stack is one level deeper than before,1
", to change the value of vactive) none described below move move a pointer (e",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 ,0
g,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
grade-school addition",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" for each length, we test each program on 30 randomly generated problems",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
for addition, we analytically determine the verification set",0
" in particular, recursion can be implemented as a program calling itself",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" on the other hand, the recursive programs have learned the true program semantics",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" lshift moves the four pointers to the left, to move to the next column",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
base cases and reduction rules for topological sort",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" fa8750-15-2-0104, and berkeley deep drive",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" as with the others, we apply the procedure described in section 3",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
bubble sort",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
5,0
" , a1a0 + b1b0} are added properly",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
e,1
g,1
"
bubble sort",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
", the verification set",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" as aforementioned, the npi model naturally supports recursion",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
", the trace corresponding to the array [3,2])",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
g,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
 this verification phase only needs to be performed once after training,1
"
as in line 13 of the right-hand side of figure 1",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
3 to construct v and then empirically create a verification set which covers v ,0
"
we propose and describe our verification procedure",1
 ,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
 b1b0 where no carry operations occur,0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" for each length, we test each program on 30 randomly generated problems",0
 b1b0 where no carry operations occur,0
6,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
bubble sort",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
", to change the value of phi) none described belowstack",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
 ,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
g,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
", the verification set",1
 18: push lo and p− 1 to slo and shi,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
", the trace corresponding to the problem “109 + 101”)",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" that is to say, the network does not learn the true program semantics",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
we experiment with two levels of recursion—partial and full",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
3,1
 these pointers are referred to as bubble pointers,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
move",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
", qstacklo or qstackhi) or to pointer (e",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
move",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" in this architecture, we consider a core controller, e",1
"
move",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
quicksort",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
g,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
g,0
3,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" as aforementioned, the npi model naturally supports recursion",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" , a1a0 + b1b0} are added properly",0
" lshift moves the four pointers to the left, to move to the next column",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
3,0
 these pointers are referred to as bubble pointers,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
base cases and reduction rules for bubble sort",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" however, our concept of recursion for neural programs is general",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
for addition, we analytically determine the verification set",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" on the other hand, the recursive programs have learned the true program semantics",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
we describe the details of the npi model relevant to our contributions",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 recursion enables provably perfect generalization,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
inside bubble and reset, there are two operations that can be made recursive",1
g,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" fa8750-15-2-0104, and berkeley deep drive",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 we outline how to construct this set,1
 we outline how to construct this set,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
 recursion can be implemented differently for different neural programming models,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 the first is the actual model architecture,1
" et+1 ∼ fenv(et, pt, at)",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"
quicksort",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
e,1
 the first is the actual model architecture,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
g,1
", the verification set",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" twc-1409915, darpa under grant no",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" lshift moves the four pointers to the left, to move to the next column",0
3 to construct v and then empirically create a verification set which covers v ,0
" that is to say, the network does not learn the true program semantics",0
"
we describe the details of the npi model relevant to our contributions",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" as aforementioned, the npi model naturally supports recursion",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
bubble sort",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 ,0
 ,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
3,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" lshift moves the four pointers to the left, to move to the next column",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" lshift moves the four pointers to the left, to move to the next column",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" in future work, we seek to enable more tasks with recursive structure",1
" in future work, we seek to enable more tasks with recursive structure",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
base cases and reduction rules for addition",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 ,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" in future work, we seek to enable more tasks with recursive structure",1
"
quicksort",0
"
we propose and describe our verification procedure",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 npi then outputs the return probability and next program and arguments to execute,1
6,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" in all experiments, α is set to 0",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" however, our concept of recursion for neural programs is general",1
"
the npi accesses an external environment, q, which varies according to the task",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
 the environment and return probability are omitted for readability,1
 the training set for addition contains 200 traces,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
move",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
this material is in part based upon work supported by the national science foundation under grant no,1
 we created a program set that reflects the semantics of algorithm 2,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
", an array for quicksort or a dag for topological sort)",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"
bubble sort",0
 the first is the actual model architecture,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 ,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 we found that changing the npi training traces is a simple way to enable this,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" in this architecture, we consider a core controller, e",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" as with the others, we apply the procedure described in section 3",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
e,1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 we adapt machinery from the original paper slightly to fit our needs,0
 the original version of the bubblesort implementation exposes the values within the array,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
training setup",0
 the first is the actual model architecture,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"
the three environment observations aid with control flow in algorithm 2",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
algorithm 2 shows the topological sort task of interest",1
"
quicksort",0
"
move",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
g,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" for each length, we test each program on 30 randomly generated problems",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" et+1 ∼ fenv(et, pt, at)",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
we propose and describe our verification procedure",0
", to change the value of phi) none described belowstack",0
 b1b0 where no carry operations occur,0
"1; and for bubble sort, appendix a",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" in future work, we seek to enable more tasks with recursive structure",0
g,1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 reset represents a −∞ value,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
bubble sort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" , a1a0 + b1b0} are added properly",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
3,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
3,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
 the original version of the bubblesort implementation exposes the values within the array,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 ,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
3 to construct v and then empirically create a verification set which covers v ,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 a1a0 + bnbn−1 ,1
 ,1
"
quicksort",0
"
bubble sort",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" each time a subprogram is called, the stack depth increases",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
3 to construct v and then empirically create a verification set which covers v ,0
 the training set for addition contains 200 traces,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
 we found that changing the npi training traces is a simple way to enable this,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
", an lstm in npi’s case, but possibly other networks in different cases",1
 almost all architectures train on program input/output pairs,0
" et+1 ∼ fenv(et, pt, at)",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 18: push lo and p− 1 to slo and shi,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" we call this set of inputs the verification set, sv ",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" however, our concept of recursion for neural programs is general",0
 recursion enables provably perfect generalization,1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"1; and for bubble sort, appendix a",1
"
the three environment observations aid with control flow in algorithm 2",0
g,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
", the trace corresponding to the array [3,2])",0
", qstacklo or qstackhi) or to pointer (e",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"1; and for bubble sort, appendix a",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 ,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" as aforementioned, the npi model naturally supports recursion",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
training setup",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" as aforementioned, the npi model naturally supports recursion",1
 almost all architectures train on program input/output pairs,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" we call this set of inputs the verification set, sv ",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 the degree for any vertex in the dag is variable,0
" in future work, we seek to enable more tasks with recursive structure",0
" , n , where the dag contains n vertices",0
" for each length, we test each program on 30 randomly generated problems",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" et+1 ∼ fenv(et, pt, at)",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
topological sort",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
grade school addition",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 ,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"1; and for bubble sort, appendix a",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
arg 2 (increment or decrement): up, down
swap",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 18: push lo and p− 1 to slo and shi,0
" that is to say, the network does not learn the true program semantics",0
e,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 indentation indicates the stack is one level deeper than before,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 a1a0 + bnbn−1 ,1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 almost all architectures train on program input/output pairs,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
we propose and describe our verification procedure",1
 we adapt machinery from the original paper slightly to fit our needs,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" , a1a0 + b1b0} are added properly",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 3: begin traversing from vertex 1 in the dag,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
 we found that changing the npi training traces is a simple way to enable this,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
base cases and reduction rules for addition",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 ,1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
we experiment with two levels of recursion—partial and full",0
" for each length, we test each program on 30 randomly generated problems",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
 b1b0 where no carry operations occur,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
g,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
6,0
" fa8750-15-2-0104, and berkeley deep drive",0
"
for addition, we analytically determine the verification set",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" in future work, we seek to enable more tasks with recursive structure",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 we adapt machinery from the original paper slightly to fit our needs,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
", to change the value of phi) none described belowstack",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 the program terminates when seeing no numbers in the current column,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
 ,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
", an array for quicksort or a dag for topological sort)",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
grade school addition",1
" for each length, we test each program on 30 randomly generated problems",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
3,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
e,0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
5,1
 there is a (changing) list of neural programs used to accomplish a given task,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
arg 2 (increment or decrement): up, down
swap",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
quicksort",1
"
for addition, we analytically determine the verification set",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
", to change the value of phi) none described belowstack",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" fa8750-15-2-0104, and berkeley deep drive",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
as in line 13 of the right-hand side of figure 1",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
g,0
 ,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" et+1 ∼ fenv(et, pt, at)",0
"
base cases and reduction rules for bubble sort",0
"
the three environment observations aid with control flow in algorithm 2",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" that is to say, the network does not learn the true program semantics",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" for each length, we test each program on 30 randomly generated problems",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" fa8750-15-2-0104, and berkeley deep drive",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
move",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 this algorithm is a variant of depth first search,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 indentation indicates the stack is one level deeper than before,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 recursion enables provably perfect generalization,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" on the other hand, the recursive programs have learned the true program semantics",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
g,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 b1b0 where no carry operations occur,1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
 we adapt machinery from the original paper slightly to fit our needs,0
" in future work, we seek to enable more tasks with recursive structure",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 this verification phase only needs to be performed once after training,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
3 to construct v and then empirically create a verification set which covers v ,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 this verification phase only needs to be performed once after training,1
"
base cases and reduction rules for quicksort",0
 18: push lo and p− 1 to slo and shi,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
g,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" that is to say, the network does not learn the true program semantics",1
", the trace corresponding to the problem “109 + 101”)",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
2,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 the environment and return probability are omitted for readability,0
 we created a program set that reflects the semantics of algorithm 2,1
", the verification set",0
 the training set for addition contains 200 traces,0
this material is in part based upon work supported by the national science foundation under grant no,1
"
algorithm 2 shows the topological sort task of interest",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
5,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 ,1
e,1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
 we found that changing the npi training traces is a simple way to enable this,0
" twc-1409915, darpa under grant no",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 a1a0 + bnbn−1 ,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
algorithm 2 shows the topological sort task of interest",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 a1a0 + bnbn−1 ,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 ,0
", qstacklo or qstackhi) or to pointer (e",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 reset represents a −∞ value,1
as mentioned in section 2,0
"
we experiment with two levels of recursion—partial and full",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
bubble sort",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
grade-school addition",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 reset represents a −∞ value,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
arg 2 (increment or decrement): up, down
swap",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
g,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 a1a0 + bnbn−1 ,0
g,0
"
move",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
training setup",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
", qstacklo or qstackhi) or to pointer (e",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" we call this set of inputs the verification set, sv ",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" we call this set of inputs the verification set, sv ",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
g,1
5,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
base cases and reduction rules for addition",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
5,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 the maximum problem length in this training set is 3 (e,1
"
arg 2 (increment or decrement): up, down
swap",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 indentation indicates the stack is one level deeper than before,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 ,1
 indentation indicates the stack is one level deeper than before,1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
e,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
we experiment with two levels of recursion—partial and full",1
e,1
" in particular, recursion can be implemented as a program calling itself",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" et+1 ∼ fenv(et, pt, at)",0
g,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 recursion can be implemented differently for different neural programming models,1
"
we describe the details of the npi model relevant to our contributions",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
this material is in part based upon work supported by the national science foundation under grant no,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
", qstacklo or qstackhi) or to pointer (e",0
 u varies with the number of vertices in the graph,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 we adapt machinery from the original paper slightly to fit our needs,0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
quicksort",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
e,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 u varies with the number of vertices in the graph,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
g,0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
we propose and describe our verification procedure",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
for addition, we analytically determine the verification set",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" we call this set of inputs the verification set, sv ",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 the program terminates when seeing no numbers in the current column,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
g,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
", to color a vertex) or variable (e",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 we adapt machinery from the original paper slightly to fit our needs,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
 these pointers are referred to as bubble pointers,0
 ,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
g,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
g,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" as aforementioned, the npi model naturally supports recursion",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" in this architecture, we consider a core controller, e",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
g,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 the environment and return probability are omitted for readability,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
the npi accesses an external environment, q, which varies according to the task",1
 ,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" , a1a0 + b1b0} are added properly",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" , a1a0 + b1b0} are added properly",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
5,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
g,1
2,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 npi then outputs the return probability and next program and arguments to execute,1
"
the three environment observations aid with control flow in algorithm 2",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
6,0
e,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
 the maximum problem length in this training set is 3 (e,0
5,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 3: begin traversing from vertex 1 in the dag,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
base cases and reduction rules for addition",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
g,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 indentation indicates the stack is one level deeper than before,0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
", qstacklo or qstackhi) or to pointer (e",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
bubble sort",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
base cases and reduction rules for quicksort",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
g,1
 these pointers are referred to as bubble pointers,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" twc-1409915, darpa under grant no",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
3,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
move",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 the maximum problem length in this training set is 3 (e,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
g,0
 3: begin traversing from vertex 1 in the dag,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 there is a (changing) list of neural programs used to accomplish a given task,0
"
training setup",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
move",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" that is to say, the network does not learn the true program semantics",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 b1b0 where no carry operations occur,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
 ,0
" , a1a0 + b1b0} are added properly",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
 npi then outputs the return probability and next program and arguments to execute,1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
", the trace corresponding to the array [3,2])",0
 we adapt machinery from the original paper slightly to fit our needs,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 ,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
quicksort",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"
topological sort",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
move",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 ,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
5,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
", an lstm in npi’s case, but possibly other networks in different cases",1
 ,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
we propose and describe our verification procedure",1
"
arg 2 (increment or decrement): up, down
swap",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
algorithm 2 shows the topological sort task of interest",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" as aforementioned, the npi model naturally supports recursion",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" twc-1409915, darpa under grant no",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 we adapt machinery from the original paper slightly to fit our needs,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
 ,0
2,1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" as with the others, we apply the procedure described in section 3",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 a1a0 + bnbn−1 ,0
g,0
 18: push lo and p− 1 to slo and shi,0
 ,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
as mentioned in section 2,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
we describe the details of the npi model relevant to our contributions",1
"
base cases and reduction rules for topological sort",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
quicksort",0
 3: begin traversing from vertex 1 in the dag,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" as with the others, we apply the procedure described in section 3",1
 the original version of the bubblesort implementation exposes the values within the array,0
", the verification set",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" et+1 ∼ fenv(et, pt, at)",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" in this architecture, we consider a core controller, e",0
 the degree for any vertex in the dag is variable,1
" lshift moves the four pointers to the left, to move to the next column",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" fa8750-15-2-0104, and berkeley deep drive",1
" however, our concept of recursion for neural programs is general",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
 indentation indicates the stack is one level deeper than before,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" fa8750-15-2-0104, and berkeley deep drive",0
 u varies with the number of vertices in the graph,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
we now report on generalization for the varying tasks,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
bubble sort",1
g,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 the core controller acts as a dispatcher for the programs,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" as with the others, we apply the procedure described in section 3",0
 ,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" each time a subprogram is called, the stack depth increases",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
", to change the value of vactive) none described below move move a pointer (e",1
g,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 ,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
", to color a vertex) or variable (e",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 the maximum problem length in this training set is 3 (e,0
 we created a program set that reflects the semantics of algorithm 2,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
 recursion enables provably perfect generalization,1
2,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
 npi then outputs the return probability and next program and arguments to execute,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 these pointers are referred to as bubble pointers,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 we created a program set that reflects the semantics of algorithm 2,1
" in all experiments, α is set to 0",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
move",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
as in line 13 of the right-hand side of figure 1",1
this material is in part based upon work supported by the national science foundation under grant no,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 3: begin traversing from vertex 1 in the dag,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
as mentioned in section 2,1
"
for addition, we analytically determine the verification set",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 recursion can be implemented differently for different neural programming models,1
 these pointers are referred to as bubble pointers,0
 18: push lo and p− 1 to slo and shi,1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" in particular, recursion can be implemented as a program calling itself",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
as mentioned in section 2,1
"
algorithm 2 shows the topological sort task of interest",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
", to change the value of phi) none described belowstack",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
algorithm 2 shows the topological sort task of interest",1
 recursion can be implemented differently for different neural programming models,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
move",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
5,0
 a1a0 + bnbn−1 ,1
 18: push lo and p− 1 to slo and shi,0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 we found that changing the npi training traces is a simple way to enable this,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 3: begin traversing from vertex 1 in the dag,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
the npi accesses an external environment, q, which varies according to the task",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
as in line 13 of the right-hand side of figure 1",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
g,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"1; and for bubble sort, appendix a",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" lshift moves the four pointers to the left, to move to the next column",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
 this algorithm is a variant of depth first search,1
"
algorithm 2 shows the topological sort task of interest",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
 ,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
3,0
we now report on generalization for the varying tasks,1
 ,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
g,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
training setup",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
g,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
bubble sort",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
g,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
this material is in part based upon work supported by the national science foundation under grant no,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
 the original version of the bubblesort implementation exposes the values within the array,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 the maximum problem length in this training set is 3 (e,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" as with the others, we apply the procedure described in section 3",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 ,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
 this verification phase only needs to be performed once after training,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" that is to say, the network does not learn the true program semantics",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
 ,1
" et+1 ∼ fenv(et, pt, at)",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
", an array for quicksort or a dag for topological sort)",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 ,1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
 almost all architectures train on program input/output pairs,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
g,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
3,1
", qstacklo or qstackhi) or to pointer (e",0
 the environment and return probability are omitted for readability,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
"
the npi accesses an external environment, q, which varies according to the task",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
2,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
move",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 3: begin traversing from vertex 1 in the dag,1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
for addition, we analytically determine the verification set",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
e,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 ,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" in particular, recursion can be implemented as a program calling itself",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 recursion enables provably perfect generalization,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
we describe the details of the npi model relevant to our contributions",0
"
arg 2 (increment or decrement): up, down
swap",0
 the core controller acts as a dispatcher for the programs,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" , n , where the dag contains n vertices",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" that is to say, the network does not learn the true program semantics",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 ,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" on the other hand, the recursive programs have learned the true program semantics",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
2,0
 ,1
" in all experiments, α is set to 0",1
g,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
training setup",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 ,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" , a1a0 + b1b0} are added properly",1
 we choose to implement a topological sort task for graphs,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
 the degree for any vertex in the dag is variable,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
", an array for quicksort or a dag for topological sort)",1
" for each length, we test each program on 30 randomly generated problems",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
 this verification phase only needs to be performed once after training,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
g,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 ,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 we found that changing the npi training traces is a simple way to enable this,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
 we adapt machinery from the original paper slightly to fit our needs,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 the program terminates when seeing no numbers in the current column,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 the original version of the bubblesort implementation exposes the values within the array,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
 ,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
3,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 ,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
the npi accesses an external environment, q, which varies according to the task",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
e,1
"
quicksort",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 a1a0 + bnbn−1 ,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
g,0
", an lstm in npi’s case, but possibly other networks in different cases",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
move",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
move",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 the program terminates when seeing no numbers in the current column,1
" as with the others, we apply the procedure described in section 3",0
"
bubble sort",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
base cases and reduction rules for addition",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 these pointers are referred to as bubble pointers,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
3,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 we created a program set that reflects the semantics of algorithm 2,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
the npi accesses an external environment, q, which varies according to the task",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
e,0
g,0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
move",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 18: push lo and p− 1 to slo and shi,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
move",0
"
move",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 reset represents a −∞ value,1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
 the training set for addition contains 200 traces,0
 these pointers are referred to as bubble pointers,1
"
to perform the verification as described here, it is critical to construct v correctly",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
for addition, we analytically determine the verification set",1
g,0
"
arg 2 (increment or decrement): up, down
swap",0
 this verification phase only needs to be performed once after training,0
 this algorithm is a variant of depth first search,0
" each time a subprogram is called, the stack depth increases",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
we experiment with two levels of recursion—partial and full",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" , n , where the dag contains n vertices",0
g,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
", the verification set",0
"
bubble sort",1
g,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
 recursion enables provably perfect generalization,0
 almost all architectures train on program input/output pairs,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 ,0
 recursion enables provably perfect generalization,1
 ,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
3,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 indentation indicates the stack is one level deeper than before,0
"
bubble sort",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" et+1 ∼ fenv(et, pt, at)",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 we created a program set that reflects the semantics of algorithm 2,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 recursion enables provably perfect generalization,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
grade-school addition",0
 recursion can be implemented differently for different neural programming models,1
", an lstm in npi’s case, but possibly other networks in different cases",1
 ,1
"
base cases and reduction rules for topological sort",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 the maximum problem length in this training set is 3 (e,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"
training setup",0
2,0
 the training set for addition contains 200 traces,1
"
quicksort",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" , n , where the dag contains n vertices",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
move",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
topological sort",1
 a1a0 + bnbn−1 ,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
", the trace corresponding to the array [3,2])",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
grade school addition",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
move",1
g,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
g,0
 our experiments use a small number of training examples,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 the degree for any vertex in the dag is variable,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
 a1a0 + bnbn−1 ,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
base cases and reduction rules for addition",0
3,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
quicksort",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 ,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
g,0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 the original version of the bubblesort implementation exposes the values within the array,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 we found that changing the npi training traces is a simple way to enable this,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
we experiment with two levels of recursion—partial and full",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 u varies with the number of vertices in the graph,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 ,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" , a1a0 + b1b0} are added properly",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
", an array for quicksort or a dag for topological sort)",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
quicksort",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
", an array for quicksort or a dag for topological sort)",0
we now report on generalization for the varying tasks,1
 ,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
6,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
g,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 we created a program set that reflects the semantics of algorithm 2,0
 the maximum problem length in this training set is 3 (e,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
inside bubble and reset, there are two operations that can be made recursive",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" on the other hand, the recursive programs have learned the true program semantics",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
g,0
 we found that changing the npi training traces is a simple way to enable this,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
we now report on generalization for the varying tasks,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
bubble sort",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" for each length, we test each program on 30 randomly generated problems",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
g,1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 these pointers are referred to as bubble pointers,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
 ,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 b1b0 where no carry operations occur,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
 ,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
we propose and describe our verification procedure",0
"
the three environment observations aid with control flow in algorithm 2",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
 the first is the actual model architecture,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" for each length, we test each program on 30 randomly generated problems",0
"
quicksort",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
", an array for quicksort or a dag for topological sort)",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" for each length, we test each program on 30 randomly generated problems",1
 indentation indicates the stack is one level deeper than before,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" lshift moves the four pointers to the left, to move to the next column",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
 the training set for addition contains 200 traces,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
 the environment and return probability are omitted for readability,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
move",1
"
inside bubble and reset, there are two operations that can be made recursive",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 the first is the actual model architecture,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"
the three environment observations aid with control flow in algorithm 2",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
the three environment observations aid with control flow in algorithm 2",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
 the training set for addition contains 200 traces,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
to perform the verification as described here, it is critical to construct v correctly",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" in all experiments, α is set to 0",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
", an lstm in npi’s case, but possibly other networks in different cases",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
g,1
g,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 ,1
 the training set for addition contains 200 traces,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
3 to construct v and then empirically create a verification set which covers v ,1
 there is a (changing) list of neural programs used to accomplish a given task,1
"
quicksort",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 reset represents a −∞ value,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
for addition, we analytically determine the verification set",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" in particular, recursion can be implemented as a program calling itself",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 ,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
 these pointers are referred to as bubble pointers,1
 recursion enables provably perfect generalization,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
quicksort",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" in this architecture, we consider a core controller, e",1
" however, our concept of recursion for neural programs is general",1
" in this architecture, we consider a core controller, e",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
e,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
3 to construct v and then empirically create a verification set which covers v ,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
e,0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 ,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" in particular, recursion can be implemented as a program calling itself",1
" in future work, we seek to enable more tasks with recursive structure",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
3,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
training setup",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 ,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 u varies with the number of vertices in the graph,1
 ,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
base cases and reduction rules for bubble sort",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
base cases and reduction rules for bubble sort",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 3: begin traversing from vertex 1 in the dag,0
 we found that changing the npi training traces is a simple way to enable this,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" fa8750-15-2-0104, and berkeley deep drive",0
" as with the others, we apply the procedure described in section 3",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 the training set for addition contains 200 traces,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 recursion enables provably perfect generalization,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
the npi accesses an external environment, q, which varies according to the task",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
bubble sort",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 these pointers are referred to as bubble pointers,1
" et+1 ∼ fenv(et, pt, at)",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
we now report on generalization for the varying tasks,1
 u varies with the number of vertices in the graph,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
topological sort",0
" on the other hand, the recursive programs have learned the true program semantics",0
 ,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 ,0
"
bubble sort",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
3,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
we now report on generalization for the varying tasks,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
g,1
as mentioned in section 2,1
2,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
g,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
bubble sort",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
2,0
", the verification set",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
 these pointers are referred to as bubble pointers,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" in particular, recursion can be implemented as a program calling itself",1
as mentioned in section 2,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
3,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" each time a subprogram is called, the stack depth increases",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 recursion enables provably perfect generalization,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
inside bubble and reset, there are two operations that can be made recursive",0
", qstacklo or qstackhi) or to pointer (e",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
as in line 13 of the right-hand side of figure 1",1
"
the three environment observations aid with control flow in algorithm 2",1
 ,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 we adapt machinery from the original paper slightly to fit our needs,0
"
training setup",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" fa8750-15-2-0104, and berkeley deep drive",1
", the trace corresponding to the array [3,2])",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 the first is the actual model architecture,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" in particular, recursion can be implemented as a program calling itself",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
3,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
as mentioned in section 2,1
g,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
", to color a vertex) or variable (e",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" each time a subprogram is called, the stack depth increases",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
base cases and reduction rules for quicksort",0
g,1
" on the other hand, the recursive programs have learned the true program semantics",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" fa8750-15-2-0104, and berkeley deep drive",0
" in future work, we seek to enable more tasks with recursive structure",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" in this architecture, we consider a core controller, e",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
3 to construct v and then empirically create a verification set which covers v ,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 3: begin traversing from vertex 1 in the dag,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" , a1a0 + b1b0} are added properly",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
g,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 the core controller acts as a dispatcher for the programs,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" in particular, recursion can be implemented as a program calling itself",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
3,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
 ,0
"
we describe the details of the npi model relevant to our contributions",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" in all experiments, α is set to 0",0
"
training setup",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" we call this set of inputs the verification set, sv ",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 ,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 we adapt machinery from the original paper slightly to fit our needs,1
 we adapt machinery from the original paper slightly to fit our needs,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
3,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 these pointers are referred to as bubble pointers,1
g,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
", an lstm in npi’s case, but possibly other networks in different cases",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 the environment and return probability are omitted for readability,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
e,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" as with the others, we apply the procedure described in section 3",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
g,1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
algorithm 2 shows the topological sort task of interest",0
"
topological sort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
6,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 we choose to implement a topological sort task for graphs,0
 we created a program set that reflects the semantics of algorithm 2,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 indentation indicates the stack is one level deeper than before,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
", to color a vertex) or variable (e",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 b1b0 where no carry operations occur,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" that is to say, the network does not learn the true program semantics",1
", to change the value of vactive) none described below move move a pointer (e",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
 the degree for any vertex in the dag is variable,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
g,0
"
in this general neural programming architecture, we show it is easy to support recursion",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 ,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" , a1a0 + b1b0} are added properly",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
g,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
move",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 the core controller acts as a dispatcher for the programs,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
g,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
 npi then outputs the return probability and next program and arguments to execute,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
", the trace corresponding to the problem “109 + 101”)",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
e,0
 our experiments use a small number of training examples,1
3,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
g,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 the original version of the bubblesort implementation exposes the values within the array,1
" for each length, we test each program on 30 randomly generated problems",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
", to color a vertex) or variable (e",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
 we choose to implement a topological sort task for graphs,1
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
base cases and reduction rules for quicksort",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" lshift moves the four pointers to the left, to move to the next column",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" each time a subprogram is called, the stack depth increases",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
bubble sort",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
for addition, we analytically determine the verification set",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"
base cases and reduction rules for addition",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" in all experiments, α is set to 0",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" on the other hand, the recursive programs have learned the true program semantics",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 there is a (changing) list of neural programs used to accomplish a given task,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
g,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" we call this set of inputs the verification set, sv ",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
 the environment and return probability are omitted for readability,0
", to change the value of vactive) none described below move move a pointer (e",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 we outline how to construct this set,1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
 indentation indicates the stack is one level deeper than before,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" as aforementioned, the npi model naturally supports recursion",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"
quicksort",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
we now report on generalization for the varying tasks,0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
3,0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" that is to say, the network does not learn the true program semantics",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
g,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
base cases and reduction rules for addition",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
bubble sort",0
" , n , where the dag contains n vertices",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 we found that changing the npi training traces is a simple way to enable this,1
" fa8750-15-2-0104, and berkeley deep drive",1
 we found that changing the npi training traces is a simple way to enable this,1
"
bubble sort",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" in future work, we seek to enable more tasks with recursive structure",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
g,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
 we adapt machinery from the original paper slightly to fit our needs,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" as with the others, we apply the procedure described in section 3",0
"
for addition, we analytically determine the verification set",0
" for each length, we test each program on 30 randomly generated problems",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
 18: push lo and p− 1 to slo and shi,0
"
bubble sort",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 we found that changing the npi training traces is a simple way to enable this,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" in particular, recursion can be implemented as a program calling itself",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
g,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" on the other hand, the recursive programs have learned the true program semantics",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
", an array for quicksort or a dag for topological sort)",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
", the verification set",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 3: begin traversing from vertex 1 in the dag,1
3 to construct v and then empirically create a verification set which covers v ,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" twc-1409915, darpa under grant no",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
 recursion can be implemented differently for different neural programming models,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" , a1a0 + b1b0} are added properly",0
"
base cases and reduction rules for addition",1
", an array for quicksort or a dag for topological sort)",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
", to change the value of vactive) none described below move move a pointer (e",1
"
the npi accesses an external environment, q, which varies according to the task",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
g,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" as with the others, we apply the procedure described in section 3",0
 almost all architectures train on program input/output pairs,1
 there is a (changing) list of neural programs used to accomplish a given task,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
we propose and describe our verification procedure",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" each time a subprogram is called, the stack depth increases",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
grade school addition",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 ,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
g,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
quicksort",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
bubble sort",0
 ,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 the program terminates when seeing no numbers in the current column,1
" for each length, we test each program on 30 randomly generated problems",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" as aforementioned, the npi model naturally supports recursion",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 b1b0 where no carry operations occur,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 the first is the actual model architecture,1
"
quicksort",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
", to color a vertex) or variable (e",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 recursion enables provably perfect generalization,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
we propose and describe our verification procedure",1
g,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 ,1
 u varies with the number of vertices in the graph,0
", the trace corresponding to the problem “109 + 101”)",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
 npi then outputs the return probability and next program and arguments to execute,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" that is to say, the network does not learn the true program semantics",1
 u varies with the number of vertices in the graph,0
", an lstm in npi’s case, but possibly other networks in different cases",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 ,0
" in future work, we seek to enable more tasks with recursive structure",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 a1a0 + bnbn−1 ,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
", the trace corresponding to the array [3,2])",1
 indentation indicates the stack is one level deeper than before,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
training setup",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
3,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 we choose to implement a topological sort task for graphs,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
quicksort",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 ,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 reset represents a −∞ value,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" in all experiments, α is set to 0",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" that is to say, the network does not learn the true program semantics",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
quicksort",0
 ,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" in future work, we seek to enable more tasks with recursive structure",0
as mentioned in section 2,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 this verification phase only needs to be performed once after training,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" , n , where the dag contains n vertices",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 ,1
" twc-1409915, darpa under grant no",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 3: begin traversing from vertex 1 in the dag,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
as mentioned in section 2,0
 the maximum problem length in this training set is 3 (e,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 we adapt machinery from the original paper slightly to fit our needs,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
 ,0
 this verification phase only needs to be performed once after training,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
g,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
as mentioned in section 2,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
 this verification phase only needs to be performed once after training,1
 the environment and return probability are omitted for readability,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
training setup",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" , a1a0 + b1b0} are added properly",1
 we found that changing the npi training traces is a simple way to enable this,0
 18: push lo and p− 1 to slo and shi,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" that is to say, the network does not learn the true program semantics",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
to perform the verification as described here, it is critical to construct v correctly",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
arg 2 (increment or decrement): up, down
swap",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
g,0
" each time a subprogram is called, the stack depth increases",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" for each length, we test each program on 30 randomly generated problems",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" for each length, we test each program on 30 randomly generated problems",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 18: push lo and p− 1 to slo and shi,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
 the training set for addition contains 200 traces,1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
quicksort",1
"
we experiment with two levels of recursion—partial and full",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 a1a0 + bnbn−1 ,0
", the trace corresponding to the problem “109 + 101”)",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
 we found that changing the npi training traces is a simple way to enable this,1
" for each length, we test each program on 30 randomly generated problems",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
grade-school addition",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for each length, we test each program on 30 randomly generated problems",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" we call this set of inputs the verification set, sv ",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
grade school addition",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
g,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
the three environment observations aid with control flow in algorithm 2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
", qstacklo or qstackhi) or to pointer (e",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
bubble sort",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
bubble sort",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
", to change the value of phi) none described belowstack",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
"
bubble sort",1
 u varies with the number of vertices in the graph,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
move",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 ,0
 the maximum problem length in this training set is 3 (e,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 the core controller acts as a dispatcher for the programs,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
", the trace corresponding to the array [3,2])",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
g,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 we choose to implement a topological sort task for graphs,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
3,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
the npi accesses an external environment, q, which varies according to the task",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
 these pointers are referred to as bubble pointers,1
 this verification phase only needs to be performed once after training,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
", the trace corresponding to the problem “109 + 101”)",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 18: push lo and p− 1 to slo and shi,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 we found that changing the npi training traces is a simple way to enable this,1
 this verification phase only needs to be performed once after training,0
" that is to say, the network does not learn the true program semantics",0
g,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
as in line 13 of the right-hand side of figure 1",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
base cases and reduction rules for quicksort",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
arg 2 (increment or decrement): up, down
swap",0
 we created a program set that reflects the semantics of algorithm 2,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
quicksort",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
", to color a vertex) or variable (e",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
", the trace corresponding to the array [3,2])",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" et+1 ∼ fenv(et, pt, at)",0
" in all experiments, α is set to 0",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 ,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 b1b0 where no carry operations occur,0
"1; and for bubble sort, appendix a",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 almost all architectures train on program input/output pairs,1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
3,0
"
as in line 13 of the right-hand side of figure 1",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
", the trace corresponding to the problem “109 + 101”)",0
" each time a subprogram is called, the stack depth increases",0
" in future work, we seek to enable more tasks with recursive structure",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
g,1
 our experiments use a small number of training examples,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 ,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 npi then outputs the return probability and next program and arguments to execute,0
 the maximum problem length in this training set is 3 (e,1
 ,1
3 to construct v and then empirically create a verification set which covers v ,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" , n , where the dag contains n vertices",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
2,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
", to change the value of vactive) none described below move move a pointer (e",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
2,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
", the trace corresponding to the problem “109 + 101”)",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" lshift moves the four pointers to the left, to move to the next column",0
"
base cases and reduction rules for topological sort",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
g,0
g,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 ,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
", an lstm in npi’s case, but possibly other networks in different cases",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
training setup",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
6,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 a1a0 + bnbn−1 ,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
base cases and reduction rules for addition",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 b1b0 where no carry operations occur,0
" in particular, recursion can be implemented as a program calling itself",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
3 to construct v and then empirically create a verification set which covers v ,1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
", the trace corresponding to the problem “109 + 101”)",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
3,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" twc-1409915, darpa under grant no",0
", the verification set",1
" , n , where the dag contains n vertices",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 b1b0 where no carry operations occur,0
3,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
base cases and reduction rules for bubble sort",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as with the others, we apply the procedure described in section 3",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
", an array for quicksort or a dag for topological sort)",1
 18: push lo and p− 1 to slo and shi,0
" for each length, we test each program on 30 randomly generated problems",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
grade school addition",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" in this architecture, we consider a core controller, e",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
grade-school addition",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
", qstacklo or qstackhi) or to pointer (e",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
g,0
"
base cases and reduction rules for bubble sort",1
3,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
3,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
we describe the details of the npi model relevant to our contributions",0
e,1
", the trace corresponding to the problem “109 + 101”)",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 a1a0 + bnbn−1 ,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 we outline how to construct this set,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" each time a subprogram is called, the stack depth increases",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"
grade-school addition",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
", an array for quicksort or a dag for topological sort)",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 ,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" in future work, we seek to enable more tasks with recursive structure",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
bubble sort",0
"
base cases and reduction rules for bubble sort",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 we outline how to construct this set,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
to perform the verification as described here, it is critical to construct v correctly",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 18: push lo and p− 1 to slo and shi,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 ,0
 the environment and return probability are omitted for readability,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" , n , where the dag contains n vertices",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
bubble sort",0
", qstacklo or qstackhi) or to pointer (e",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
 npi then outputs the return probability and next program and arguments to execute,1
g,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
 npi then outputs the return probability and next program and arguments to execute,0
" fa8750-15-2-0104, and berkeley deep drive",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
g,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
e,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
base cases and reduction rules for topological sort",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
g,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
 ,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 we adapt machinery from the original paper slightly to fit our needs,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
g,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
quicksort",0
"
base cases and reduction rules for topological sort",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" fa8750-15-2-0104, and berkeley deep drive",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
 the training set for addition contains 200 traces,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
this material is in part based upon work supported by the national science foundation under grant no,0
" we call this set of inputs the verification set, sv ",0
 indentation indicates the stack is one level deeper than before,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
g,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
to perform the verification as described here, it is critical to construct v correctly",0
g,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
quicksort",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" each time a subprogram is called, the stack depth increases",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" lshift moves the four pointers to the left, to move to the next column",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
 this verification phase only needs to be performed once after training,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
g,1
g,1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
 this algorithm is a variant of depth first search,0
", qstacklo or qstackhi) or to pointer (e",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
base cases and reduction rules for quicksort",1
 3: begin traversing from vertex 1 in the dag,0
"
topological sort",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
3,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"1; and for bubble sort, appendix a",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
bubble sort",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 almost all architectures train on program input/output pairs,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
", the trace corresponding to the array [3,2])",0
"
base cases and reduction rules for bubble sort",0
"
the three environment observations aid with control flow in algorithm 2",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
 the maximum problem length in this training set is 3 (e,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 indentation indicates the stack is one level deeper than before,0
 ,0
", to color a vertex) or variable (e",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
g,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
base cases and reduction rules for topological sort",0
", to change the value of vactive) none described below move move a pointer (e",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
2,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" in all experiments, α is set to 0",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
inside bubble and reset, there are two operations that can be made recursive",0
 the maximum problem length in this training set is 3 (e,1
this material is in part based upon work supported by the national science foundation under grant no,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
6,0
 npi then outputs the return probability and next program and arguments to execute,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
 the first is the actual model architecture,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" , n , where the dag contains n vertices",0
"
move",0
 ,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
", to change the value of phi) none described belowstack",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 a1a0 + bnbn−1 ,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
 ,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
topological sort",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" et+1 ∼ fenv(et, pt, at)",0
2,0
", an array for quicksort or a dag for topological sort)",1
 we created a program set that reflects the semantics of algorithm 2,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
 the core controller acts as a dispatcher for the programs,0
"1; and for bubble sort, appendix a",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
3,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"
for addition, we analytically determine the verification set",1
as mentioned in section 2,1
6,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" in future work, we seek to enable more tasks with recursive structure",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
g,1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
g,0
 the program terminates when seeing no numbers in the current column,1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 indentation indicates the stack is one level deeper than before,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
grade school addition",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
"
base cases and reduction rules for bubble sort",1
"
we experiment with two levels of recursion—partial and full",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 a1a0 + bnbn−1 ,0
 our experiments use a small number of training examples,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
base cases and reduction rules for addition",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
topological sort",1
 we choose to implement a topological sort task for graphs,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"
quicksort",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
grade-school addition",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" lshift moves the four pointers to the left, to move to the next column",0
 this algorithm is a variant of depth first search,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" that is to say, the network does not learn the true program semantics",0
g,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 the environment and return probability are omitted for readability,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
in this general neural programming architecture, we show it is easy to support recursion",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
topological sort",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
 recursion enables provably perfect generalization,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" in particular, recursion can be implemented as a program calling itself",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
bubble sort",0
 indentation indicates the stack is one level deeper than before,1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" for each length, we test each program on 30 randomly generated problems",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" as aforementioned, the npi model naturally supports recursion",0
" lshift moves the four pointers to the left, to move to the next column",1
"
we describe the details of the npi model relevant to our contributions",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 the degree for any vertex in the dag is variable,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" fa8750-15-2-0104, and berkeley deep drive",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
g,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 indentation indicates the stack is one level deeper than before,1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 this algorithm is a variant of depth first search,1
" in particular, recursion can be implemented as a program calling itself",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" twc-1409915, darpa under grant no",0
 this algorithm is a variant of depth first search,0
 recursion can be implemented differently for different neural programming models,0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
as in line 13 of the right-hand side of figure 1",1
", the trace corresponding to the problem “109 + 101”)",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" et+1 ∼ fenv(et, pt, at)",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" that is to say, the network does not learn the true program semantics",0
g,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
move",0
 the environment and return probability are omitted for readability,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" in all experiments, α is set to 0",0
 our experiments use a small number of training examples,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 recursion can be implemented differently for different neural programming models,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"1; and for bubble sort, appendix a",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
g,1
2,1
 the core controller acts as a dispatcher for the programs,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
arg 2 (increment or decrement): up, down
swap",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" in all experiments, α is set to 0",1
2,1
g,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
to perform the verification as described here, it is critical to construct v correctly",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
2,1
" in all experiments, α is set to 0",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
", to color a vertex) or variable (e",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
inside bubble and reset, there are two operations that can be made recursive",0
", qstacklo or qstackhi) or to pointer (e",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 the program terminates when seeing no numbers in the current column,1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
the npi accesses an external environment, q, which varies according to the task",0
 ,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 the degree for any vertex in the dag is variable,1
" in this architecture, we consider a core controller, e",1
 these pointers are referred to as bubble pointers,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
grade-school addition",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
g,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
quicksort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 we found that changing the npi training traces is a simple way to enable this,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" that is to say, the network does not learn the true program semantics",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
the three environment observations aid with control flow in algorithm 2",0
" however, our concept of recursion for neural programs is general",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 u varies with the number of vertices in the graph,1
" et+1 ∼ fenv(et, pt, at)",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" , n , where the dag contains n vertices",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
move",1
"
grade-school addition",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" in all experiments, α is set to 0",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
e,1
 the training set for addition contains 200 traces,1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" however, our concept of recursion for neural programs is general",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
 3: begin traversing from vertex 1 in the dag,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
3,0
", to change the value of phi) none described belowstack",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
base cases and reduction rules for bubble sort",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 there is a (changing) list of neural programs used to accomplish a given task,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
", to color a vertex) or variable (e",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
g,0
 reset represents a −∞ value,0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
", an array for quicksort or a dag for topological sort)",0
"
the three environment observations aid with control flow in algorithm 2",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 ,1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 the program terminates when seeing no numbers in the current column,0
"
we describe the details of the npi model relevant to our contributions",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" as with the others, we apply the procedure described in section 3",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" each time a subprogram is called, the stack depth increases",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" in all experiments, α is set to 0",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
arg 2 (increment or decrement): up, down
swap",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
", to change the value of phi) none described belowstack",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
3 to construct v and then empirically create a verification set which covers v ,0
 ,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
bubble sort",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
quicksort",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
g,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
3,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
grade school addition",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 these pointers are referred to as bubble pointers,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 there is a (changing) list of neural programs used to accomplish a given task,0
"
base cases and reduction rules for addition",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 we adapt machinery from the original paper slightly to fit our needs,0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 this algorithm is a variant of depth first search,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
 the environment and return probability are omitted for readability,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
the three environment observations aid with control flow in algorithm 2",0
3,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
"
base cases and reduction rules for bubble sort",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
", qstacklo or qstackhi) or to pointer (e",0
we now report on generalization for the varying tasks,1
"
base cases and reduction rules for bubble sort",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
6,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 ,1
" as with the others, we apply the procedure described in section 3",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" as aforementioned, the npi model naturally supports recursion",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
grade-school addition",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" as aforementioned, the npi model naturally supports recursion",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 the core controller acts as a dispatcher for the programs,0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 the original version of the bubblesort implementation exposes the values within the array,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
g,1
", qstacklo or qstackhi) or to pointer (e",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
grade-school addition",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 ,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 the core controller acts as a dispatcher for the programs,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
", the verification set",1
"
move",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
the npi accesses an external environment, q, which varies according to the task",1
 reset represents a −∞ value,0
g,1
" for each length, we test each program on 30 randomly generated problems",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" twc-1409915, darpa under grant no",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
g,1
we now report on generalization for the varying tasks,0
 3: begin traversing from vertex 1 in the dag,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
inside bubble and reset, there are two operations that can be made recursive",1
 the maximum problem length in this training set is 3 (e,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
the npi accesses an external environment, q, which varies according to the task",1
"
we experiment with two levels of recursion—partial and full",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
training setup",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
this material is in part based upon work supported by the national science foundation under grant no,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
3,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
", qstacklo or qstackhi) or to pointer (e",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" for each length, we test each program on 30 randomly generated problems",0
 we found that changing the npi training traces is a simple way to enable this,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" for each length, we test each program on 30 randomly generated problems",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" however, our concept of recursion for neural programs is general",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 we adapt machinery from the original paper slightly to fit our needs,1
 ,0
"
grade-school addition",0
" fa8750-15-2-0104, and berkeley deep drive",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
 reset represents a −∞ value,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 this algorithm is a variant of depth first search,0
3,1
"
base cases and reduction rules for quicksort",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 our experiments use a small number of training examples,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 ,1
" lshift moves the four pointers to the left, to move to the next column",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
base cases and reduction rules for topological sort",0
"
move",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" however, our concept of recursion for neural programs is general",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 this algorithm is a variant of depth first search,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
", to color a vertex) or variable (e",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
training setup",1
" , a1a0 + b1b0} are added properly",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"1; and for bubble sort, appendix a",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" in future work, we seek to enable more tasks with recursive structure",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 ,1
" , n , where the dag contains n vertices",1
" we call this set of inputs the verification set, sv ",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we call this set of inputs the verification set, sv ",0
 the program terminates when seeing no numbers in the current column,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
arg 2 (increment or decrement): up, down
swap",1
g,1
g,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
g,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
2,0
"
inside bubble and reset, there are two operations that can be made recursive",0
 u varies with the number of vertices in the graph,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 our experiments use a small number of training examples,1
 we outline how to construct this set,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
g,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
3,1
 the core controller acts as a dispatcher for the programs,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
move",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
", the trace corresponding to the array [3,2])",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 the training set for addition contains 200 traces,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
as mentioned in section 2,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" on the other hand, the recursive programs have learned the true program semantics",0
" in this architecture, we consider a core controller, e",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
", the trace corresponding to the array [3,2])",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
", an array for quicksort or a dag for topological sort)",0
" for each length, we test each program on 30 randomly generated problems",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
g,1
"
arg 2 (increment or decrement): up, down
swap",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 these pointers are referred to as bubble pointers,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
", the verification set",1
" , n , where the dag contains n vertices",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
 almost all architectures train on program input/output pairs,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
base cases and reduction rules for bubble sort",1
 indentation indicates the stack is one level deeper than before,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 the first is the actual model architecture,0
 we adapt machinery from the original paper slightly to fit our needs,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
quicksort",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
 we adapt machinery from the original paper slightly to fit our needs,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
", the trace corresponding to the problem “109 + 101”)",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
grade school addition",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 the first is the actual model architecture,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
base cases and reduction rules for topological sort",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 we outline how to construct this set,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 recursion can be implemented differently for different neural programming models,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
", qstacklo or qstackhi) or to pointer (e",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
 indentation indicates the stack is one level deeper than before,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
g,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
this material is in part based upon work supported by the national science foundation under grant no,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
we experiment with two levels of recursion—partial and full",0
 a1a0 + bnbn−1 ,1
 ,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" as aforementioned, the npi model naturally supports recursion",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" for each length, we test each program on 30 randomly generated problems",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 18: push lo and p− 1 to slo and shi,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" twc-1409915, darpa under grant no",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
"
bubble sort",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
quicksort",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 ,0
 u varies with the number of vertices in the graph,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 ,1
 this verification phase only needs to be performed once after training,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" as aforementioned, the npi model naturally supports recursion",1
as mentioned in section 2,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
we describe the details of the npi model relevant to our contributions",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
base cases and reduction rules for quicksort",0
 the degree for any vertex in the dag is variable,1
g,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
bubble sort",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
5,1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
grade-school addition",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
g,1
 we created a program set that reflects the semantics of algorithm 2,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 we choose to implement a topological sort task for graphs,1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
bubble sort",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" for each length, we test each program on 30 randomly generated problems",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
grade school addition",0
" et+1 ∼ fenv(et, pt, at)",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
algorithm 2 shows the topological sort task of interest",1
"
the three environment observations aid with control flow in algorithm 2",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 recursion can be implemented differently for different neural programming models,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 the original version of the bubblesort implementation exposes the values within the array,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
grade school addition",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
 u varies with the number of vertices in the graph,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
we experiment with two levels of recursion—partial and full",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 the original version of the bubblesort implementation exposes the values within the array,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" as with the others, we apply the procedure described in section 3",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 ,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
"
for addition, we analytically determine the verification set",0
"
move",1
 ,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
"
grade-school addition",0
 the maximum problem length in this training set is 3 (e,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
", the trace corresponding to the array [3,2])",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 the first is the actual model architecture,0
g,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"1; and for bubble sort, appendix a",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" we call this set of inputs the verification set, sv ",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
g,1
" for each length, we test each program on 30 randomly generated problems",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 we choose to implement a topological sort task for graphs,1
 recursion enables provably perfect generalization,1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" on the other hand, the recursive programs have learned the true program semantics",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
"
we describe the details of the npi model relevant to our contributions",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" in this architecture, we consider a core controller, e",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" et+1 ∼ fenv(et, pt, at)",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
move",0
"
algorithm 2 shows the topological sort task of interest",0
 ,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 ,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" lshift moves the four pointers to the left, to move to the next column",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 b1b0 where no carry operations occur,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 ,1
as mentioned in section 2,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
grade-school addition",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
grade-school addition",0
"
base cases and reduction rules for addition",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
 ,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" for each length, we test each program on 30 randomly generated problems",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" each time a subprogram is called, the stack depth increases",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
e,1
 ,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"1; and for bubble sort, appendix a",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" in all experiments, α is set to 0",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
training setup",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
 3: begin traversing from vertex 1 in the dag,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" however, our concept of recursion for neural programs is general",0
 the core controller acts as a dispatcher for the programs,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
we experiment with two levels of recursion—partial and full",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
quicksort",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
the npi accesses an external environment, q, which varies according to the task",0
"
algorithm 2 shows the topological sort task of interest",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
5,0
", the trace corresponding to the array [3,2])",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 almost all architectures train on program input/output pairs,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" as with the others, we apply the procedure described in section 3",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
arg 2 (increment or decrement): up, down
swap",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
 the training set for addition contains 200 traces,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" we call this set of inputs the verification set, sv ",0
" in particular, recursion can be implemented as a program calling itself",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" in this architecture, we consider a core controller, e",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
e,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
3,0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
move",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 ,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
the npi accesses an external environment, q, which varies according to the task",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
", the trace corresponding to the array [3,2])",0
 u varies with the number of vertices in the graph,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
base cases and reduction rules for quicksort",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" , a1a0 + b1b0} are added properly",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
3 to construct v and then empirically create a verification set which covers v ,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
g,0
g,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 almost all architectures train on program input/output pairs,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" lshift moves the four pointers to the left, to move to the next column",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
", to change the value of vactive) none described below move move a pointer (e",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 ,1
 we outline how to construct this set,1
"
for addition, we analytically determine the verification set",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"
arg 2 (increment or decrement): up, down
swap",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
this material is in part based upon work supported by the national science foundation under grant no,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" however, our concept of recursion for neural programs is general",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
5,0
"
as in line 13 of the right-hand side of figure 1",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
g,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 we created a program set that reflects the semantics of algorithm 2,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 ,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
 u varies with the number of vertices in the graph,0
 ,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
g,0
", qstacklo or qstackhi) or to pointer (e",1
"
base cases and reduction rules for bubble sort",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"
algorithm 2 shows the topological sort task of interest",0
3,1
 recursion enables provably perfect generalization,1
" for each length, we test each program on 30 randomly generated problems",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" for each length, we test each program on 30 randomly generated problems",1
"
bubble sort",1
 recursion can be implemented differently for different neural programming models,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
g,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
for addition, we analytically determine the verification set",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
we now report on generalization for the varying tasks,0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 these pointers are referred to as bubble pointers,1
" twc-1409915, darpa under grant no",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
3 to construct v and then empirically create a verification set which covers v ,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 the environment and return probability are omitted for readability,0
", the trace corresponding to the array [3,2])",1
 indentation indicates the stack is one level deeper than before,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
6,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
arg 2 (increment or decrement): up, down
swap",1
"
base cases and reduction rules for topological sort",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
arg 2 (increment or decrement): up, down
swap",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" lshift moves the four pointers to the left, to move to the next column",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
"
base cases and reduction rules for addition",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
", the verification set",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
base cases and reduction rules for quicksort",0
g,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 recursion can be implemented differently for different neural programming models,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
g,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
to perform the verification as described here, it is critical to construct v correctly",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 we created a program set that reflects the semantics of algorithm 2,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
", the trace corresponding to the problem “109 + 101”)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
for addition, we analytically determine the verification set",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
", the trace corresponding to the array [3,2])",1
" each time a subprogram is called, the stack depth increases",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
", the trace corresponding to the array [3,2])",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
", qstacklo or qstackhi) or to pointer (e",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
base cases and reduction rules for bubble sort",1
", to change the value of vactive) none described below move move a pointer (e",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 ,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
 the program terminates when seeing no numbers in the current column,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
inside bubble and reset, there are two operations that can be made recursive",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
e,1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
move",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" on the other hand, the recursive programs have learned the true program semantics",0
", the trace corresponding to the problem “109 + 101”)",0
 this algorithm is a variant of depth first search,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
bubble sort",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
", to change the value of vactive) none described below move move a pointer (e",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 u varies with the number of vertices in the graph,1
 ,0
" however, our concept of recursion for neural programs is general",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 there is a (changing) list of neural programs used to accomplish a given task,0
 the first is the actual model architecture,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
", to color a vertex) or variable (e",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
5,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 recursion can be implemented differently for different neural programming models,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
 recursion enables provably perfect generalization,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
5,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
e,0
 ,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 a1a0 + bnbn−1 ,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
3 to construct v and then empirically create a verification set which covers v ,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
", the trace corresponding to the problem “109 + 101”)",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
g,1
"
base cases and reduction rules for topological sort",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" , n , where the dag contains n vertices",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
", the trace corresponding to the array [3,2])",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
this material is in part based upon work supported by the national science foundation under grant no,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
", the trace corresponding to the problem “109 + 101”)",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 our experiments use a small number of training examples,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
", the verification set",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
grade school addition",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 a1a0 + bnbn−1 ,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 a1a0 + bnbn−1 ,1
3,1
" using this modification, we constructed a verification set consisting of one array of size 10",1
 ,1
", an array for quicksort or a dag for topological sort)",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 b1b0 where no carry operations occur,1
 b1b0 where no carry operations occur,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
as mentioned in section 2,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 18: push lo and p− 1 to slo and shi,0
 we found that changing the npi training traces is a simple way to enable this,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
 3: begin traversing from vertex 1 in the dag,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
e,1
 ,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 we adapt machinery from the original paper slightly to fit our needs,1
"
as in line 13 of the right-hand side of figure 1",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
g,1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
6,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
3,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" each time a subprogram is called, the stack depth increases",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
quicksort",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 recursion can be implemented differently for different neural programming models,1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
base cases and reduction rules for topological sort",1
"
we experiment with two levels of recursion—partial and full",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
g,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" in this architecture, we consider a core controller, e",1
" however, our concept of recursion for neural programs is general",0
 ,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" however, our concept of recursion for neural programs is general",0
"
we describe the details of the npi model relevant to our contributions",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 we choose to implement a topological sort task for graphs,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
inside bubble and reset, there are two operations that can be made recursive",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
the npi accesses an external environment, q, which varies according to the task",0
" however, our concept of recursion for neural programs is general",1
"1; and for bubble sort, appendix a",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 the core controller acts as a dispatcher for the programs,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 18: push lo and p− 1 to slo and shi,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
", to change the value of phi) none described belowstack",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
algorithm 2 shows the topological sort task of interest",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
", qstacklo or qstackhi) or to pointer (e",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 ,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
g,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
", an lstm in npi’s case, but possibly other networks in different cases",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 this verification phase only needs to be performed once after training,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
 ,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 npi then outputs the return probability and next program and arguments to execute,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 almost all architectures train on program input/output pairs,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 the original version of the bubblesort implementation exposes the values within the array,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
we describe the details of the npi model relevant to our contributions",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
the three environment observations aid with control flow in algorithm 2",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
we propose and describe our verification procedure",1
"
grade-school addition",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
g,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
e,0
 reset represents a −∞ value,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" on the other hand, the recursive programs have learned the true program semantics",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" in particular, recursion can be implemented as a program calling itself",0
" as aforementioned, the npi model naturally supports recursion",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 b1b0 where no carry operations occur,1
e,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
as mentioned in section 2,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" et+1 ∼ fenv(et, pt, at)",0
g,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
3,0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
5,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
as in line 13 of the right-hand side of figure 1",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 the program terminates when seeing no numbers in the current column,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 we created a program set that reflects the semantics of algorithm 2,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 ,0
 ,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" , n , where the dag contains n vertices",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" however, our concept of recursion for neural programs is general",1
we now report on generalization for the varying tasks,0
this material is in part based upon work supported by the national science foundation under grant no,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
g,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
grade school addition",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
3 to construct v and then empirically create a verification set which covers v ,1
", to change the value of phi) none described belowstack",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
move",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
grade school addition",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
2,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
the three environment observations aid with control flow in algorithm 2",0
"
base cases and reduction rules for bubble sort",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
inside bubble and reset, there are two operations that can be made recursive",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
we experiment with two levels of recursion—partial and full",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
", the trace corresponding to the problem “109 + 101”)",1
 this verification phase only needs to be performed once after training,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
", to change the value of vactive) none described below move move a pointer (e",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
as in line 13 of the right-hand side of figure 1",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
arg 2 (increment or decrement): up, down
swap",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" twc-1409915, darpa under grant no",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 ,0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 ,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" twc-1409915, darpa under grant no",0
" however, our concept of recursion for neural programs is general",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
g,0
3,0
"
move",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 we outline how to construct this set,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
e,0
as mentioned in section 2,0
 ,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
training setup",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
as in line 13 of the right-hand side of figure 1",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
base cases and reduction rules for bubble sort",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
g,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
arg 2 (increment or decrement): up, down
swap",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" et+1 ∼ fenv(et, pt, at)",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
move",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" lshift moves the four pointers to the left, to move to the next column",1
" as with the others, we apply the procedure described in section 3",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" in all experiments, α is set to 0",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
 we choose to implement a topological sort task for graphs,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
2,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 ,1
 a1a0 + bnbn−1 ,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 our experiments use a small number of training examples,0
g,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
this material is in part based upon work supported by the national science foundation under grant no,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
as in line 13 of the right-hand side of figure 1",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" in future work, we seek to enable more tasks with recursive structure",1
g,1
" using this modification, we constructed a verification set consisting of one array of size 10",0
 reset represents a −∞ value,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" in this architecture, we consider a core controller, e",1
3,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 ,1
 these pointers are referred to as bubble pointers,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
 the maximum problem length in this training set is 3 (e,0
"1; and for bubble sort, appendix a",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
 almost all architectures train on program input/output pairs,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" in future work, we seek to enable more tasks with recursive structure",1
g,1
3,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
g,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
", an array for quicksort or a dag for topological sort)",0
 the original version of the bubblesort implementation exposes the values within the array,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
we now report on generalization for the varying tasks,0
"
move",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
this material is in part based upon work supported by the national science foundation under grant no,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" in this architecture, we consider a core controller, e",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
g,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
e,0
"
inside bubble and reset, there are two operations that can be made recursive",0
3 to construct v and then empirically create a verification set which covers v ,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 we outline how to construct this set,1
3,0
", the verification set",0
3,1
" each time a subprogram is called, the stack depth increases",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
training setup",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
 the environment and return probability are omitted for readability,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 3: begin traversing from vertex 1 in the dag,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
", qstacklo or qstackhi) or to pointer (e",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" for each length, we test each program on 30 randomly generated problems",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
base cases and reduction rules for topological sort",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 our experiments use a small number of training examples,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
", to color a vertex) or variable (e",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 we choose to implement a topological sort task for graphs,1
" in all experiments, α is set to 0",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 recursion enables provably perfect generalization,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
g,0
"
arg 2 (increment or decrement): up, down
swap",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
g,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
3,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
for addition, we analytically determine the verification set",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" lshift moves the four pointers to the left, to move to the next column",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 these pointers are referred to as bubble pointers,0
 there is a (changing) list of neural programs used to accomplish a given task,0
 the program terminates when seeing no numbers in the current column,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
we propose and describe our verification procedure",0
"
we experiment with two levels of recursion—partial and full",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 there is a (changing) list of neural programs used to accomplish a given task,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 there is a (changing) list of neural programs used to accomplish a given task,1
 ,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
g,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
", the trace corresponding to the array [3,2])",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
algorithm 2 shows the topological sort task of interest",1
6,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" , a1a0 + b1b0} are added properly",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
 we adapt machinery from the original paper slightly to fit our needs,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 ,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 our experiments use a small number of training examples,1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
2,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
", to color a vertex) or variable (e",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" for each length, we test each program on 30 randomly generated problems",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
the three environment observations aid with control flow in algorithm 2",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
", to change the value of vactive) none described below move move a pointer (e",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" in all experiments, α is set to 0",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
 we created a program set that reflects the semantics of algorithm 2,0
"
algorithm 2 shows the topological sort task of interest",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 this algorithm is a variant of depth first search,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 the first is the actual model architecture,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"
inside bubble and reset, there are two operations that can be made recursive",0
 the degree for any vertex in the dag is variable,0
"
base cases and reduction rules for bubble sort",0
"
base cases and reduction rules for addition",1
 this verification phase only needs to be performed once after training,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 18: push lo and p− 1 to slo and shi,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
this material is in part based upon work supported by the national science foundation under grant no,1
 almost all architectures train on program input/output pairs,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" however, our concept of recursion for neural programs is general",0
" for each length, we test each program on 30 randomly generated problems",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
topological sort",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
g,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
3,1
g,0
"
quicksort",1
 ,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
g,1
 we created a program set that reflects the semantics of algorithm 2,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
5,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
move",1
 there is a (changing) list of neural programs used to accomplish a given task,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 indentation indicates the stack is one level deeper than before,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" for each length, we test each program on 30 randomly generated problems",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 we choose to implement a topological sort task for graphs,1
 these pointers are referred to as bubble pointers,1
 ,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
for addition, we analytically determine the verification set",0
", to change the value of phi) none described belowstack",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 we choose to implement a topological sort task for graphs,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
g,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
 the first is the actual model architecture,1
"
arg 2 (increment or decrement): up, down
swap",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
 reset represents a −∞ value,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 we created a program set that reflects the semantics of algorithm 2,1
" however, our concept of recursion for neural programs is general",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 ,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" for each length, we test each program on 30 randomly generated problems",1
 the core controller acts as a dispatcher for the programs,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
g,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
base cases and reduction rules for quicksort",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
g,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
g,1
e,1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
5,1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
 we choose to implement a topological sort task for graphs,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
g,0
" twc-1409915, darpa under grant no",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
base cases and reduction rules for topological sort",0
"
topological sort",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" we call this set of inputs the verification set, sv ",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
 ,0
 a1a0 + bnbn−1 ,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 the original version of the bubblesort implementation exposes the values within the array,1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 almost all architectures train on program input/output pairs,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
", to color a vertex) or variable (e",0
"
base cases and reduction rules for bubble sort",0
 ,0
g,0
" in all experiments, α is set to 0",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
base cases and reduction rules for topological sort",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
e,1
", to change the value of vactive) none described below move move a pointer (e",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"
we propose and describe our verification procedure",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
", an array for quicksort or a dag for topological sort)",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" for each length, we test each program on 30 randomly generated problems",1
 the training set for addition contains 200 traces,0
g,0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
quicksort",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 the core controller acts as a dispatcher for the programs,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 the environment and return probability are omitted for readability,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
", the trace corresponding to the problem “109 + 101”)",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
g,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
topological sort",0
 the maximum problem length in this training set is 3 (e,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
g,1
e,0
", to change the value of phi) none described belowstack",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 the degree for any vertex in the dag is variable,0
" we call this set of inputs the verification set, sv ",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
we now report on generalization for the varying tasks,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
g,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
", an lstm in npi’s case, but possibly other networks in different cases",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
6,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
topological sort",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 we outline how to construct this set,0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 ,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
 the training set for addition contains 200 traces,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" for each length, we test each program on 30 randomly generated problems",1
e,1
" in all experiments, α is set to 0",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
e,0
 the core controller acts as a dispatcher for the programs,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
this material is in part based upon work supported by the national science foundation under grant no,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 ,0
 a1a0 + bnbn−1 ,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 indentation indicates the stack is one level deeper than before,0
 3: begin traversing from vertex 1 in the dag,0
g,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
we now report on generalization for the varying tasks,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
topological sort",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 we adapt machinery from the original paper slightly to fit our needs,0
"
base cases and reduction rules for bubble sort",0
g,1
", the trace corresponding to the array [3,2])",1
", the verification set",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
2,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" for each length, we test each program on 30 randomly generated problems",1
 indentation indicates the stack is one level deeper than before,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
g,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
quicksort",1
 u varies with the number of vertices in the graph,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
g,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
", the verification set",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
we propose and describe our verification procedure",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 a1a0 + bnbn−1 ,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
quicksort",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
g,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" as aforementioned, the npi model naturally supports recursion",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 the core controller acts as a dispatcher for the programs,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 we adapt machinery from the original paper slightly to fit our needs,0
" et+1 ∼ fenv(et, pt, at)",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" , a1a0 + b1b0} are added properly",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 there is a (changing) list of neural programs used to accomplish a given task,0
"
base cases and reduction rules for topological sort",1
", an lstm in npi’s case, but possibly other networks in different cases",1
"
we describe the details of the npi model relevant to our contributions",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 we outline how to construct this set,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
grade school addition",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
grade-school addition",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 we found that changing the npi training traces is a simple way to enable this,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 b1b0 where no carry operations occur,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
topological sort",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" , n , where the dag contains n vertices",0
"
bubble sort",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
as in line 13 of the right-hand side of figure 1",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
for addition, we analytically determine the verification set",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" on the other hand, the recursive programs have learned the true program semantics",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"1; and for bubble sort, appendix a",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
", to color a vertex) or variable (e",1
" in particular, recursion can be implemented as a program calling itself",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
g,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
we propose and describe our verification procedure",0
" in this architecture, we consider a core controller, e",1
 ,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 ,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
we now report on generalization for the varying tasks,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
topological sort",0
"
base cases and reduction rules for topological sort",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
we describe the details of the npi model relevant to our contributions",1
 recursion enables provably perfect generalization,0
g,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"1; and for bubble sort, appendix a",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
move",0
" each time a subprogram is called, the stack depth increases",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" in future work, we seek to enable more tasks with recursive structure",1
6,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 3: begin traversing from vertex 1 in the dag,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 indentation indicates the stack is one level deeper than before,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
3,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
2,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
", to color a vertex) or variable (e",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
 these pointers are referred to as bubble pointers,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 the degree for any vertex in the dag is variable,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
the npi accesses an external environment, q, which varies according to the task",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
base cases and reduction rules for topological sort",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 the degree for any vertex in the dag is variable,0
 ,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
"
move",1
 the environment and return probability are omitted for readability,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
grade-school addition",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
g,0
g,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
g,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
grade school addition",0
" , a1a0 + b1b0} are added properly",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" that is to say, the network does not learn the true program semantics",1
", an array for quicksort or a dag for topological sort)",0
" twc-1409915, darpa under grant no",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
grade-school addition",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 u varies with the number of vertices in the graph,1
"
quicksort",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 ,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" , n , where the dag contains n vertices",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" twc-1409915, darpa under grant no",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
g,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
we propose and describe our verification procedure",0
 ,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" on the other hand, the recursive programs have learned the true program semantics",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 this algorithm is a variant of depth first search,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 ,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
we experiment with two levels of recursion—partial and full",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
", to change the value of vactive) none described below move move a pointer (e",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
g,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 there is a (changing) list of neural programs used to accomplish a given task,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
base cases and reduction rules for bubble sort",1
 we choose to implement a topological sort task for graphs,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"
base cases and reduction rules for quicksort",1
"
topological sort",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 ,1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
g,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" we call this set of inputs the verification set, sv ",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
", an array for quicksort or a dag for topological sort)",1
" in all experiments, α is set to 0",0
" , a1a0 + b1b0} are added properly",0
g,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 b1b0 where no carry operations occur,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
g,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 npi then outputs the return probability and next program and arguments to execute,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 the environment and return probability are omitted for readability,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
 we choose to implement a topological sort task for graphs,0
 almost all architectures train on program input/output pairs,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
quicksort",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 the program terminates when seeing no numbers in the current column,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" as with the others, we apply the procedure described in section 3",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
g,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
3 to construct v and then empirically create a verification set which covers v ,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
", to change the value of phi) none described belowstack",0
", to color a vertex) or variable (e",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
", to change the value of vactive) none described below move move a pointer (e",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
as in line 13 of the right-hand side of figure 1",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
base cases and reduction rules for topological sort",0
g,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
as mentioned in section 2,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
g,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
base cases and reduction rules for quicksort",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 we outline how to construct this set,0
" as aforementioned, the npi model naturally supports recursion",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
 ,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
algorithm 2 shows the topological sort task of interest",1
 3: begin traversing from vertex 1 in the dag,1
", the trace corresponding to the array [3,2])",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
 ,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
", an array for quicksort or a dag for topological sort)",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
2,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
", qstacklo or qstackhi) or to pointer (e",1
"
move",0
 the training set for addition contains 200 traces,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
arg 2 (increment or decrement): up, down
swap",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
", the verification set",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
move",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
 ,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" as aforementioned, the npi model naturally supports recursion",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
e,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 the core controller acts as a dispatcher for the programs,1
 ,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
g,1
" in this architecture, we consider a core controller, e",0
 ,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 this verification phase only needs to be performed once after training,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 the core controller acts as a dispatcher for the programs,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
g,1
 we found that changing the npi training traces is a simple way to enable this,1
3,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
as in line 13 of the right-hand side of figure 1",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 ,1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 b1b0 where no carry operations occur,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
we now report on generalization for the varying tasks,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
"
the npi accesses an external environment, q, which varies according to the task",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
", an array for quicksort or a dag for topological sort)",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 npi then outputs the return probability and next program and arguments to execute,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
bubble sort",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
", to change the value of vactive) none described below move move a pointer (e",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" we call this set of inputs the verification set, sv ",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
3 to construct v and then empirically create a verification set which covers v ,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" in particular, recursion can be implemented as a program calling itself",1
 ,0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
bubble sort",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
3 to construct v and then empirically create a verification set which covers v ,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
 the core controller acts as a dispatcher for the programs,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
we now report on generalization for the varying tasks,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
g,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
", to color a vertex) or variable (e",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
e,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" twc-1409915, darpa under grant no",1
"
we describe the details of the npi model relevant to our contributions",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
move",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 we adapt machinery from the original paper slightly to fit our needs,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
the three environment observations aid with control flow in algorithm 2",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
g,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
 this algorithm is a variant of depth first search,0
"
grade school addition",0
"
topological sort",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" on the other hand, the recursive programs have learned the true program semantics",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" as aforementioned, the npi model naturally supports recursion",0
" in this architecture, we consider a core controller, e",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
"
base cases and reduction rules for addition",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
g,1
 there is a (changing) list of neural programs used to accomplish a given task,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 recursion enables provably perfect generalization,1
", the trace corresponding to the array [3,2])",0
" fa8750-15-2-0104, and berkeley deep drive",1
", an lstm in npi’s case, but possibly other networks in different cases",1
 indentation indicates the stack is one level deeper than before,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" lshift moves the four pointers to the left, to move to the next column",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
6,1
 the maximum problem length in this training set is 3 (e,0
 ,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
we now report on generalization for the varying tasks,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 b1b0 where no carry operations occur,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
as mentioned in section 2,1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
 the program terminates when seeing no numbers in the current column,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 u varies with the number of vertices in the graph,1
g,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
 ,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" et+1 ∼ fenv(et, pt, at)",0
"
training setup",0
"
arg 2 (increment or decrement): up, down
swap",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" that is to say, the network does not learn the true program semantics",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
base cases and reduction rules for addition",0
 ,1
"
algorithm 2 shows the topological sort task of interest",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 the environment and return probability are omitted for readability,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" twc-1409915, darpa under grant no",0
 recursion can be implemented differently for different neural programming models,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
3,0
 we outline how to construct this set,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
we propose and describe our verification procedure",1
g,1
g,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" on the other hand, the recursive programs have learned the true program semantics",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
g,1
"
move",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" lshift moves the four pointers to the left, to move to the next column",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 we created a program set that reflects the semantics of algorithm 2,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 reset represents a −∞ value,1
g,0
 ,1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
g,0
", the trace corresponding to the array [3,2])",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
 ,1
 ,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 u varies with the number of vertices in the graph,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 indentation indicates the stack is one level deeper than before,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
3,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
we experiment with two levels of recursion—partial and full",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 the degree for any vertex in the dag is variable,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
base cases and reduction rules for bubble sort",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" each time a subprogram is called, the stack depth increases",1
" fa8750-15-2-0104, and berkeley deep drive",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" , n , where the dag contains n vertices",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
 18: push lo and p− 1 to slo and shi,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
", to color a vertex) or variable (e",0
g,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
3,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" on the other hand, the recursive programs have learned the true program semantics",0
", to change the value of vactive) none described below move move a pointer (e",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
bubble sort",0
 ,0
" for each length, we test each program on 30 randomly generated problems",1
"
we experiment with two levels of recursion—partial and full",0
"
topological sort",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
bubble sort",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
g,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 ,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
this material is in part based upon work supported by the national science foundation under grant no,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,1
 the core controller acts as a dispatcher for the programs,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 the first is the actual model architecture,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"
algorithm 2 shows the topological sort task of interest",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
the three environment observations aid with control flow in algorithm 2",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" fa8750-15-2-0104, and berkeley deep drive",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
we propose and describe our verification procedure",1
g,0
 the degree for any vertex in the dag is variable,1
", to change the value of vactive) none described below move move a pointer (e",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" for each length, we test each program on 30 randomly generated problems",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
3,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 3: begin traversing from vertex 1 in the dag,0
"
bubble sort",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
the npi accesses an external environment, q, which varies according to the task",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
g,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
grade-school addition",1
", qstacklo or qstackhi) or to pointer (e",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
g,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
5,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" , n , where the dag contains n vertices",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
 recursion can be implemented differently for different neural programming models,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 ,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
grade school addition",0
" that is to say, the network does not learn the true program semantics",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"
we experiment with two levels of recursion—partial and full",1
 ,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
", to color a vertex) or variable (e",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
"
move",0
3,0
this material is in part based upon work supported by the national science foundation under grant no,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
 the original version of the bubblesort implementation exposes the values within the array,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
g,0
 we found that changing the npi training traces is a simple way to enable this,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
 b1b0 where no carry operations occur,1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 the program terminates when seeing no numbers in the current column,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 the original version of the bubblesort implementation exposes the values within the array,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 our experiments use a small number of training examples,1
" we call this set of inputs the verification set, sv ",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
e,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
 there is a (changing) list of neural programs used to accomplish a given task,0
 u varies with the number of vertices in the graph,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 we outline how to construct this set,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" twc-1409915, darpa under grant no",1
 recursion can be implemented differently for different neural programming models,0
 this verification phase only needs to be performed once after training,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 npi then outputs the return probability and next program and arguments to execute,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" however, our concept of recursion for neural programs is general",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" for each length, we test each program on 30 randomly generated problems",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
", qstacklo or qstackhi) or to pointer (e",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" , a1a0 + b1b0} are added properly",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 the program terminates when seeing no numbers in the current column,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" in particular, recursion can be implemented as a program calling itself",0
"
grade school addition",0
" , a1a0 + b1b0} are added properly",1
3 to construct v and then empirically create a verification set which covers v ,1
 npi then outputs the return probability and next program and arguments to execute,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 recursion enables provably perfect generalization,0
", qstacklo or qstackhi) or to pointer (e",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
topological sort",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
", qstacklo or qstackhi) or to pointer (e",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" we call this set of inputs the verification set, sv ",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 these pointers are referred to as bubble pointers,0
g,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 the core controller acts as a dispatcher for the programs,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
g,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
base cases and reduction rules for quicksort",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" we call this set of inputs the verification set, sv ",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
grade-school addition",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 ,1
"
quicksort",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
the three environment observations aid with control flow in algorithm 2",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
3 to construct v and then empirically create a verification set which covers v ,0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
g,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
this material is in part based upon work supported by the national science foundation under grant no,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
", the verification set",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"
topological sort",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
5,1
"
bubble sort",0
"
we describe the details of the npi model relevant to our contributions",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" twc-1409915, darpa under grant no",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
3,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
", the trace corresponding to the array [3,2])",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 the original version of the bubblesort implementation exposes the values within the array,0
this material is in part based upon work supported by the national science foundation under grant no,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
e,0
 ,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
bubble sort",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 a1a0 + bnbn−1 ,1
" each time a subprogram is called, the stack depth increases",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
e,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
g,1
"
we propose and describe our verification procedure",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" as aforementioned, the npi model naturally supports recursion",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
 the original version of the bubblesort implementation exposes the values within the array,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 we choose to implement a topological sort task for graphs,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 ,0
"1; and for bubble sort, appendix a",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 a1a0 + bnbn−1 ,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
g,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" in this architecture, we consider a core controller, e",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 we adapt machinery from the original paper slightly to fit our needs,1
"
move",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
6,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" for each length, we test each program on 30 randomly generated problems",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
g,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
2,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"1; and for bubble sort, appendix a",0
"
to perform the verification as described here, it is critical to construct v correctly",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
this material is in part based upon work supported by the national science foundation under grant no,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
arg 2 (increment or decrement): up, down
swap",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 our experiments use a small number of training examples,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
base cases and reduction rules for addition",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
 ,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 the first is the actual model architecture,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" in particular, recursion can be implemented as a program calling itself",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 almost all architectures train on program input/output pairs,0
 we choose to implement a topological sort task for graphs,0
"
the npi accesses an external environment, q, which varies according to the task",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 the maximum problem length in this training set is 3 (e,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
g,1
"
inside bubble and reset, there are two operations that can be made recursive",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" for each length, we test each program on 30 randomly generated problems",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" on the other hand, the recursive programs have learned the true program semantics",0
" that is to say, the network does not learn the true program semantics",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 ,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 npi then outputs the return probability and next program and arguments to execute,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
base cases and reduction rules for quicksort",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 these pointers are referred to as bubble pointers,1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
g,1
" lshift moves the four pointers to the left, to move to the next column",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
as in line 13 of the right-hand side of figure 1",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
", to change the value of phi) none described belowstack",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" for each length, we test each program on 30 randomly generated problems",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 ,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
base cases and reduction rules for topological sort",1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 b1b0 where no carry operations occur,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"
to perform the verification as described here, it is critical to construct v correctly",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
 ,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
", the trace corresponding to the array [3,2])",0
" twc-1409915, darpa under grant no",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" , a1a0 + b1b0} are added properly",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
 ,0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" each time a subprogram is called, the stack depth increases",1
"
move",1
"
training setup",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 ,0
we now report on generalization for the varying tasks,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 ,1
 the training set for addition contains 200 traces,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 we found that changing the npi training traces is a simple way to enable this,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" for each length, we test each program on 30 randomly generated problems",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,0
", to change the value of phi) none described belowstack",0
", an array for quicksort or a dag for topological sort)",1
 ,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
 reset represents a −∞ value,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 ,1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
 3: begin traversing from vertex 1 in the dag,0
" that is to say, the network does not learn the true program semantics",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
3,0
 we adapt machinery from the original paper slightly to fit our needs,1
 u varies with the number of vertices in the graph,0
" fa8750-15-2-0104, and berkeley deep drive",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
", to change the value of phi) none described belowstack",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 we found that changing the npi training traces is a simple way to enable this,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 reset represents a −∞ value,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 b1b0 where no carry operations occur,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
", qstacklo or qstackhi) or to pointer (e",0
" in future work, we seek to enable more tasks with recursive structure",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
3,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 ,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 ,0
"
base cases and reduction rules for addition",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
", the trace corresponding to the array [3,2])",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 ,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
the npi accesses an external environment, q, which varies according to the task",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
", to change the value of phi) none described belowstack",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
5,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" twc-1409915, darpa under grant no",0
"
base cases and reduction rules for topological sort",0
5,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
algorithm 2 shows the topological sort task of interest",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
quicksort",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 ,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
we experiment with two levels of recursion—partial and full",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
g,0
 the program terminates when seeing no numbers in the current column,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 recursion enables provably perfect generalization,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
g,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 reset represents a −∞ value,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
 we choose to implement a topological sort task for graphs,0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 recursion can be implemented differently for different neural programming models,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 a1a0 + bnbn−1 ,1
 the core controller acts as a dispatcher for the programs,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" however, our concept of recursion for neural programs is general",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
g,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" in particular, recursion can be implemented as a program calling itself",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"
we propose and describe our verification procedure",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
 ,0
3,0
 ,1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
g,0
"
grade school addition",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
 ,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
topological sort",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" , n , where the dag contains n vertices",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
g,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
", to change the value of vactive) none described below move move a pointer (e",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
as in line 13 of the right-hand side of figure 1",0
"
base cases and reduction rules for topological sort",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
 we outline how to construct this set,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 we outline how to construct this set,0
 the original version of the bubblesort implementation exposes the values within the array,1
 this makes it difficult to reason about what the model will do when given complex inputs,0
3,1
"
for addition, we analytically determine the verification set",1
 the environment and return probability are omitted for readability,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 u varies with the number of vertices in the graph,1
", an lstm in npi’s case, but possibly other networks in different cases",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
2,1
", the verification set",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
g,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
g,1
 recursion can be implemented differently for different neural programming models,0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
3,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" et+1 ∼ fenv(et, pt, at)",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
base cases and reduction rules for addition",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" for each length, we test each program on 30 randomly generated problems",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
to perform the verification as described here, it is critical to construct v correctly",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
3 to construct v and then empirically create a verification set which covers v ,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
3,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" that is to say, the network does not learn the true program semantics",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 the degree for any vertex in the dag is variable,1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
3 to construct v and then empirically create a verification set which covers v ,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 reset represents a −∞ value,1
" in all experiments, α is set to 0",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
3,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
bubble sort",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" as aforementioned, the npi model naturally supports recursion",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
quicksort",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 this algorithm is a variant of depth first search,1
", to change the value of phi) none described belowstack",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
 the first is the actual model architecture,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 the original version of the bubblesort implementation exposes the values within the array,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" on the other hand, the recursive programs have learned the true program semantics",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
", to change the value of vactive) none described below move move a pointer (e",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
this material is in part based upon work supported by the national science foundation under grant no,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
the three environment observations aid with control flow in algorithm 2",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
5,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"
training setup",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
we propose and describe our verification procedure",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" twc-1409915, darpa under grant no",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
grade-school addition",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" each time a subprogram is called, the stack depth increases",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
6,0
" in all experiments, α is set to 0",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
"
training setup",0
", the trace corresponding to the problem “109 + 101”)",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
2,1
" each time a subprogram is called, the stack depth increases",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
quicksort",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" as with the others, we apply the procedure described in section 3",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
quicksort",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
base cases and reduction rules for quicksort",1
 reset represents a −∞ value,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
g,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 ,1
"
we experiment with two levels of recursion—partial and full",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
", to color a vertex) or variable (e",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
g,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
"
move",1
" in particular, recursion can be implemented as a program calling itself",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
2,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
to perform the verification as described here, it is critical to construct v correctly",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" in future work, we seek to enable more tasks with recursive structure",0
" in future work, we seek to enable more tasks with recursive structure",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
", to change the value of vactive) none described below move move a pointer (e",0
", an array for quicksort or a dag for topological sort)",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in particular, recursion can be implemented as a program calling itself",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
3 to construct v and then empirically create a verification set which covers v ,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
e,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
move",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
 npi then outputs the return probability and next program and arguments to execute,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
2,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
grade school addition",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
", to change the value of phi) none described belowstack",0
 reset represents a −∞ value,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
", an lstm in npi’s case, but possibly other networks in different cases",1
 ,0
 the degree for any vertex in the dag is variable,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
", the verification set",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
3,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
g,1
", the trace corresponding to the array [3,2])",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 u varies with the number of vertices in the graph,0
 the environment and return probability are omitted for readability,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" as aforementioned, the npi model naturally supports recursion",1
g,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
g,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
 we choose to implement a topological sort task for graphs,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
g,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
g,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
to perform the verification as described here, it is critical to construct v correctly",1
 ,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
training setup",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
quicksort",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
bubble sort",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
g,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" as aforementioned, the npi model naturally supports recursion",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 ,0
 the original version of the bubblesort implementation exposes the values within the array,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
as in line 13 of the right-hand side of figure 1",0
"
move",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" in particular, recursion can be implemented as a program calling itself",1
 recursion can be implemented differently for different neural programming models,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 almost all architectures train on program input/output pairs,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
", to change the value of phi) none described belowstack",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
6,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
3 to construct v and then empirically create a verification set which covers v ,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
", the trace corresponding to the array [3,2])",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" lshift moves the four pointers to the left, to move to the next column",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
", the verification set",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 almost all architectures train on program input/output pairs,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" as aforementioned, the npi model naturally supports recursion",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" for each length, we test each program on 30 randomly generated problems",0
g,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" as aforementioned, the npi model naturally supports recursion",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" fa8750-15-2-0104, and berkeley deep drive",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" on the other hand, the recursive programs have learned the true program semantics",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
g,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 u varies with the number of vertices in the graph,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
g,0
this material is in part based upon work supported by the national science foundation under grant no,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 there is a (changing) list of neural programs used to accomplish a given task,1
 b1b0 where no carry operations occur,0
 the training set for addition contains 200 traces,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
6,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
 reset represents a −∞ value,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
", the trace corresponding to the array [3,2])",0
", the trace corresponding to the array [3,2])",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" in particular, recursion can be implemented as a program calling itself",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" in particular, recursion can be implemented as a program calling itself",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 the degree for any vertex in the dag is variable,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
", an lstm in npi’s case, but possibly other networks in different cases",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
move",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
g,1
"
move",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
for addition, we analytically determine the verification set",0
"
training setup",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 the environment and return probability are omitted for readability,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
3 to construct v and then empirically create a verification set which covers v ,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
g,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" each time a subprogram is called, the stack depth increases",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 the environment and return probability are omitted for readability,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
we now report on generalization for the varying tasks,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
grade school addition",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" as with the others, we apply the procedure described in section 3",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" however, our concept of recursion for neural programs is general",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 the training set for addition contains 200 traces,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
this material is in part based upon work supported by the national science foundation under grant no,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" , n , where the dag contains n vertices",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" et+1 ∼ fenv(et, pt, at)",1
" for each length, we test each program on 30 randomly generated problems",1
", to change the value of vactive) none described below move move a pointer (e",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
", to change the value of vactive) none described below move move a pointer (e",1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" we call this set of inputs the verification set, sv ",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" in this architecture, we consider a core controller, e",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
3,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
g,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
base cases and reduction rules for bubble sort",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
 ,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
3,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
e,1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
as mentioned in section 2,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 a1a0 + bnbn−1 ,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
we describe the details of the npi model relevant to our contributions",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
we propose and describe our verification procedure",0
", to change the value of phi) none described belowstack",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
 the first is the actual model architecture,1
g,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 almost all architectures train on program input/output pairs,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 the first is the actual model architecture,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
the three environment observations aid with control flow in algorithm 2",0
"
quicksort",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
 ,1
g,1
"
as in line 13 of the right-hand side of figure 1",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"
for addition, we analytically determine the verification set",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 the maximum problem length in this training set is 3 (e,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
g,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 ,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
 3: begin traversing from vertex 1 in the dag,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 the core controller acts as a dispatcher for the programs,0
g,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 the maximum problem length in this training set is 3 (e,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
e,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
 the original version of the bubblesort implementation exposes the values within the array,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 18: push lo and p− 1 to slo and shi,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" for each length, we test each program on 30 randomly generated problems",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" for each length, we test each program on 30 randomly generated problems",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
", an array for quicksort or a dag for topological sort)",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" that is to say, the network does not learn the true program semantics",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 the environment and return probability are omitted for readability,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
base cases and reduction rules for bubble sort",0
 this algorithm is a variant of depth first search,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 ,0
"
inside bubble and reset, there are two operations that can be made recursive",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 npi then outputs the return probability and next program and arguments to execute,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 the program terminates when seeing no numbers in the current column,0
 ,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 the first is the actual model architecture,0
 ,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 the maximum problem length in this training set is 3 (e,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" twc-1409915, darpa under grant no",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
", an lstm in npi’s case, but possibly other networks in different cases",1
 3: begin traversing from vertex 1 in the dag,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" et+1 ∼ fenv(et, pt, at)",1
"
base cases and reduction rules for topological sort",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
we now report on generalization for the varying tasks,1
"
bubble sort",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
", the trace corresponding to the array [3,2])",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
algorithm 2 shows the topological sort task of interest",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 our experiments use a small number of training examples,1
this material is in part based upon work supported by the national science foundation under grant no,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
", to change the value of phi) none described belowstack",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 ,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
g,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
base cases and reduction rules for quicksort",1
 indentation indicates the stack is one level deeper than before,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 the original version of the bubblesort implementation exposes the values within the array,0
"
base cases and reduction rules for addition",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"1; and for bubble sort, appendix a",1
" however, our concept of recursion for neural programs is general",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 we choose to implement a topological sort task for graphs,0
 this verification phase only needs to be performed once after training,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 b1b0 where no carry operations occur,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" we call this set of inputs the verification set, sv ",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 ,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" fa8750-15-2-0104, and berkeley deep drive",1
"1; and for bubble sort, appendix a",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
g,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
 our experiments use a small number of training examples,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
3 to construct v and then empirically create a verification set which covers v ,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
quicksort",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 ,0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 the training set for addition contains 200 traces,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 the training set for addition contains 200 traces,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
 we created a program set that reflects the semantics of algorithm 2,1
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 these pointers are referred to as bubble pointers,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 recursion can be implemented differently for different neural programming models,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
arg 2 (increment or decrement): up, down
swap",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
 our experiments use a small number of training examples,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" in future work, we seek to enable more tasks with recursive structure",1
" fa8750-15-2-0104, and berkeley deep drive",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
 the first is the actual model architecture,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 recursion enables provably perfect generalization,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
for addition, we analytically determine the verification set",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
topological sort",1
"
we experiment with two levels of recursion—partial and full",0
g,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
", to color a vertex) or variable (e",0
"
for addition, we analytically determine the verification set",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
we experiment with two levels of recursion—partial and full",1
 these pointers are referred to as bubble pointers,0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 indentation indicates the stack is one level deeper than before,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
we propose and describe our verification procedure",0
 ,0
 indentation indicates the stack is one level deeper than before,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
the three environment observations aid with control flow in algorithm 2",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" we call this set of inputs the verification set, sv ",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 18: push lo and p− 1 to slo and shi,1
 the environment and return probability are omitted for readability,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 we outline how to construct this set,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
g,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
g,1
" for each length, we test each program on 30 randomly generated problems",0
 the first is the actual model architecture,1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 ,0
" , a1a0 + b1b0} are added properly",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
training setup",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
", the trace corresponding to the array [3,2])",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
g,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
", the trace corresponding to the problem “109 + 101”)",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 the environment and return probability are omitted for readability,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" , a1a0 + b1b0} are added properly",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
training setup",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 reset represents a −∞ value,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
the npi accesses an external environment, q, which varies according to the task",1
"
topological sort",0
" in this architecture, we consider a core controller, e",0
"
grade school addition",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
base cases and reduction rules for quicksort",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
we experiment with two levels of recursion—partial and full",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" in all experiments, α is set to 0",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
as mentioned in section 2,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
we now report on generalization for the varying tasks,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" as with the others, we apply the procedure described in section 3",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" twc-1409915, darpa under grant no",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
5,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 our experiments use a small number of training examples,0
" , n , where the dag contains n vertices",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" lshift moves the four pointers to the left, to move to the next column",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" that is to say, the network does not learn the true program semantics",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
topological sort",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
 18: push lo and p− 1 to slo and shi,1
"
bubble sort",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
bubble sort",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 the environment and return probability are omitted for readability,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
g,0
 the training set for addition contains 200 traces,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
 npi then outputs the return probability and next program and arguments to execute,0
 18: push lo and p− 1 to slo and shi,1
 ,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 the maximum problem length in this training set is 3 (e,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 our experiments use a small number of training examples,1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 we choose to implement a topological sort task for graphs,0
" for each length, we test each program on 30 randomly generated problems",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 this algorithm is a variant of depth first search,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 3: begin traversing from vertex 1 in the dag,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
 ,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 the training set for addition contains 200 traces,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" in this architecture, we consider a core controller, e",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
 we found that changing the npi training traces is a simple way to enable this,1
"
base cases and reduction rules for topological sort",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
the npi accesses an external environment, q, which varies according to the task",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
g,0
"
move",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" that is to say, the network does not learn the true program semantics",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
 we choose to implement a topological sort task for graphs,1
 ,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
g,0
"
base cases and reduction rules for topological sort",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" , a1a0 + b1b0} are added properly",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
g,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
g,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
topological sort",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
3,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
3 to construct v and then empirically create a verification set which covers v ,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 we outline how to construct this set,0
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
", the trace corresponding to the problem “109 + 101”)",1
 ,0
" however, our concept of recursion for neural programs is general",0
 our experiments use a small number of training examples,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 the training set for addition contains 200 traces,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 the training set for addition contains 200 traces,0
"
for addition, we analytically determine the verification set",0
"
algorithm 2 shows the topological sort task of interest",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
3,0
" in future work, we seek to enable more tasks with recursive structure",1
 recursion can be implemented differently for different neural programming models,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
g,1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 the training set for addition contains 200 traces,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 18: push lo and p− 1 to slo and shi,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 ,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
", the trace corresponding to the problem “109 + 101”)",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
 this algorithm is a variant of depth first search,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 the first is the actual model architecture,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
we describe the details of the npi model relevant to our contributions",1
" for each length, we test each program on 30 randomly generated problems",0
" for each length, we test each program on 30 randomly generated problems",0
e,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 18: push lo and p− 1 to slo and shi,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
g,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
g,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 npi then outputs the return probability and next program and arguments to execute,1
 ,1
"
base cases and reduction rules for bubble sort",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
 we created a program set that reflects the semantics of algorithm 2,0
" for each length, we test each program on 30 randomly generated problems",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" for each length, we test each program on 30 randomly generated problems",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
", to color a vertex) or variable (e",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
 reset represents a −∞ value,0
"
inside bubble and reset, there are two operations that can be made recursive",0
", to change the value of phi) none described belowstack",0
as mentioned in section 2,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 npi then outputs the return probability and next program and arguments to execute,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 the core controller acts as a dispatcher for the programs,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
g,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
base cases and reduction rules for addition",1
g,0
 we adapt machinery from the original paper slightly to fit our needs,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" on the other hand, the recursive programs have learned the true program semantics",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 ,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
this material is in part based upon work supported by the national science foundation under grant no,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" each time a subprogram is called, the stack depth increases",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" twc-1409915, darpa under grant no",1
3 to construct v and then empirically create a verification set which covers v ,0
" for each length, we test each program on 30 randomly generated problems",1
", to change the value of vactive) none described below move move a pointer (e",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
e,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" in all experiments, α is set to 0",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
", the verification set",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" in this architecture, we consider a core controller, e",0
 we outline how to construct this set,1
 the first is the actual model architecture,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" on the other hand, the recursive programs have learned the true program semantics",1
e,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" that is to say, the network does not learn the true program semantics",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 ,0
 recursion can be implemented differently for different neural programming models,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
3,1
" et+1 ∼ fenv(et, pt, at)",1
 the original version of the bubblesort implementation exposes the values within the array,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
bubble sort",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"
inside bubble and reset, there are two operations that can be made recursive",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
