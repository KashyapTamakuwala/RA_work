Sentence,Status
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 ,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 this algorithm is a variant of depth first search,0
 u varies with the number of vertices in the graph,0
g,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" as with the others, we apply the procedure described in section 3",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
3,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
g,0
"
as in line 13 of the right-hand side of figure 1",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" in all experiments, α is set to 0",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
base cases and reduction rules for quicksort",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 this verification phase only needs to be performed once after training,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
", qstacklo or qstackhi) or to pointer (e",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
", an array for quicksort or a dag for topological sort)",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 these pointers are referred to as bubble pointers,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" however, our concept of recursion for neural programs is general",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
grade school addition",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
training setup",0
", an lstm in npi’s case, but possibly other networks in different cases",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
", to change the value of vactive) none described below move move a pointer (e",0
"
base cases and reduction rules for addition",1
" twc-1409915, darpa under grant no",1
" as with the others, we apply the procedure described in section 3",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
", an array for quicksort or a dag for topological sort)",0
 the core controller acts as a dispatcher for the programs,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
2,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" twc-1409915, darpa under grant no",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"1; and for bubble sort, appendix a",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 the training set for addition contains 200 traces,0
", pstart or childlist[vactive]) up or down none described belowwrite",0
3,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
2,1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
", qstacklo or qstackhi) or to pointer (e",0
 18: push lo and p− 1 to slo and shi,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" fa8750-15-2-0104, and berkeley deep drive",0
 the program terminates when seeing no numbers in the current column,1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" as with the others, we apply the procedure described in section 3",0
"
inside bubble and reset, there are two operations that can be made recursive",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
g,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" fa8750-15-2-0104, and berkeley deep drive",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 we choose to implement a topological sort task for graphs,0
" fa8750-15-2-0104, and berkeley deep drive",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 the program terminates when seeing no numbers in the current column,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
", the trace corresponding to the problem “109 + 101”)",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
"
we describe the details of the npi model relevant to our contributions",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
2,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
we now report on generalization for the varying tasks,0
 ,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 a1a0 + bnbn−1 ,0
 ,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
bubble sort",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
g,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
grade-school addition",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
bubble sort",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
5,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 indentation indicates the stack is one level deeper than before,1
 there is a (changing) list of neural programs used to accomplish a given task,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
", to change the value of vactive) none described below move move a pointer (e",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
as in line 13 of the right-hand side of figure 1",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
6,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" twc-1409915, darpa under grant no",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
the three environment observations aid with control flow in algorithm 2",0
 the core controller acts as a dispatcher for the programs,1
"
quicksort",0
" in this architecture, we consider a core controller, e",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 we created a program set that reflects the semantics of algorithm 2,1
3,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
", to change the value of vactive) none described below move move a pointer (e",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
2,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 ,1
 a1a0 + bnbn−1 ,1
g,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
", the trace corresponding to the problem “109 + 101”)",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
g,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" we call this set of inputs the verification set, sv ",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
 npi then outputs the return probability and next program and arguments to execute,1
" lshift moves the four pointers to the left, to move to the next column",0
"
base cases and reduction rules for bubble sort",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
g,0
", to color a vertex) or variable (e",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
3,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
g,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 the maximum problem length in this training set is 3 (e,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
algorithm 2 shows the topological sort task of interest",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 ,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 18: push lo and p− 1 to slo and shi,1
 ,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" et+1 ∼ fenv(et, pt, at)",0
 the degree for any vertex in the dag is variable,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" twc-1409915, darpa under grant no",0
"
move",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 we created a program set that reflects the semantics of algorithm 2,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
training setup",0
 the environment and return probability are omitted for readability,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
 the training set for addition contains 200 traces,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
", to color a vertex) or variable (e",1
" fa8750-15-2-0104, and berkeley deep drive",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 this algorithm is a variant of depth first search,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 18: push lo and p− 1 to slo and shi,1
" et+1 ∼ fenv(et, pt, at)",0
"
grade-school addition",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
the three environment observations aid with control flow in algorithm 2",1
 recursion can be implemented differently for different neural programming models,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
", the trace corresponding to the array [3,2])",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" as aforementioned, the npi model naturally supports recursion",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 ,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
quicksort",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" however, our concept of recursion for neural programs is general",1
 this verification phase only needs to be performed once after training,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
 ,1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
", to change the value of phi) none described belowstack",0
g,0
"
in this general neural programming architecture, we show it is easy to support recursion",1
 we adapt machinery from the original paper slightly to fit our needs,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
bubble sort",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 we found that changing the npi training traces is a simple way to enable this,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 the degree for any vertex in the dag is variable,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
quicksort",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
 ,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
2,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 ,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 u varies with the number of vertices in the graph,0
 indentation indicates the stack is one level deeper than before,0
 the maximum problem length in this training set is 3 (e,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" lshift moves the four pointers to the left, to move to the next column",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 18: push lo and p− 1 to slo and shi,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
algorithm 2 shows the topological sort task of interest",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
quicksort",1
 the original version of the bubblesort implementation exposes the values within the array,0
 the program terminates when seeing no numbers in the current column,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 ,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
3,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 ,0
 the environment and return probability are omitted for readability,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" in particular, recursion can be implemented as a program calling itself",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" each time a subprogram is called, the stack depth increases",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
inside bubble and reset, there are two operations that can be made recursive",0
", the trace corresponding to the problem “109 + 101”)",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" we call this set of inputs the verification set, sv ",0
 ,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 we choose to implement a topological sort task for graphs,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
", the trace corresponding to the array [3,2])",0
 a1a0 + bnbn−1 ,0
" et+1 ∼ fenv(et, pt, at)",1
", an array for quicksort or a dag for topological sort)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
bubble sort",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
", the trace corresponding to the array [3,2])",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
quicksort",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
we describe the details of the npi model relevant to our contributions",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
 the maximum problem length in this training set is 3 (e,1
 these pointers are referred to as bubble pointers,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
 the program terminates when seeing no numbers in the current column,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
we propose and describe our verification procedure",0
3,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 we created a program set that reflects the semantics of algorithm 2,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
this material is in part based upon work supported by the national science foundation under grant no,1
" for each length, we test each program on 30 randomly generated problems",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 18: push lo and p− 1 to slo and shi,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
g,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
this material is in part based upon work supported by the national science foundation under grant no,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
we propose and describe our verification procedure",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" for each length, we test each program on 30 randomly generated problems",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 these pointers are referred to as bubble pointers,0
" in future work, we seek to enable more tasks with recursive structure",1
" lshift moves the four pointers to the left, to move to the next column",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 this verification phase only needs to be performed once after training,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
e,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 a1a0 + bnbn−1 ,0
", to change the value of vactive) none described below move move a pointer (e",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 u varies with the number of vertices in the graph,0
 the first is the actual model architecture,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
 the first is the actual model architecture,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
bubble sort",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
g,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 recursion can be implemented differently for different neural programming models,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
we describe the details of the npi model relevant to our contributions",1
" , n , where the dag contains n vertices",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as with the others, we apply the procedure described in section 3",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
e,0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
", to change the value of phi) none described belowstack",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
move",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
 we choose to implement a topological sort task for graphs,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
quicksort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
"1; and for bubble sort, appendix a",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
g,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
", to change the value of phi) none described belowstack",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for each length, we test each program on 30 randomly generated problems",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" each time a subprogram is called, the stack depth increases",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
grade school addition",1
3 to construct v and then empirically create a verification set which covers v ,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 this algorithm is a variant of depth first search,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
for addition, we analytically determine the verification set",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 ,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
base cases and reduction rules for addition",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 the first is the actual model architecture,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
training setup",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" in this architecture, we consider a core controller, e",1
g,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
3,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" however, our concept of recursion for neural programs is general",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" twc-1409915, darpa under grant no",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 the first is the actual model architecture,0
"
as in line 13 of the right-hand side of figure 1",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 this verification phase only needs to be performed once after training,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
move",1
"
move",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" lshift moves the four pointers to the left, to move to the next column",0
" for each length, we test each program on 30 randomly generated problems",0
" on the other hand, the recursive programs have learned the true program semantics",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
move",1
this material is in part based upon work supported by the national science foundation under grant no,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
e,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 we choose to implement a topological sort task for graphs,0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
e,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 ,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
6,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" twc-1409915, darpa under grant no",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
6,0
 a1a0 + bnbn−1 ,1
e,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 our experiments use a small number of training examples,0
" however, our concept of recursion for neural programs is general",0
 ,0
"
inside bubble and reset, there are two operations that can be made recursive",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 a1a0 + bnbn−1 ,1
"
arg 2 (increment or decrement): up, down
swap",0
" we call this set of inputs the verification set, sv ",0
 we created a program set that reflects the semantics of algorithm 2,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 b1b0 where no carry operations occur,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 the environment and return probability are omitted for readability,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
 3: begin traversing from vertex 1 in the dag,1
", to color a vertex) or variable (e",1
" we call this set of inputs the verification set, sv ",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" however, our concept of recursion for neural programs is general",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" as aforementioned, the npi model naturally supports recursion",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
", qstacklo or qstackhi) or to pointer (e",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" that is to say, the network does not learn the true program semantics",0
" , a1a0 + b1b0} are added properly",0
 almost all architectures train on program input/output pairs,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 the first is the actual model architecture,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" that is to say, the network does not learn the true program semantics",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 the original version of the bubblesort implementation exposes the values within the array,1
"
bubble sort",1
"
for addition, we analytically determine the verification set",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 18: push lo and p− 1 to slo and shi,1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 this verification phase only needs to be performed once after training,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" each time a subprogram is called, the stack depth increases",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
training setup",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
bubble sort",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
 npi then outputs the return probability and next program and arguments to execute,0
" however, our concept of recursion for neural programs is general",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
2,1
", to color a vertex) or variable (e",0
"
bubble sort",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
g,1
 the first is the actual model architecture,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
", the verification set",1
"
we describe the details of the npi model relevant to our contributions",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
base cases and reduction rules for quicksort",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" , n , where the dag contains n vertices",1
" as aforementioned, the npi model naturally supports recursion",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
 recursion can be implemented differently for different neural programming models,1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
", to change the value of vactive) none described below move move a pointer (e",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
g,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 our experiments use a small number of training examples,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
base cases and reduction rules for quicksort",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
", the trace corresponding to the problem “109 + 101”)",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
g,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 almost all architectures train on program input/output pairs,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"
topological sort",0
g,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 ,1
 ,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 recursion enables provably perfect generalization,1
"
arg 2 (increment or decrement): up, down
swap",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
 there is a (changing) list of neural programs used to accomplish a given task,0
g,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
"
grade-school addition",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 the program terminates when seeing no numbers in the current column,1
" as with the others, we apply the procedure described in section 3",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"
topological sort",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
3,1
"
move",0
" twc-1409915, darpa under grant no",1
 ,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" each time a subprogram is called, the stack depth increases",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
 we choose to implement a topological sort task for graphs,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
g,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" lshift moves the four pointers to the left, to move to the next column",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 u varies with the number of vertices in the graph,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
", the trace corresponding to the problem “109 + 101”)",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 ,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
we now report on generalization for the varying tasks,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" for each length, we test each program on 30 randomly generated problems",0
"
we propose and describe our verification procedure",1
 ,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 3: begin traversing from vertex 1 in the dag,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
quicksort",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 recursion can be implemented differently for different neural programming models,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 the core controller acts as a dispatcher for the programs,0
"1; and for bubble sort, appendix a",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
grade-school addition",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
base cases and reduction rules for bubble sort",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
for addition, we analytically determine the verification set",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
as mentioned in section 2,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
", the verification set",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 reset represents a −∞ value,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 3: begin traversing from vertex 1 in the dag,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 b1b0 where no carry operations occur,0
e,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
quicksort",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
2,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
move",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 the core controller acts as a dispatcher for the programs,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
2,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" using this modification, we constructed a verification set consisting of one array of size 10",0
", the trace corresponding to the problem “109 + 101”)",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" , n , where the dag contains n vertices",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" as aforementioned, the npi model naturally supports recursion",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
we now report on generalization for the varying tasks,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 we adapt machinery from the original paper slightly to fit our needs,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
g,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
2,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" , a1a0 + b1b0} are added properly",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 we outline how to construct this set,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
5,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" as with the others, we apply the procedure described in section 3",1
2,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 ,0
 recursion enables provably perfect generalization,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
g,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
 the maximum problem length in this training set is 3 (e,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" lshift moves the four pointers to the left, to move to the next column",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
the three environment observations aid with control flow in algorithm 2",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" lshift moves the four pointers to the left, to move to the next column",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
for addition, we analytically determine the verification set",0
 recursion enables provably perfect generalization,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" we call this set of inputs the verification set, sv ",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
g,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
g,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
we experiment with two levels of recursion—partial and full",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
base cases and reduction rules for addition",0
g,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" , n , where the dag contains n vertices",1
" we call this set of inputs the verification set, sv ",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" for each length, we test each program on 30 randomly generated problems",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
for addition, we analytically determine the verification set",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
base cases and reduction rules for addition",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" , n , where the dag contains n vertices",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
 almost all architectures train on program input/output pairs,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
g,1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
", qstacklo or qstackhi) or to pointer (e",0
g,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
base cases and reduction rules for quicksort",0
" on the other hand, the recursive programs have learned the true program semantics",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
g,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
as mentioned in section 2,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
6,1
" each time a subprogram is called, the stack depth increases",0
", the trace corresponding to the problem “109 + 101”)",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
the npi accesses an external environment, q, which varies according to the task",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
 ,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
base cases and reduction rules for topological sort",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
to perform the verification as described here, it is critical to construct v correctly",1
 there is a (changing) list of neural programs used to accomplish a given task,0
"
the npi accesses an external environment, q, which varies according to the task",0
", the trace corresponding to the array [3,2])",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
3,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 3: begin traversing from vertex 1 in the dag,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 a1a0 + bnbn−1 ,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 this verification phase only needs to be performed once after training,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
arg 2 (increment or decrement): up, down
swap",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
3,0
", to color a vertex) or variable (e",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
", the trace corresponding to the array [3,2])",0
 ,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
we propose and describe our verification procedure",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
training setup",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
g,0
 we choose to implement a topological sort task for graphs,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
" however, our concept of recursion for neural programs is general",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
", to change the value of vactive) none described below move move a pointer (e",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 indentation indicates the stack is one level deeper than before,1
 we choose to implement a topological sort task for graphs,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 ,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" we call this set of inputs the verification set, sv ",1
 the maximum problem length in this training set is 3 (e,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 ,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
3,1
 ,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
quicksort",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" as with the others, we apply the procedure described in section 3",1
g,1
"
to perform the verification as described here, it is critical to construct v correctly",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 ,0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
6,1
", the trace corresponding to the problem “109 + 101”)",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 we created a program set that reflects the semantics of algorithm 2,1
"
base cases and reduction rules for topological sort",1
"
bubble sort",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
g,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
3,1
", to change the value of phi) none described belowstack",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 the degree for any vertex in the dag is variable,0
", an lstm in npi’s case, but possibly other networks in different cases",1
"
the three environment observations aid with control flow in algorithm 2",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
", an lstm in npi’s case, but possibly other networks in different cases",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
", the trace corresponding to the problem “109 + 101”)",1
", an array for quicksort or a dag for topological sort)",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
base cases and reduction rules for addition",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
quicksort",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 the training set for addition contains 200 traces,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 a1a0 + bnbn−1 ,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
g,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"1; and for bubble sort, appendix a",1
" in this architecture, we consider a core controller, e",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
we experiment with two levels of recursion—partial and full",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 ,1
g,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" that is to say, the network does not learn the true program semantics",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
3 to construct v and then empirically create a verification set which covers v ,0
 we choose to implement a topological sort task for graphs,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" as aforementioned, the npi model naturally supports recursion",1
 we outline how to construct this set,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
arg 2 (increment or decrement): up, down
swap",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
"
base cases and reduction rules for bubble sort",1
 the program terminates when seeing no numbers in the current column,1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 the maximum problem length in this training set is 3 (e,0
" , a1a0 + b1b0} are added properly",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 recursion can be implemented differently for different neural programming models,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" et+1 ∼ fenv(et, pt, at)",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
arg 2 (increment or decrement): up, down
swap",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
g,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
3,1
 we outline how to construct this set,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
grade-school addition",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
as in line 13 of the right-hand side of figure 1",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
 indentation indicates the stack is one level deeper than before,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
as in line 13 of the right-hand side of figure 1",1
" for each length, we test each program on 30 randomly generated problems",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" twc-1409915, darpa under grant no",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 indentation indicates the stack is one level deeper than before,0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 the program terminates when seeing no numbers in the current column,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" we call this set of inputs the verification set, sv ",0
", to color a vertex) or variable (e",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 npi then outputs the return probability and next program and arguments to execute,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" in particular, recursion can be implemented as a program calling itself",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" for each length, we test each program on 30 randomly generated problems",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 ,1
" fa8750-15-2-0104, and berkeley deep drive",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
for addition, we analytically determine the verification set",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
base cases and reduction rules for bubble sort",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
 the maximum problem length in this training set is 3 (e,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
the npi accesses an external environment, q, which varies according to the task",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 ,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
", the trace corresponding to the problem “109 + 101”)",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" in particular, recursion can be implemented as a program calling itself",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
we describe the details of the npi model relevant to our contributions",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 recursion enables provably perfect generalization,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
to perform the verification as described here, it is critical to construct v correctly",0
 the original version of the bubblesort implementation exposes the values within the array,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" et+1 ∼ fenv(et, pt, at)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
quicksort",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
", qstacklo or qstackhi) or to pointer (e",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 the first is the actual model architecture,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
grade-school addition",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" lshift moves the four pointers to the left, to move to the next column",1
"
bubble sort",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" in future work, we seek to enable more tasks with recursive structure",1
"
we propose and describe our verification procedure",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 this algorithm is a variant of depth first search,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
 we found that changing the npi training traces is a simple way to enable this,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
g,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 our experiments use a small number of training examples,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
g,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
as mentioned in section 2,1
", to change the value of vactive) none described below move move a pointer (e",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
base cases and reduction rules for quicksort",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" however, our concept of recursion for neural programs is general",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
quicksort",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
g,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
the npi accesses an external environment, q, which varies according to the task",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
the npi accesses an external environment, q, which varies according to the task",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 our experiments use a small number of training examples,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" in particular, recursion can be implemented as a program calling itself",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
we experiment with two levels of recursion—partial and full",1
 the first is the actual model architecture,0
g,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 this verification phase only needs to be performed once after training,0
" on the other hand, the recursive programs have learned the true program semantics",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
 the program terminates when seeing no numbers in the current column,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 the training set for addition contains 200 traces,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
 the original version of the bubblesort implementation exposes the values within the array,0
 there is a (changing) list of neural programs used to accomplish a given task,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
base cases and reduction rules for topological sort",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" that is to say, the network does not learn the true program semantics",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
3,0
2,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
this material is in part based upon work supported by the national science foundation under grant no,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
g,1
", the verification set",0
 ,0
3,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
", the trace corresponding to the array [3,2])",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
for addition, we analytically determine the verification set",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 ,0
we now report on generalization for the varying tasks,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" in this architecture, we consider a core controller, e",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 indentation indicates the stack is one level deeper than before,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" in all experiments, α is set to 0",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
base cases and reduction rules for addition",1
"
move",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
e,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" et+1 ∼ fenv(et, pt, at)",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
", to color a vertex) or variable (e",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
g,0
" in future work, we seek to enable more tasks with recursive structure",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"
base cases and reduction rules for topological sort",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
to perform the verification as described here, it is critical to construct v correctly",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
base cases and reduction rules for quicksort",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
as mentioned in section 2,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
 3: begin traversing from vertex 1 in the dag,1
"
base cases and reduction rules for bubble sort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
 the training set for addition contains 200 traces,1
", an lstm in npi’s case, but possibly other networks in different cases",1
"
we propose and describe our verification procedure",0
" we call this set of inputs the verification set, sv ",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 we choose to implement a topological sort task for graphs,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
as mentioned in section 2,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
 ,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 b1b0 where no carry operations occur,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 we found that changing the npi training traces is a simple way to enable this,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 reset represents a −∞ value,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 the core controller acts as a dispatcher for the programs,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
we describe the details of the npi model relevant to our contributions",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
5,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" that is to say, the network does not learn the true program semantics",1
g,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 recursion can be implemented differently for different neural programming models,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
 this verification phase only needs to be performed once after training,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" et+1 ∼ fenv(et, pt, at)",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
quicksort",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
 ,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 18: push lo and p− 1 to slo and shi,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
 the program terminates when seeing no numbers in the current column,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 the environment and return probability are omitted for readability,0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 3: begin traversing from vertex 1 in the dag,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
g,1
", an lstm in npi’s case, but possibly other networks in different cases",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
", the verification set",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
 ,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 the maximum problem length in this training set is 3 (e,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
3 to construct v and then empirically create a verification set which covers v ,1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 npi then outputs the return probability and next program and arguments to execute,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
base cases and reduction rules for topological sort",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
base cases and reduction rules for topological sort",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 we created a program set that reflects the semantics of algorithm 2,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"
grade-school addition",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
e,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 this algorithm is a variant of depth first search,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
"
the three environment observations aid with control flow in algorithm 2",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
bubble sort",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 b1b0 where no carry operations occur,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
we experiment with two levels of recursion—partial and full",0
" twc-1409915, darpa under grant no",0
 we found that changing the npi training traces is a simple way to enable this,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
grade school addition",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
base cases and reduction rules for quicksort",1
 these pointers are referred to as bubble pointers,0
" , n , where the dag contains n vertices",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 our experiments use a small number of training examples,0
" twc-1409915, darpa under grant no",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" lshift moves the four pointers to the left, to move to the next column",0
" as with the others, we apply the procedure described in section 3",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
e,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
", to change the value of vactive) none described below move move a pointer (e",1
", to color a vertex) or variable (e",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
", to color a vertex) or variable (e",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
", to color a vertex) or variable (e",0
g,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
e,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
quicksort",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
 this verification phase only needs to be performed once after training,0
 the maximum problem length in this training set is 3 (e,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
move",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" , a1a0 + b1b0} are added properly",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 ,0
", to change the value of vactive) none described below move move a pointer (e",0
g,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" as aforementioned, the npi model naturally supports recursion",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 npi then outputs the return probability and next program and arguments to execute,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
", to change the value of vactive) none described below move move a pointer (e",0
"
base cases and reduction rules for quicksort",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
6,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" as with the others, we apply the procedure described in section 3",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 ,0
"
we describe the details of the npi model relevant to our contributions",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
algorithm 2 shows the topological sort task of interest",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" , a1a0 + b1b0} are added properly",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 we created a program set that reflects the semantics of algorithm 2,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
 ,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
base cases and reduction rules for topological sort",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" in this architecture, we consider a core controller, e",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
g,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
grade school addition",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
grade-school addition",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
we experiment with two levels of recursion—partial and full",0
", the trace corresponding to the array [3,2])",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
move",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 ,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
g,1
g,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 ,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
algorithm 2 shows the topological sort task of interest",0
"
training setup",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
move",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
g,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
 npi then outputs the return probability and next program and arguments to execute,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 the original version of the bubblesort implementation exposes the values within the array,1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" that is to say, the network does not learn the true program semantics",1
 ,1
" in all experiments, α is set to 0",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
grade school addition",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
 the degree for any vertex in the dag is variable,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
", to color a vertex) or variable (e",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
5,0
"
algorithm 2 shows the topological sort task of interest",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
 the training set for addition contains 200 traces,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 the program terminates when seeing no numbers in the current column,0
 the original version of the bubblesort implementation exposes the values within the array,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" on the other hand, the recursive programs have learned the true program semantics",1
"
base cases and reduction rules for addition",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 we adapt machinery from the original paper slightly to fit our needs,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
topological sort",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
move",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
", the trace corresponding to the array [3,2])",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
", to color a vertex) or variable (e",0
" twc-1409915, darpa under grant no",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
e,0
" as with the others, we apply the procedure described in section 3",1
"
move",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 the training set for addition contains 200 traces,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 these pointers are referred to as bubble pointers,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
3 to construct v and then empirically create a verification set which covers v ,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" , a1a0 + b1b0} are added properly",0
3,0
" in this architecture, we consider a core controller, e",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
 ,1
"
base cases and reduction rules for topological sort",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 we adapt machinery from the original paper slightly to fit our needs,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" as aforementioned, the npi model naturally supports recursion",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 we choose to implement a topological sort task for graphs,1
 the core controller acts as a dispatcher for the programs,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
we propose and describe our verification procedure",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 this verification phase only needs to be performed once after training,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
we now report on generalization for the varying tasks,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
", the trace corresponding to the array [3,2])",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"
we describe the details of the npi model relevant to our contributions",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
g,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
for addition, we analytically determine the verification set",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" , n , where the dag contains n vertices",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
3,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
training setup",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
3,0
 ,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
base cases and reduction rules for bubble sort",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 we found that changing the npi training traces is a simple way to enable this,0
 recursion enables provably perfect generalization,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 the maximum problem length in this training set is 3 (e,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
g,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
", qstacklo or qstackhi) or to pointer (e",1
"
for addition, we analytically determine the verification set",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
e,0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
algorithm 2 shows the topological sort task of interest",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
arg 2 (increment or decrement): up, down
swap",1
e,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
g,1
" for each length, we test each program on 30 randomly generated problems",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 3: begin traversing from vertex 1 in the dag,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
grade-school addition",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
topological sort",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 3: begin traversing from vertex 1 in the dag,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
3 to construct v and then empirically create a verification set which covers v ,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 npi then outputs the return probability and next program and arguments to execute,0
 indentation indicates the stack is one level deeper than before,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 recursion enables provably perfect generalization,1
 almost all architectures train on program input/output pairs,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
 ,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 ,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 ,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
2,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
", an array for quicksort or a dag for topological sort)",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
e,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
g,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" for each length, we test each program on 30 randomly generated problems",0
"
quicksort",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" , a1a0 + b1b0} are added properly",0
"
we experiment with two levels of recursion—partial and full",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 ,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
", the verification set",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" that is to say, the network does not learn the true program semantics",0
e,1
 almost all architectures train on program input/output pairs,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
5,1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
3,1
"
the three environment observations aid with control flow in algorithm 2",1
"
bubble sort",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
the three environment observations aid with control flow in algorithm 2",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
 we created a program set that reflects the semantics of algorithm 2,0
 we choose to implement a topological sort task for graphs,1
 we outline how to construct this set,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 these pointers are referred to as bubble pointers,1
" twc-1409915, darpa under grant no",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
bubble sort",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
e,1
" we call this set of inputs the verification set, sv ",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
g,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" et+1 ∼ fenv(et, pt, at)",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
g,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
", to change the value of vactive) none described below move move a pointer (e",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 we outline how to construct this set,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" twc-1409915, darpa under grant no",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
bubble sort",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" that is to say, the network does not learn the true program semantics",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
algorithm 2 shows the topological sort task of interest",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
3 to construct v and then empirically create a verification set which covers v ,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
we propose and describe our verification procedure",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
in this general neural programming architecture, we show it is easy to support recursion",1
 the program terminates when seeing no numbers in the current column,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 ,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 b1b0 where no carry operations occur,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" et+1 ∼ fenv(et, pt, at)",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
", to change the value of vactive) none described below move move a pointer (e",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 npi then outputs the return probability and next program and arguments to execute,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
g,0
2,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 ,1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
the npi accesses an external environment, q, which varies according to the task",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 we found that changing the npi training traces is a simple way to enable this,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 ,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
2,1
 we adapt machinery from the original paper slightly to fit our needs,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
g,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 recursion can be implemented differently for different neural programming models,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
g,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" , a1a0 + b1b0} are added properly",0
e,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" for each length, we test each program on 30 randomly generated problems",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
g,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 the degree for any vertex in the dag is variable,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 18: push lo and p− 1 to slo and shi,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
g,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
we propose and describe our verification procedure",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" , a1a0 + b1b0} are added properly",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" as with the others, we apply the procedure described in section 3",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 almost all architectures train on program input/output pairs,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
 3: begin traversing from vertex 1 in the dag,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 ,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
the npi accesses an external environment, q, which varies according to the task",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
algorithm 2 shows the topological sort task of interest",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 almost all architectures train on program input/output pairs,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
g,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" however, our concept of recursion for neural programs is general",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 ,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
quicksort",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
 this algorithm is a variant of depth first search,1
3,0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 there is a (changing) list of neural programs used to accomplish a given task,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 a1a0 + bnbn−1 ,1
"
move",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 this verification phase only needs to be performed once after training,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" each time a subprogram is called, the stack depth increases",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
bubble sort",0
"
as in line 13 of the right-hand side of figure 1",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 our experiments use a small number of training examples,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
3,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 recursion enables provably perfect generalization,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
6,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
training setup",1
" for each length, we test each program on 30 randomly generated problems",1
", to color a vertex) or variable (e",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 the program terminates when seeing no numbers in the current column,1
 ,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" lshift moves the four pointers to the left, to move to the next column",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
topological sort",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
move",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 ,1
 ,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"
grade-school addition",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
we experiment with two levels of recursion—partial and full",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 ,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 reset represents a −∞ value,0
g,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
 the core controller acts as a dispatcher for the programs,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
6,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
quicksort",1
" in this architecture, we consider a core controller, e",0
" that is to say, the network does not learn the true program semantics",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
we propose and describe our verification procedure",0
 reset represents a −∞ value,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 recursion can be implemented differently for different neural programming models,1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 we created a program set that reflects the semantics of algorithm 2,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
 this verification phase only needs to be performed once after training,1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
 the training set for addition contains 200 traces,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
quicksort",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 these pointers are referred to as bubble pointers,1
"
we propose and describe our verification procedure",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 we created a program set that reflects the semantics of algorithm 2,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
 ,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" in particular, recursion can be implemented as a program calling itself",1
g,1
", the trace corresponding to the problem “109 + 101”)",0
g,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 3: begin traversing from vertex 1 in the dag,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
"
arg 2 (increment or decrement): up, down
swap",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 ,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
the npi accesses an external environment, q, which varies according to the task",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" et+1 ∼ fenv(et, pt, at)",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 this algorithm is a variant of depth first search,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
3 to construct v and then empirically create a verification set which covers v ,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
3,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 ,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 ,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" as aforementioned, the npi model naturally supports recursion",0
"
move",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
5,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
as mentioned in section 2,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
 reset represents a −∞ value,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 we found that changing the npi training traces is a simple way to enable this,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" as with the others, we apply the procedure described in section 3",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
", to color a vertex) or variable (e",1
 ,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
we now report on generalization for the varying tasks,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" in all experiments, α is set to 0",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 the degree for any vertex in the dag is variable,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" in future work, we seek to enable more tasks with recursive structure",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
g,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" , n , where the dag contains n vertices",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
", an array for quicksort or a dag for topological sort)",1
 ,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" in future work, we seek to enable more tasks with recursive structure",1
", the trace corresponding to the array [3,2])",1
g,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 ,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 the program terminates when seeing no numbers in the current column,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" fa8750-15-2-0104, and berkeley deep drive",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
quicksort",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
move",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" that is to say, the network does not learn the true program semantics",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
quicksort",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
3,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" for each length, we test each program on 30 randomly generated problems",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 these pointers are referred to as bubble pointers,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 ,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
3,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
e,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
2,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 a1a0 + bnbn−1 ,0
"
bubble sort",0
g,0
 these pointers are referred to as bubble pointers,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 ,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 ,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"
algorithm 2 shows the topological sort task of interest",1
" in future work, we seek to enable more tasks with recursive structure",0
"
base cases and reduction rules for quicksort",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 almost all architectures train on program input/output pairs,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" on the other hand, the recursive programs have learned the true program semantics",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
g,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
we now report on generalization for the varying tasks,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"
quicksort",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
base cases and reduction rules for quicksort",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 there is a (changing) list of neural programs used to accomplish a given task,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" lshift moves the four pointers to the left, to move to the next column",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 the training set for addition contains 200 traces,0
" , n , where the dag contains n vertices",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
 the first is the actual model architecture,1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
we describe the details of the npi model relevant to our contributions",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
move",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
 u varies with the number of vertices in the graph,1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
", the verification set",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" on the other hand, the recursive programs have learned the true program semantics",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 the first is the actual model architecture,1
"
the non-recursive trace loops on cycles of add1 and lshift",1
 we adapt machinery from the original paper slightly to fit our needs,0
 this algorithm is a variant of depth first search,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
", to change the value of phi) none described belowstack",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
training setup",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
", the verification set",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 ,0
we now report on generalization for the varying tasks,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
as mentioned in section 2,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
g,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
3,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
bubble sort",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 ,0
"
arg 2 (increment or decrement): up, down
swap",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
3,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" we call this set of inputs the verification set, sv ",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 we found that changing the npi training traces is a simple way to enable this,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
g,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
g,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
5,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
 our experiments use a small number of training examples,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
this material is in part based upon work supported by the national science foundation under grant no,0
"
base cases and reduction rules for addition",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 npi then outputs the return probability and next program and arguments to execute,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
", an array for quicksort or a dag for topological sort)",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
arg 2 (increment or decrement): up, down
swap",0
" et+1 ∼ fenv(et, pt, at)",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 recursion enables provably perfect generalization,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" , n , where the dag contains n vertices",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" lshift moves the four pointers to the left, to move to the next column",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
training setup",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
g,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
e,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
"
move",0
g,0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 ,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
base cases and reduction rules for bubble sort",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
e,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 ,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
g,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"
for addition, we analytically determine the verification set",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" , a1a0 + b1b0} are added properly",1
 indentation indicates the stack is one level deeper than before,0
", an lstm in npi’s case, but possibly other networks in different cases",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 the core controller acts as a dispatcher for the programs,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 the training set for addition contains 200 traces,0
 a1a0 + bnbn−1 ,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 we adapt machinery from the original paper slightly to fit our needs,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 the original version of the bubblesort implementation exposes the values within the array,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 our experiments use a small number of training examples,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
 the training set for addition contains 200 traces,0
", an array for quicksort or a dag for topological sort)",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
g,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 the training set for addition contains 200 traces,0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
grade-school addition",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 indentation indicates the stack is one level deeper than before,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 npi then outputs the return probability and next program and arguments to execute,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
e,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" for each length, we test each program on 30 randomly generated problems",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
we propose and describe our verification procedure",1
 we outline how to construct this set,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 b1b0 where no carry operations occur,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 our experiments use a small number of training examples,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
3,1
e,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
g,0
as mentioned in section 2,0
" as with the others, we apply the procedure described in section 3",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" that is to say, the network does not learn the true program semantics",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" on the other hand, the recursive programs have learned the true program semantics",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
topological sort",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" fa8750-15-2-0104, and berkeley deep drive",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 the core controller acts as a dispatcher for the programs,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
", the trace corresponding to the array [3,2])",0
"
for addition, we analytically determine the verification set",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 the degree for any vertex in the dag is variable,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 ,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
move",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 we created a program set that reflects the semantics of algorithm 2,0
 the original version of the bubblesort implementation exposes the values within the array,0
g,0
"
the npi accesses an external environment, q, which varies according to the task",0
"
the three environment observations aid with control flow in algorithm 2",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
3,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
", the trace corresponding to the array [3,2])",1
" in all experiments, α is set to 0",1
 ,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
topological sort",0
"
bubble sort",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
arg 2 (increment or decrement): up, down
swap",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
e,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 u varies with the number of vertices in the graph,0
" et+1 ∼ fenv(et, pt, at)",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
g,1
"
training setup",0
"
the npi accesses an external environment, q, which varies according to the task",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
e,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 b1b0 where no carry operations occur,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
g,0
" in this architecture, we consider a core controller, e",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
5,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" in future work, we seek to enable more tasks with recursive structure",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
 recursion enables provably perfect generalization,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"1; and for bubble sort, appendix a",0
 these pointers are referred to as bubble pointers,0
 this makes it difficult to reason about what the model will do when given complex inputs,0
 the first is the actual model architecture,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"
we describe the details of the npi model relevant to our contributions",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
base cases and reduction rules for addition",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
the npi accesses an external environment, q, which varies according to the task",0
"
base cases and reduction rules for quicksort",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
base cases and reduction rules for topological sort",1
 we adapt machinery from the original paper slightly to fit our needs,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
quicksort",0
 ,1
 we outline how to construct this set,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
training setup",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 the degree for any vertex in the dag is variable,0
 ,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
6,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 3: begin traversing from vertex 1 in the dag,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"
bubble sort",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
 the degree for any vertex in the dag is variable,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
g,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" as aforementioned, the npi model naturally supports recursion",0
 recursion can be implemented differently for different neural programming models,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 the original version of the bubblesort implementation exposes the values within the array,1
", to color a vertex) or variable (e",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 we outline how to construct this set,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
for addition, we analytically determine the verification set",1
 u varies with the number of vertices in the graph,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
"
base cases and reduction rules for bubble sort",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 the original version of the bubblesort implementation exposes the values within the array,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
the three environment observations aid with control flow in algorithm 2",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" that is to say, the network does not learn the true program semantics",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
we now report on generalization for the varying tasks,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 ,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 we adapt machinery from the original paper slightly to fit our needs,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
 ,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
g,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 ,1
this material is in part based upon work supported by the national science foundation under grant no,0
3,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
arg 2 (increment or decrement): up, down
swap",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" as aforementioned, the npi model naturally supports recursion",0
g,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
g,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
e,0
 we found that changing the npi training traces is a simple way to enable this,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
training setup",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
 our experiments use a small number of training examples,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 reset represents a −∞ value,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" , a1a0 + b1b0} are added properly",1
"
algorithm 2 shows the topological sort task of interest",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
we propose and describe our verification procedure",1
", qstacklo or qstackhi) or to pointer (e",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" in all experiments, α is set to 0",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
", to color a vertex) or variable (e",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
base cases and reduction rules for topological sort",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 almost all architectures train on program input/output pairs,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
to perform the verification as described here, it is critical to construct v correctly",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" as aforementioned, the npi model naturally supports recursion",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
move",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" for each length, we test each program on 30 randomly generated problems",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 we outline how to construct this set,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 ,1
"
arg 2 (increment or decrement): up, down
swap",1
" as aforementioned, the npi model naturally supports recursion",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 ,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
", to change the value of phi) none described belowstack",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" et+1 ∼ fenv(et, pt, at)",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
inside bubble and reset, there are two operations that can be made recursive",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" in all experiments, α is set to 0",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
g,1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 ,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
", qstacklo or qstackhi) or to pointer (e",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" fa8750-15-2-0104, and berkeley deep drive",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 the original version of the bubblesort implementation exposes the values within the array,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
the npi accesses an external environment, q, which varies according to the task",0
"
the npi accesses an external environment, q, which varies according to the task",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
grade-school addition",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 ,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 the program terminates when seeing no numbers in the current column,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" lshift moves the four pointers to the left, to move to the next column",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
"
for addition, we analytically determine the verification set",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 ,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
 ,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
we experiment with two levels of recursion—partial and full",0
" as aforementioned, the npi model naturally supports recursion",1
", to change the value of phi) none described belowstack",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
g,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 indentation indicates the stack is one level deeper than before,1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 the degree for any vertex in the dag is variable,0
"
move",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 ,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 18: push lo and p− 1 to slo and shi,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
 3: begin traversing from vertex 1 in the dag,0
g,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"
quicksort",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" twc-1409915, darpa under grant no",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 ,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
quicksort",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
 the original version of the bubblesort implementation exposes the values within the array,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" for each length, we test each program on 30 randomly generated problems",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
", to change the value of vactive) none described below move move a pointer (e",1
"
the npi accesses an external environment, q, which varies according to the task",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 b1b0 where no carry operations occur,0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
", the trace corresponding to the problem “109 + 101”)",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"
for addition, we analytically determine the verification set",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
 the core controller acts as a dispatcher for the programs,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 the maximum problem length in this training set is 3 (e,1
"
base cases and reduction rules for topological sort",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 indentation indicates the stack is one level deeper than before,1
 u varies with the number of vertices in the graph,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 these pointers are referred to as bubble pointers,0
g,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
g,0
 18: push lo and p− 1 to slo and shi,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" in future work, we seek to enable more tasks with recursive structure",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 a1a0 + bnbn−1 ,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 the first is the actual model architecture,0
 ,0
" lshift moves the four pointers to the left, to move to the next column",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
6,0
", to color a vertex) or variable (e",1
g,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 our experiments use a small number of training examples,1
"
we propose and describe our verification procedure",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 18: push lo and p− 1 to slo and shi,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 3: begin traversing from vertex 1 in the dag,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
g,1
"
the three environment observations aid with control flow in algorithm 2",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" lshift moves the four pointers to the left, to move to the next column",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" , a1a0 + b1b0} are added properly",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
g,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
base cases and reduction rules for addition",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" however, our concept of recursion for neural programs is general",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 u varies with the number of vertices in the graph,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
2,1
 almost all architectures train on program input/output pairs,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" twc-1409915, darpa under grant no",1
", to color a vertex) or variable (e",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
", to change the value of phi) none described belowstack",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
as mentioned in section 2,0
"
to perform the verification as described here, it is critical to construct v correctly",1
 the degree for any vertex in the dag is variable,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 recursion can be implemented differently for different neural programming models,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 b1b0 where no carry operations occur,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
6,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 ,0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
", qstacklo or qstackhi) or to pointer (e",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" lshift moves the four pointers to the left, to move to the next column",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
g,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
", the trace corresponding to the problem “109 + 101”)",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" as aforementioned, the npi model naturally supports recursion",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" that is to say, the network does not learn the true program semantics",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 ,1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
grade-school addition",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
the three environment observations aid with control flow in algorithm 2",0
" each time a subprogram is called, the stack depth increases",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
 the training set for addition contains 200 traces,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 the original version of the bubblesort implementation exposes the values within the array,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 ,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" in future work, we seek to enable more tasks with recursive structure",0
", the trace corresponding to the array [3,2])",0
3,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
g,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 npi then outputs the return probability and next program and arguments to execute,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" on the other hand, the recursive programs have learned the true program semantics",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 the original version of the bubblesort implementation exposes the values within the array,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
", an lstm in npi’s case, but possibly other networks in different cases",0
g,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" for each length, we test each program on 30 randomly generated problems",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 we found that changing the npi training traces is a simple way to enable this,1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
6,1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" , n , where the dag contains n vertices",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 this verification phase only needs to be performed once after training,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
training setup",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
3 to construct v and then empirically create a verification set which covers v ,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
 the training set for addition contains 200 traces,1
 ,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
g,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
", the verification set",0
"
grade school addition",1
 b1b0 where no carry operations occur,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"1; and for bubble sort, appendix a",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 b1b0 where no carry operations occur,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 a1a0 + bnbn−1 ,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 ,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
 18: push lo and p− 1 to slo and shi,1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" twc-1409915, darpa under grant no",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" twc-1409915, darpa under grant no",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
", the trace corresponding to the problem “109 + 101”)",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
as mentioned in section 2,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" each time a subprogram is called, the stack depth increases",1
"
the three environment observations aid with control flow in algorithm 2",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
", an lstm in npi’s case, but possibly other networks in different cases",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,0
" however, our concept of recursion for neural programs is general",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 the program terminates when seeing no numbers in the current column,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
"
base cases and reduction rules for bubble sort",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
the three environment observations aid with control flow in algorithm 2",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
we now report on generalization for the varying tasks,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
base cases and reduction rules for bubble sort",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" et+1 ∼ fenv(et, pt, at)",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
quicksort",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
g,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
g,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" each time a subprogram is called, the stack depth increases",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"
as in line 13 of the right-hand side of figure 1",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
3,0
 indentation indicates the stack is one level deeper than before,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" in particular, recursion can be implemented as a program calling itself",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 the original version of the bubblesort implementation exposes the values within the array,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
2,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
", an array for quicksort or a dag for topological sort)",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
"
as in line 13 of the right-hand side of figure 1",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
3 to construct v and then empirically create a verification set which covers v ,0
g,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" in all experiments, α is set to 0",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
3,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 indentation indicates the stack is one level deeper than before,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
g,0
 the maximum problem length in this training set is 3 (e,1
" twc-1409915, darpa under grant no",1
 u varies with the number of vertices in the graph,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 recursion enables provably perfect generalization,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
g,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
g,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" for each length, we test each program on 30 randomly generated problems",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 these pointers are referred to as bubble pointers,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" each time a subprogram is called, the stack depth increases",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" in all experiments, α is set to 0",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
 the maximum problem length in this training set is 3 (e,0
3,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
move",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
 npi then outputs the return probability and next program and arguments to execute,0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
move",0
g,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
we propose and describe our verification procedure",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" on the other hand, the recursive programs have learned the true program semantics",1
"
bubble sort",0
 our experiments use a small number of training examples,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
move",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" fa8750-15-2-0104, and berkeley deep drive",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
as in line 13 of the right-hand side of figure 1",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
e,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 recursion enables provably perfect generalization,0
g,0
" for each length, we test each program on 30 randomly generated problems",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" , a1a0 + b1b0} are added properly",0
" we call this set of inputs the verification set, sv ",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 we choose to implement a topological sort task for graphs,0
3,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
2,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" , n , where the dag contains n vertices",1
 the maximum problem length in this training set is 3 (e,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 reset represents a −∞ value,0
g,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
we now report on generalization for the varying tasks,1
 ,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
g,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
base cases and reduction rules for addition",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
we propose and describe our verification procedure",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
", to change the value of vactive) none described below move move a pointer (e",0
" however, our concept of recursion for neural programs is general",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
base cases and reduction rules for bubble sort",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
training setup",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" fa8750-15-2-0104, and berkeley deep drive",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" for each length, we test each program on 30 randomly generated problems",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 b1b0 where no carry operations occur,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 the training set for addition contains 200 traces,0
3 to construct v and then empirically create a verification set which covers v ,1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
3,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" as aforementioned, the npi model naturally supports recursion",1
", an lstm in npi’s case, but possibly other networks in different cases",0
 we found that changing the npi training traces is a simple way to enable this,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
g,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" fa8750-15-2-0104, and berkeley deep drive",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" each time a subprogram is called, the stack depth increases",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
move",1
5,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
as mentioned in section 2,0
g,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 ,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
 a1a0 + bnbn−1 ,0
 ,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
quicksort",0
 the first is the actual model architecture,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" each time a subprogram is called, the stack depth increases",0
" in particular, recursion can be implemented as a program calling itself",0
" in all experiments, α is set to 0",1
we now report on generalization for the varying tasks,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
we now report on generalization for the varying tasks,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" , n , where the dag contains n vertices",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
g,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 ,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
g,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
"
grade school addition",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" for each length, we test each program on 30 randomly generated problems",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
"
we propose and describe our verification procedure",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
", an array for quicksort or a dag for topological sort)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
g,1
"
we propose and describe our verification procedure",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
g,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 we choose to implement a topological sort task for graphs,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
base cases and reduction rules for topological sort",1
", qstacklo or qstackhi) or to pointer (e",1
" in all experiments, α is set to 0",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"
training setup",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" on the other hand, the recursive programs have learned the true program semantics",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
5,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
algorithm 2 shows the topological sort task of interest",0
"
base cases and reduction rules for topological sort",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
3,0
"
quicksort",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
3,0
"
quicksort",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
", the trace corresponding to the array [3,2])",1
", to change the value of vactive) none described below move move a pointer (e",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
grade-school addition",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 these pointers are referred to as bubble pointers,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 indentation indicates the stack is one level deeper than before,0
 ,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
2,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 the environment and return probability are omitted for readability,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
move",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
g,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
5,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
e,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
 the program terminates when seeing no numbers in the current column,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 3: begin traversing from vertex 1 in the dag,0
" in particular, recursion can be implemented as a program calling itself",0
 the first is the actual model architecture,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 the environment and return probability are omitted for readability,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" on the other hand, the recursive programs have learned the true program semantics",0
"
the three environment observations aid with control flow in algorithm 2",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
"1; and for bubble sort, appendix a",1
", to change the value of vactive) none described below move move a pointer (e",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
3,1
 the core controller acts as a dispatcher for the programs,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
6,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
g,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
bubble sort",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
 ,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 ,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
g,1
" , n , where the dag contains n vertices",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
3,1
 indentation indicates the stack is one level deeper than before,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
", qstacklo or qstackhi) or to pointer (e",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" each time a subprogram is called, the stack depth increases",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 a1a0 + bnbn−1 ,1
"
algorithm 2 shows the topological sort task of interest",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" in all experiments, α is set to 0",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
", to change the value of vactive) none described below move move a pointer (e",1
"
move",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" each time a subprogram is called, the stack depth increases",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
 the maximum problem length in this training set is 3 (e,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 ,0
"
bubble sort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 the original version of the bubblesort implementation exposes the values within the array,0
", the trace corresponding to the array [3,2])",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" on the other hand, the recursive programs have learned the true program semantics",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
bubble sort",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
quicksort",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 we outline how to construct this set,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
move",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 reset represents a −∞ value,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 u varies with the number of vertices in the graph,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" in particular, recursion can be implemented as a program calling itself",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
quicksort",0
" et+1 ∼ fenv(et, pt, at)",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 the first is the actual model architecture,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
this material is in part based upon work supported by the national science foundation under grant no,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 the training set for addition contains 200 traces,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
g,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 the maximum problem length in this training set is 3 (e,1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 reset represents a −∞ value,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
 the first is the actual model architecture,1
 recursion can be implemented differently for different neural programming models,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
grade school addition",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 recursion enables provably perfect generalization,1
"
the npi accesses an external environment, q, which varies according to the task",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
base cases and reduction rules for topological sort",0
this material is in part based upon work supported by the national science foundation under grant no,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
move",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 recursion can be implemented differently for different neural programming models,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"
move",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
bubble sort",0
"
training setup",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
", to change the value of vactive) none described below move move a pointer (e",0
" lshift moves the four pointers to the left, to move to the next column",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
3,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
move",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 ,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
2,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
", qstacklo or qstackhi) or to pointer (e",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" et+1 ∼ fenv(et, pt, at)",1
 ,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
topological sort",0
"
base cases and reduction rules for topological sort",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" we call this set of inputs the verification set, sv ",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" for each length, we test each program on 30 randomly generated problems",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
the three environment observations aid with control flow in algorithm 2",0
 ,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
"
as in line 13 of the right-hand side of figure 1",0
 the core controller acts as a dispatcher for the programs,0
 this algorithm is a variant of depth first search,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"1; and for bubble sort, appendix a",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"
base cases and reduction rules for addition",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
 recursion enables provably perfect generalization,0
g,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
as mentioned in section 2,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
g,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
arg 2 (increment or decrement): up, down
swap",1
"
base cases and reduction rules for quicksort",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
base cases and reduction rules for bubble sort",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 recursion enables provably perfect generalization,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
this material is in part based upon work supported by the national science foundation under grant no,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" for each length, we test each program on 30 randomly generated problems",1
" we call this set of inputs the verification set, sv ",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
e,0
" in all experiments, α is set to 0",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 ,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
 the first is the actual model architecture,1
 we adapt machinery from the original paper slightly to fit our needs,1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 u varies with the number of vertices in the graph,0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
quicksort",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
we propose and describe our verification procedure",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
quicksort",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" in all experiments, α is set to 0",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 ,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" , n , where the dag contains n vertices",0
", to change the value of phi) none described belowstack",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
6,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
 this verification phase only needs to be performed once after training,0
 ,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" as with the others, we apply the procedure described in section 3",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"1; and for bubble sort, appendix a",0
e,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
", an lstm in npi’s case, but possibly other networks in different cases",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" in particular, recursion can be implemented as a program calling itself",1
" , n , where the dag contains n vertices",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
as mentioned in section 2,1
", to change the value of phi) none described belowstack",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" as aforementioned, the npi model naturally supports recursion",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
g,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
 the program terminates when seeing no numbers in the current column,1
"
base cases and reduction rules for quicksort",0
"
arg 2 (increment or decrement): up, down
swap",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
g,1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
", the trace corresponding to the array [3,2])",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 this verification phase only needs to be performed once after training,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
", the trace corresponding to the problem “109 + 101”)",1
g,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 there is a (changing) list of neural programs used to accomplish a given task,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" as aforementioned, the npi model naturally supports recursion",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
as in line 13 of the right-hand side of figure 1",0
g,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
g,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
", qstacklo or qstackhi) or to pointer (e",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 ,1
" using this modification, we constructed a verification set consisting of one array of size 10",0
", an array for quicksort or a dag for topological sort)",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
3 to construct v and then empirically create a verification set which covers v ,1
 ,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 we outline how to construct this set,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 this algorithm is a variant of depth first search,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 our experiments use a small number of training examples,0
 this algorithm is a variant of depth first search,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" in all experiments, α is set to 0",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
 we choose to implement a topological sort task for graphs,0
" twc-1409915, darpa under grant no",1
2,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
base cases and reduction rules for bubble sort",1
"
quicksort",0
 there is a (changing) list of neural programs used to accomplish a given task,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
 we found that changing the npi training traces is a simple way to enable this,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
 b1b0 where no carry operations occur,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 the degree for any vertex in the dag is variable,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 ,0
g,0
"
bubble sort",0
 recursion enables provably perfect generalization,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
"
as in line 13 of the right-hand side of figure 1",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" in future work, we seek to enable more tasks with recursive structure",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
g,0
 almost all architectures train on program input/output pairs,0
" that is to say, the network does not learn the true program semantics",0
 a1a0 + bnbn−1 ,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
to perform the verification as described here, it is critical to construct v correctly",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
 there is a (changing) list of neural programs used to accomplish a given task,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
base cases and reduction rules for quicksort",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 u varies with the number of vertices in the graph,0
" in all experiments, α is set to 0",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 the training set for addition contains 200 traces,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
6,1
"
move",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
topological sort",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 our experiments use a small number of training examples,0
" in all experiments, α is set to 0",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
 recursion enables provably perfect generalization,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
 ,1
 reset represents a −∞ value,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
we experiment with two levels of recursion—partial and full",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
", qstacklo or qstackhi) or to pointer (e",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 recursion enables provably perfect generalization,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 ,0
", the trace corresponding to the problem “109 + 101”)",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 the training set for addition contains 200 traces,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" , a1a0 + b1b0} are added properly",0
"
arg 2 (increment or decrement): up, down
swap",0
"1; and for bubble sort, appendix a",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" , n , where the dag contains n vertices",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 recursion enables provably perfect generalization,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" in particular, recursion can be implemented as a program calling itself",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
move",1
", an array for quicksort or a dag for topological sort)",0
6,0
 ,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" in future work, we seek to enable more tasks with recursive structure",1
" we call this set of inputs the verification set, sv ",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" in this architecture, we consider a core controller, e",1
 npi then outputs the return probability and next program and arguments to execute,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" for each length, we test each program on 30 randomly generated problems",1
2,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 u varies with the number of vertices in the graph,0
 ,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 the environment and return probability are omitted for readability,0
" , a1a0 + b1b0} are added properly",1
 these pointers are referred to as bubble pointers,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"
grade school addition",0
 ,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
3,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
 the environment and return probability are omitted for readability,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
 u varies with the number of vertices in the graph,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 the degree for any vertex in the dag is variable,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
this material is in part based upon work supported by the national science foundation under grant no,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 we outline how to construct this set,0
5,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
for addition, we analytically determine the verification set",1
 these pointers are referred to as bubble pointers,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
arg 2 (increment or decrement): up, down
swap",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
", to change the value of vactive) none described below move move a pointer (e",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
g,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
 ,0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" in particular, recursion can be implemented as a program calling itself",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
", the trace corresponding to the array [3,2])",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 ,1
" in all experiments, α is set to 0",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
", to color a vertex) or variable (e",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 the maximum problem length in this training set is 3 (e,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
this material is in part based upon work supported by the national science foundation under grant no,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
", the trace corresponding to the problem “109 + 101”)",1
 ,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" lshift moves the four pointers to the left, to move to the next column",1
", qstacklo or qstackhi) or to pointer (e",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" in particular, recursion can be implemented as a program calling itself",0
 this algorithm is a variant of depth first search,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
 this algorithm is a variant of depth first search,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
 we choose to implement a topological sort task for graphs,0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
the three environment observations aid with control flow in algorithm 2",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
g,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 these pointers are referred to as bubble pointers,0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
", to change the value of phi) none described belowstack",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
", to change the value of phi) none described belowstack",0
" as with the others, we apply the procedure described in section 3",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
g,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
as mentioned in section 2,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
this material is in part based upon work supported by the national science foundation under grant no,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
3 to construct v and then empirically create a verification set which covers v ,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" as with the others, we apply the procedure described in section 3",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" in this architecture, we consider a core controller, e",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
grade-school addition",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 this algorithm is a variant of depth first search,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 18: push lo and p− 1 to slo and shi,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
3,0
", the trace corresponding to the problem “109 + 101”)",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
g,0
" on the other hand, the recursive programs have learned the true program semantics",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
arg 2 (increment or decrement): up, down
swap",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 our experiments use a small number of training examples,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
bubble sort",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" we call this set of inputs the verification set, sv ",0
" as aforementioned, the npi model naturally supports recursion",0
", to change the value of phi) none described belowstack",0
 reset represents a −∞ value,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
", qstacklo or qstackhi) or to pointer (e",0
"
grade school addition",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" , n , where the dag contains n vertices",1
3 to construct v and then empirically create a verification set which covers v ,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
 the core controller acts as a dispatcher for the programs,1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 we choose to implement a topological sort task for graphs,1
e,1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 we found that changing the npi training traces is a simple way to enable this,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" , n , where the dag contains n vertices",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
g,1
 the first is the actual model architecture,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" twc-1409915, darpa under grant no",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 this algorithm is a variant of depth first search,1
" , a1a0 + b1b0} are added properly",0
", qstacklo or qstackhi) or to pointer (e",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
 these pointers are referred to as bubble pointers,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
e,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
3 to construct v and then empirically create a verification set which covers v ,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
topological sort",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
", the trace corresponding to the problem “109 + 101”)",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 we created a program set that reflects the semantics of algorithm 2,1
 almost all architectures train on program input/output pairs,1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
training setup",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" in this architecture, we consider a core controller, e",0
 the training set for addition contains 200 traces,1
", to change the value of phi) none described belowstack",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" in particular, recursion can be implemented as a program calling itself",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 ,1
"
we describe the details of the npi model relevant to our contributions",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
3 to construct v and then empirically create a verification set which covers v ,1
g,1
 we found that changing the npi training traces is a simple way to enable this,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" twc-1409915, darpa under grant no",0
 npi then outputs the return probability and next program and arguments to execute,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 ,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
", the trace corresponding to the problem “109 + 101”)",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" for each length, we test each program on 30 randomly generated problems",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 the core controller acts as a dispatcher for the programs,0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 b1b0 where no carry operations occur,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
arg 2 (increment or decrement): up, down
swap",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 the core controller acts as a dispatcher for the programs,0
" each time a subprogram is called, the stack depth increases",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" , a1a0 + b1b0} are added properly",1
"
quicksort",0
g,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 ,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
arg 2 (increment or decrement): up, down
swap",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the core controller acts as a dispatcher for the programs,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
", to change the value of phi) none described belowstack",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
 we outline how to construct this set,1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
6,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
bubble sort",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
topological sort",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
g,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
g,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 the original version of the bubblesort implementation exposes the values within the array,1
g,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 ,0
3,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
g,1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" that is to say, the network does not learn the true program semantics",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 we adapt machinery from the original paper slightly to fit our needs,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"1; and for bubble sort, appendix a",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 the degree for any vertex in the dag is variable,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
for addition, we analytically determine the verification set",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
 3: begin traversing from vertex 1 in the dag,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
training setup",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 almost all architectures train on program input/output pairs,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
"
algorithm 2 shows the topological sort task of interest",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" as with the others, we apply the procedure described in section 3",1
"
grade-school addition",1
" fa8750-15-2-0104, and berkeley deep drive",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
", to change the value of phi) none described belowstack",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 the first is the actual model architecture,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
quicksort",0
 the environment and return probability are omitted for readability,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"
topological sort",0
we now report on generalization for the varying tasks,0
" , a1a0 + b1b0} are added properly",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 u varies with the number of vertices in the graph,1
 the original version of the bubblesort implementation exposes the values within the array,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 there is a (changing) list of neural programs used to accomplish a given task,1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
g,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
g,1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
g,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
 this algorithm is a variant of depth first search,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
base cases and reduction rules for addition",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
quicksort",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
g,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
grade school addition",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
 this algorithm is a variant of depth first search,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" fa8750-15-2-0104, and berkeley deep drive",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
 b1b0 where no carry operations occur,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
5,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
g,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
g,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
the npi accesses an external environment, q, which varies according to the task",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" as with the others, we apply the procedure described in section 3",1
"
to perform the verification as described here, it is critical to construct v correctly",1
", to change the value of phi) none described belowstack",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" lshift moves the four pointers to the left, to move to the next column",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 reset represents a −∞ value,0
e,1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" , a1a0 + b1b0} are added properly",0
 we created a program set that reflects the semantics of algorithm 2,0
"
we describe the details of the npi model relevant to our contributions",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"1; and for bubble sort, appendix a",0
"
we experiment with two levels of recursion—partial and full",1
3,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 ,1
" lshift moves the four pointers to the left, to move to the next column",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" we call this set of inputs the verification set, sv ",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 we found that changing the npi training traces is a simple way to enable this,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
 ,0
" twc-1409915, darpa under grant no",0
", the verification set",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
"
quicksort",0
 ,0
e,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
"
base cases and reduction rules for addition",1
we now report on generalization for the varying tasks,1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 recursion enables provably perfect generalization,1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
 these pointers are referred to as bubble pointers,1
 ,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
 the environment and return probability are omitted for readability,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 b1b0 where no carry operations occur,0
"
inside bubble and reset, there are two operations that can be made recursive",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
for addition, we analytically determine the verification set",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
training setup",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 this algorithm is a variant of depth first search,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
base cases and reduction rules for bubble sort",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 these pointers are referred to as bubble pointers,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 a1a0 + bnbn−1 ,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
we describe the details of the npi model relevant to our contributions",1
 these pointers are referred to as bubble pointers,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 our experiments use a small number of training examples,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
 ,1
" , n , where the dag contains n vertices",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
base cases and reduction rules for addition",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" in all experiments, α is set to 0",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
g,1
 ,0
 this algorithm is a variant of depth first search,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
g,1
"
as in line 13 of the right-hand side of figure 1",0
g,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" we call this set of inputs the verification set, sv ",0
" each time a subprogram is called, the stack depth increases",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
this material is in part based upon work supported by the national science foundation under grant no,1
" , n , where the dag contains n vertices",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
 npi then outputs the return probability and next program and arguments to execute,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
we describe the details of the npi model relevant to our contributions",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
grade-school addition",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" as with the others, we apply the procedure described in section 3",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
quicksort",0
3 to construct v and then empirically create a verification set which covers v ,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
bubble sort",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
g,0
 the first is the actual model architecture,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" as aforementioned, the npi model naturally supports recursion",0
" , a1a0 + b1b0} are added properly",0
g,1
 ,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
as mentioned in section 2,1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" we call this set of inputs the verification set, sv ",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
g,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
g,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
 3: begin traversing from vertex 1 in the dag,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" fa8750-15-2-0104, and berkeley deep drive",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 ,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" for each length, we test each program on 30 randomly generated problems",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 we choose to implement a topological sort task for graphs,1
 there is a (changing) list of neural programs used to accomplish a given task,0
 almost all architectures train on program input/output pairs,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 this algorithm is a variant of depth first search,1
"
base cases and reduction rules for addition",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
base cases and reduction rules for addition",0
"
topological sort",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" fa8750-15-2-0104, and berkeley deep drive",1
 recursion enables provably perfect generalization,0
"
quicksort",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" for each length, we test each program on 30 randomly generated problems",0
"
training setup",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 the degree for any vertex in the dag is variable,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" in particular, recursion can be implemented as a program calling itself",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
base cases and reduction rules for topological sort",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 almost all architectures train on program input/output pairs,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"
base cases and reduction rules for bubble sort",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
g,1
", an array for quicksort or a dag for topological sort)",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
g,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
move",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 the environment and return probability are omitted for readability,1
 npi then outputs the return probability and next program and arguments to execute,0
g,1
g,1
"
as in line 13 of the right-hand side of figure 1",0
e,0
", the verification set",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
2,1
 the degree for any vertex in the dag is variable,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
g,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 our experiments use a small number of training examples,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
g,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" as aforementioned, the npi model naturally supports recursion",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
move",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
", the verification set",1
 we adapt machinery from the original paper slightly to fit our needs,0
" et+1 ∼ fenv(et, pt, at)",0
 we created a program set that reflects the semantics of algorithm 2,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
 recursion enables provably perfect generalization,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
 npi then outputs the return probability and next program and arguments to execute,0
 this verification phase only needs to be performed once after training,0
6,0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
g,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 the degree for any vertex in the dag is variable,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
base cases and reduction rules for topological sort",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
6,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
this material is in part based upon work supported by the national science foundation under grant no,1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
 ,1
g,1
"
base cases and reduction rules for topological sort",0
 18: push lo and p− 1 to slo and shi,1
", the trace corresponding to the problem “109 + 101”)",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
as mentioned in section 2,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" lshift moves the four pointers to the left, to move to the next column",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" we call this set of inputs the verification set, sv ",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" each time a subprogram is called, the stack depth increases",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" in future work, we seek to enable more tasks with recursive structure",1
 ,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
algorithm 2 shows the topological sort task of interest",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
g,0
 3: begin traversing from vertex 1 in the dag,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" in particular, recursion can be implemented as a program calling itself",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" for each length, we test each program on 30 randomly generated problems",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 reset represents a −∞ value,0
"
quicksort",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" each time a subprogram is called, the stack depth increases",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 we adapt machinery from the original paper slightly to fit our needs,1
g,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 these pointers are referred to as bubble pointers,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
"
topological sort",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
g,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 ,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" on the other hand, the recursive programs have learned the true program semantics",0
this material is in part based upon work supported by the national science foundation under grant no,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
3,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
", the trace corresponding to the problem “109 + 101”)",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" as aforementioned, the npi model naturally supports recursion",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
 we outline how to construct this set,1
 recursion can be implemented differently for different neural programming models,0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
"
base cases and reduction rules for topological sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
grade-school addition",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
move",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
", the verification set",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
", an lstm in npi’s case, but possibly other networks in different cases",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
 we adapt machinery from the original paper slightly to fit our needs,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
3,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
base cases and reduction rules for bubble sort",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
", the verification set",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
 we adapt machinery from the original paper slightly to fit our needs,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
", to change the value of phi) none described belowstack",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
3,0
g,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
3 to construct v and then empirically create a verification set which covers v ,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 the original version of the bubblesort implementation exposes the values within the array,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 we created a program set that reflects the semantics of algorithm 2,1
 we created a program set that reflects the semantics of algorithm 2,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 the environment and return probability are omitted for readability,0
", an lstm in npi’s case, but possibly other networks in different cases",1
"
grade-school addition",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
g,0
 a1a0 + bnbn−1 ,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" for each length, we test each program on 30 randomly generated problems",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
we now report on generalization for the varying tasks,0
" in this architecture, we consider a core controller, e",0
"1; and for bubble sort, appendix a",0
 ,1
 almost all architectures train on program input/output pairs,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
we now report on generalization for the varying tasks,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
", qstacklo or qstackhi) or to pointer (e",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
 recursion enables provably perfect generalization,1
 the first is the actual model architecture,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 18: push lo and p− 1 to slo and shi,1
 u varies with the number of vertices in the graph,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 the maximum problem length in this training set is 3 (e,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" that is to say, the network does not learn the true program semantics",0
e,1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" each time a subprogram is called, the stack depth increases",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
as mentioned in section 2,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" , a1a0 + b1b0} are added properly",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
as mentioned in section 2,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
 the program terminates when seeing no numbers in the current column,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 ,0
" that is to say, the network does not learn the true program semantics",1
", qstacklo or qstackhi) or to pointer (e",0
3,1
", to change the value of phi) none described belowstack",1
" in this architecture, we consider a core controller, e",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
5,1
 ,0
"
base cases and reduction rules for bubble sort",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"
grade-school addition",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" in particular, recursion can be implemented as a program calling itself",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
"
we describe the details of the npi model relevant to our contributions",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
 ,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
"
base cases and reduction rules for addition",1
3,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" et+1 ∼ fenv(et, pt, at)",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
", qstacklo or qstackhi) or to pointer (e",0
 a1a0 + bnbn−1 ,0
 the maximum problem length in this training set is 3 (e,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 this algorithm is a variant of depth first search,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" in future work, we seek to enable more tasks with recursive structure",1
"
arg 2 (increment or decrement): up, down
swap",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
 ,0
 almost all architectures train on program input/output pairs,0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
training setup",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
we experiment with two levels of recursion—partial and full",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 we created a program set that reflects the semantics of algorithm 2,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
 ,0
", to change the value of vactive) none described below move move a pointer (e",1
"
we propose and describe our verification procedure",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 we adapt machinery from the original paper slightly to fit our needs,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
base cases and reduction rules for addition",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 ,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
g,0
" et+1 ∼ fenv(et, pt, at)",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
 indentation indicates the stack is one level deeper than before,0
"
we experiment with two levels of recursion—partial and full",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 recursion can be implemented differently for different neural programming models,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
as in line 13 of the right-hand side of figure 1",1
3,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 reset represents a −∞ value,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" in all experiments, α is set to 0",0
as mentioned in section 2,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
5,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
 this verification phase only needs to be performed once after training,1
" in future work, we seek to enable more tasks with recursive structure",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
g,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"1; and for bubble sort, appendix a",1
 the environment and return probability are omitted for readability,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 the original version of the bubblesort implementation exposes the values within the array,1
 we adapt machinery from the original paper slightly to fit our needs,1
 the degree for any vertex in the dag is variable,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
g,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"
inside bubble and reset, there are two operations that can be made recursive",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
g,0
 the environment and return probability are omitted for readability,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
2,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
 ,0
3,0
 u varies with the number of vertices in the graph,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 we outline how to construct this set,0
 we choose to implement a topological sort task for graphs,1
" we call this set of inputs the verification set, sv ",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" as aforementioned, the npi model naturally supports recursion",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
the three environment observations aid with control flow in algorithm 2",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
 these pointers are referred to as bubble pointers,1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
 the program terminates when seeing no numbers in the current column,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
", to change the value of phi) none described belowstack",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
 recursion enables provably perfect generalization,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
5,0
 the training set for addition contains 200 traces,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 npi then outputs the return probability and next program and arguments to execute,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" fa8750-15-2-0104, and berkeley deep drive",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 ,0
2,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
g,0
"
quicksort",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
we experiment with two levels of recursion—partial and full",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
arg 2 (increment or decrement): up, down
swap",0
 ,0
g,1
 ,0
 recursion can be implemented differently for different neural programming models,0
", an array for quicksort or a dag for topological sort)",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"1; and for bubble sort, appendix a",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
", to color a vertex) or variable (e",1
 recursion can be implemented differently for different neural programming models,1
 we adapt machinery from the original paper slightly to fit our needs,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" , n , where the dag contains n vertices",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
arg 2 (increment or decrement): up, down
swap",0
 we found that changing the npi training traces is a simple way to enable this,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
base cases and reduction rules for quicksort",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
bubble sort",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
bubble sort",0
" as with the others, we apply the procedure described in section 3",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"
training setup",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
 ,0
" in particular, recursion can be implemented as a program calling itself",1
 the degree for any vertex in the dag is variable,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
g,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
3 to construct v and then empirically create a verification set which covers v ,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
g,1
" that is to say, the network does not learn the true program semantics",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
g,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 almost all architectures train on program input/output pairs,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
e,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 ,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
we experiment with two levels of recursion—partial and full",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 we found that changing the npi training traces is a simple way to enable this,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
we experiment with two levels of recursion—partial and full",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
base cases and reduction rules for bubble sort",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 the core controller acts as a dispatcher for the programs,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
 b1b0 where no carry operations occur,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
 ,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
 b1b0 where no carry operations occur,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" for each length, we test each program on 30 randomly generated problems",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
this material is in part based upon work supported by the national science foundation under grant no,0
", the verification set",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
 the environment and return probability are omitted for readability,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
we now report on generalization for the varying tasks,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
3 to construct v and then empirically create a verification set which covers v ,0
as mentioned in section 2,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" on the other hand, the recursive programs have learned the true program semantics",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" on the other hand, the recursive programs have learned the true program semantics",0
"
algorithm 2 shows the topological sort task of interest",1
"
topological sort",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 18: push lo and p− 1 to slo and shi,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" in this architecture, we consider a core controller, e",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
2,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
bubble sort",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" in this architecture, we consider a core controller, e",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
the three environment observations aid with control flow in algorithm 2",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
 the program terminates when seeing no numbers in the current column,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" each time a subprogram is called, the stack depth increases",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" in particular, recursion can be implemented as a program calling itself",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
5,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 our experiments use a small number of training examples,0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" in future work, we seek to enable more tasks with recursive structure",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
 ,1
"
for addition, we analytically determine the verification set",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" as aforementioned, the npi model naturally supports recursion",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" , n , where the dag contains n vertices",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 a1a0 + bnbn−1 ,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 we adapt machinery from the original paper slightly to fit our needs,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 ,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"
the npi accesses an external environment, q, which varies according to the task",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
 ,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 ,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" that is to say, the network does not learn the true program semantics",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for each length, we test each program on 30 randomly generated problems",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" for each length, we test each program on 30 randomly generated problems",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
the three environment observations aid with control flow in algorithm 2",1
" , a1a0 + b1b0} are added properly",0
 a1a0 + bnbn−1 ,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 recursion can be implemented differently for different neural programming models,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" in particular, recursion can be implemented as a program calling itself",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
 ,1
" each time a subprogram is called, the stack depth increases",0
 the core controller acts as a dispatcher for the programs,0
"
grade-school addition",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
", an array for quicksort or a dag for topological sort)",0
", qstacklo or qstackhi) or to pointer (e",1
 reset represents a −∞ value,1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
 ,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
g,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" each time a subprogram is called, the stack depth increases",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 18: push lo and p− 1 to slo and shi,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 the training set for addition contains 200 traces,0
"
bubble sort",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
3,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 3: begin traversing from vertex 1 in the dag,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
for addition, we analytically determine the verification set",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" we call this set of inputs the verification set, sv ",1
" in all experiments, α is set to 0",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
", to change the value of vactive) none described below move move a pointer (e",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 ,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
"
we experiment with two levels of recursion—partial and full",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
g,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" that is to say, the network does not learn the true program semantics",1
 almost all architectures train on program input/output pairs,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 reset represents a −∞ value,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" however, our concept of recursion for neural programs is general",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" for each length, we test each program on 30 randomly generated problems",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
g,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 the degree for any vertex in the dag is variable,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" however, our concept of recursion for neural programs is general",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
3,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
", the trace corresponding to the array [3,2])",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
 ,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 npi then outputs the return probability and next program and arguments to execute,1
 recursion can be implemented differently for different neural programming models,1
g,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 reset represents a −∞ value,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" in all experiments, α is set to 0",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
g,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
move",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" we call this set of inputs the verification set, sv ",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 ,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"1; and for bubble sort, appendix a",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 this verification phase only needs to be performed once after training,0
 these pointers are referred to as bubble pointers,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
 the environment and return probability are omitted for readability,1
" as with the others, we apply the procedure described in section 3",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
g,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
 ,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
 the training set for addition contains 200 traces,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
this material is in part based upon work supported by the national science foundation under grant no,1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
", an array for quicksort or a dag for topological sort)",0
", the trace corresponding to the problem “109 + 101”)",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
this material is in part based upon work supported by the national science foundation under grant no,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 ,0
" in particular, recursion can be implemented as a program calling itself",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 we created a program set that reflects the semantics of algorithm 2,0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 ,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
g,0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
base cases and reduction rules for bubble sort",0
"
we experiment with two levels of recursion—partial and full",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
grade-school addition",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
inside bubble and reset, there are two operations that can be made recursive",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
 we outline how to construct this set,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 ,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
 recursion can be implemented differently for different neural programming models,1
"
inside bubble and reset, there are two operations that can be made recursive",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
"
base cases and reduction rules for bubble sort",1
", the trace corresponding to the problem “109 + 101”)",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 b1b0 where no carry operations occur,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
g,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" in future work, we seek to enable more tasks with recursive structure",1
", to change the value of vactive) none described below move move a pointer (e",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
", the verification set",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
", an array for quicksort or a dag for topological sort)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
g,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
e,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 we outline how to construct this set,1
 ,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
", the verification set",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
", the trace corresponding to the problem “109 + 101”)",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
5,1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
g,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
 the training set for addition contains 200 traces,0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
inside bubble and reset, there are two operations that can be made recursive",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 we adapt machinery from the original paper slightly to fit our needs,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"
base cases and reduction rules for quicksort",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
", to change the value of vactive) none described below move move a pointer (e",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 this makes it difficult to reason about what the model will do when given complex inputs,1
3 to construct v and then empirically create a verification set which covers v ,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 the degree for any vertex in the dag is variable,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
g,1
"
arg 2 (increment or decrement): up, down
swap",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
we experiment with two levels of recursion—partial and full",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
move",0
"
to perform the verification as described here, it is critical to construct v correctly",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 reset represents a −∞ value,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 the training set for addition contains 200 traces,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
 we choose to implement a topological sort task for graphs,0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
3 to construct v and then empirically create a verification set which covers v ,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 the first is the actual model architecture,0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
"
base cases and reduction rules for quicksort",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
5,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
", the trace corresponding to the problem “109 + 101”)",0
" , a1a0 + b1b0} are added properly",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
algorithm 2 shows the topological sort task of interest",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"
we experiment with two levels of recursion—partial and full",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
g,0
g,0
2,0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
we describe the details of the npi model relevant to our contributions",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
g,0
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" we call this set of inputs the verification set, sv ",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
 we outline how to construct this set,1
 ,1
"
base cases and reduction rules for bubble sort",1
", an array for quicksort or a dag for topological sort)",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
"
move",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
", qstacklo or qstackhi) or to pointer (e",1
 the maximum problem length in this training set is 3 (e,0
" twc-1409915, darpa under grant no",0
"
bubble sort",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 ,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
5,1
"
the three environment observations aid with control flow in algorithm 2",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
 ,0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
we propose and describe our verification procedure",0
g,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 we choose to implement a topological sort task for graphs,0
 ,1
", to change the value of vactive) none described below move move a pointer (e",0
" we call this set of inputs the verification set, sv ",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 ,1
 the core controller acts as a dispatcher for the programs,1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 these pointers are referred to as bubble pointers,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
bubble sort",1
"
we propose and describe our verification procedure",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" in this architecture, we consider a core controller, e",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
this material is in part based upon work supported by the national science foundation under grant no,0
 recursion enables provably perfect generalization,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
", the verification set",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
", to color a vertex) or variable (e",0
"
bubble sort",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" in particular, recursion can be implemented as a program calling itself",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 this algorithm is a variant of depth first search,0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
", to change the value of phi) none described belowstack",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
"
quicksort",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
"
we describe the details of the npi model relevant to our contributions",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" lshift moves the four pointers to the left, to move to the next column",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
we experiment with two levels of recursion—partial and full",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
g,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
5,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
bubble sort",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 this verification phase only needs to be performed once after training,0
 npi then outputs the return probability and next program and arguments to execute,0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
3,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
bubble sort",1
3,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 the first is the actual model architecture,0
 ,1
" in future work, we seek to enable more tasks with recursive structure",0
" on the other hand, the recursive programs have learned the true program semantics",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 recursion enables provably perfect generalization,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" however, our concept of recursion for neural programs is general",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
base cases and reduction rules for topological sort",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" for each length, we test each program on 30 randomly generated problems",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
for addition, we analytically determine the verification set",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 b1b0 where no carry operations occur,1
" for each length, we test each program on 30 randomly generated problems",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 we outline how to construct this set,0
g,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" twc-1409915, darpa under grant no",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
 the environment and return probability are omitted for readability,0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
move",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
grade-school addition",0
" that is to say, the network does not learn the true program semantics",0
 the maximum problem length in this training set is 3 (e,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"
we experiment with two levels of recursion—partial and full",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
3,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
", an array for quicksort or a dag for topological sort)",1
 recursion enables provably perfect generalization,0
"
for addition, we analytically determine the verification set",0
 ,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
base cases and reduction rules for bubble sort",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
"
base cases and reduction rules for quicksort",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
 ,1
g,0
"
base cases and reduction rules for bubble sort",1
 the core controller acts as a dispatcher for the programs,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 the program terminates when seeing no numbers in the current column,0
we now report on generalization for the varying tasks,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
", an lstm in npi’s case, but possibly other networks in different cases",1
"
quicksort",1
" we call this set of inputs the verification set, sv ",0
 we created a program set that reflects the semantics of algorithm 2,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" fa8750-15-2-0104, and berkeley deep drive",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 recursion enables provably perfect generalization,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
for addition, we analytically determine the verification set",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
grade-school addition",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
e,0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
3,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" each time a subprogram is called, the stack depth increases",0
"
algorithm 2 shows the topological sort task of interest",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
", to color a vertex) or variable (e",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
the three environment observations aid with control flow in algorithm 2",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 our experiments use a small number of training examples,1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
", to change the value of vactive) none described below move move a pointer (e",0
"
the three environment observations aid with control flow in algorithm 2",0
" each time a subprogram is called, the stack depth increases",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
", to color a vertex) or variable (e",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
 npi then outputs the return probability and next program and arguments to execute,1
" on the other hand, the recursive programs have learned the true program semantics",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
move",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
 we found that changing the npi training traces is a simple way to enable this,1
" for each length, we test each program on 30 randomly generated problems",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
6,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
inside bubble and reset, there are two operations that can be made recursive",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" as with the others, we apply the procedure described in section 3",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" that is to say, the network does not learn the true program semantics",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
quicksort",1
 the degree for any vertex in the dag is variable,0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 ,1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
g,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
 npi then outputs the return probability and next program and arguments to execute,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
", to change the value of phi) none described belowstack",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
to perform the verification as described here, it is critical to construct v correctly",1
 ,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" in particular, recursion can be implemented as a program calling itself",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
topological sort",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
g,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
", an array for quicksort or a dag for topological sort)",1
"
as in line 13 of the right-hand side of figure 1",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 recursion can be implemented differently for different neural programming models,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
g,0
 the maximum problem length in this training set is 3 (e,1
 our experiments use a small number of training examples,1
 we created a program set that reflects the semantics of algorithm 2,0
as mentioned in section 2,1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
 ,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 recursion enables provably perfect generalization,1
3,0
", to color a vertex) or variable (e",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
", to change the value of vactive) none described below move move a pointer (e",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
 we adapt machinery from the original paper slightly to fit our needs,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
3,0
this material is in part based upon work supported by the national science foundation under grant no,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 the first is the actual model architecture,0
3,1
 the maximum problem length in this training set is 3 (e,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
g,1
g,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" in all experiments, α is set to 0",0
 indentation indicates the stack is one level deeper than before,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
"
the npi accesses an external environment, q, which varies according to the task",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
topological sort",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
5,0
g,1
 the program terminates when seeing no numbers in the current column,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
", to color a vertex) or variable (e",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" however, our concept of recursion for neural programs is general",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
3,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" each time a subprogram is called, the stack depth increases",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
base cases and reduction rules for bubble sort",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
as mentioned in section 2,0
"
arg 2 (increment or decrement): up, down
swap",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
g,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
 the original version of the bubblesort implementation exposes the values within the array,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
bubble sort",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 ,1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 ,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
", an array for quicksort or a dag for topological sort)",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 u varies with the number of vertices in the graph,0
" however, our concept of recursion for neural programs is general",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
 npi then outputs the return probability and next program and arguments to execute,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 we created a program set that reflects the semantics of algorithm 2,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
we describe the details of the npi model relevant to our contributions",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" in all experiments, α is set to 0",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
topological sort",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
quicksort",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
", an lstm in npi’s case, but possibly other networks in different cases",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 these pointers are referred to as bubble pointers,1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" in this architecture, we consider a core controller, e",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
5,1
"
the three environment observations aid with control flow in algorithm 2",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
g,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
 reset represents a −∞ value,1
g,1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"
training setup",1
"
base cases and reduction rules for topological sort",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
grade school addition",1
" , a1a0 + b1b0} are added properly",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
", an array for quicksort or a dag for topological sort)",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"1; and for bubble sort, appendix a",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
g,0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
 the core controller acts as a dispatcher for the programs,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
we experiment with two levels of recursion—partial and full",1
"
inside bubble and reset, there are two operations that can be made recursive",1
 ,0
" as with the others, we apply the procedure described in section 3",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
we propose and describe our verification procedure",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
as mentioned in section 2,0
"
for addition, we analytically determine the verification set",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
 we found that changing the npi training traces is a simple way to enable this,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" as aforementioned, the npi model naturally supports recursion",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 ,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" in this architecture, we consider a core controller, e",0
"
base cases and reduction rules for bubble sort",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
e,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 ,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 our experiments use a small number of training examples,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
 our experiments use a small number of training examples,1
 reset represents a −∞ value,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" on the other hand, the recursive programs have learned the true program semantics",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
g,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 the training set for addition contains 200 traces,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
 3: begin traversing from vertex 1 in the dag,0
" , n , where the dag contains n vertices",0
 almost all architectures train on program input/output pairs,1
"
quicksort",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
", the verification set",1
"
we experiment with two levels of recursion—partial and full",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
3 to construct v and then empirically create a verification set which covers v ,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" twc-1409915, darpa under grant no",0
 indentation indicates the stack is one level deeper than before,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
 reset represents a −∞ value,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
"
bubble sort",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
"1; and for bubble sort, appendix a",0
"
topological sort",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
we describe the details of the npi model relevant to our contributions",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 ,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
5,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
 we found that changing the npi training traces is a simple way to enable this,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 reset represents a −∞ value,0
"
quicksort",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
"
topological sort",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
grade school addition",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
 this algorithm is a variant of depth first search,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
3,1
we now report on generalization for the varying tasks,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" on the other hand, the recursive programs have learned the true program semantics",1
 the training set for addition contains 200 traces,1
" on the other hand, the recursive programs have learned the true program semantics",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
e,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" as aforementioned, the npi model naturally supports recursion",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
", the verification set",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
 these pointers are referred to as bubble pointers,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" each time a subprogram is called, the stack depth increases",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
g,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
3,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" however, our concept of recursion for neural programs is general",0
"
base cases and reduction rules for bubble sort",0
2,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
 this algorithm is a variant of depth first search,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 the environment and return probability are omitted for readability,1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
 ,1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
quicksort",0
" et+1 ∼ fenv(et, pt, at)",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" , n , where the dag contains n vertices",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
base cases and reduction rules for topological sort",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
g,0
", an lstm in npi’s case, but possibly other networks in different cases",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 these pointers are referred to as bubble pointers,0
 we created a program set that reflects the semantics of algorithm 2,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
3,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
as mentioned in section 2,1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" we call this set of inputs the verification set, sv ",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" fa8750-15-2-0104, and berkeley deep drive",0
" fa8750-15-2-0104, and berkeley deep drive",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
quicksort",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
as in line 13 of the right-hand side of figure 1",0
"
bubble sort",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
g,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
 the degree for any vertex in the dag is variable,0
6,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
algorithm 2 shows the topological sort task of interest",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
bubble sort",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
this material is in part based upon work supported by the national science foundation under grant no,0
 these pointers are referred to as bubble pointers,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
as in line 13 of the right-hand side of figure 1",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 the environment and return probability are omitted for readability,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" in all experiments, α is set to 0",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" et+1 ∼ fenv(et, pt, at)",1
"
topological sort",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 the first is the actual model architecture,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 the original version of the bubblesort implementation exposes the values within the array,1
", an lstm in npi’s case, but possibly other networks in different cases",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
move",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 there is a (changing) list of neural programs used to accomplish a given task,0
"
the three environment observations aid with control flow in algorithm 2",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
2,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" however, our concept of recursion for neural programs is general",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
move",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
 recursion can be implemented differently for different neural programming models,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 ,1
" however, our concept of recursion for neural programs is general",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 a1a0 + bnbn−1 ,1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 the maximum problem length in this training set is 3 (e,1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
topological sort",0
e,1
"
quicksort",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
g,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
arg 2 (increment or decrement): up, down
swap",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
e,1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
this material is in part based upon work supported by the national science foundation under grant no,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
 we created a program set that reflects the semantics of algorithm 2,0
" for each length, we test each program on 30 randomly generated problems",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
 these pointers are referred to as bubble pointers,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
g,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 we outline how to construct this set,1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
g,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
grade-school addition",1
"
bubble sort",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
 we outline how to construct this set,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" twc-1409915, darpa under grant no",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
arg 2 (increment or decrement): up, down
swap",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
"
topological sort",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the degree for any vertex in the dag is variable,0
"
grade school addition",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
", an lstm in npi’s case, but possibly other networks in different cases",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
g,1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
g,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
base cases and reduction rules for addition",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" et+1 ∼ fenv(et, pt, at)",1
" on the other hand, the recursive programs have learned the true program semantics",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
bubble sort",1
" in this architecture, we consider a core controller, e",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 18: push lo and p− 1 to slo and shi,1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
", qstacklo or qstackhi) or to pointer (e",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" et+1 ∼ fenv(et, pt, at)",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 the maximum problem length in this training set is 3 (e,0
 ,0
"
base cases and reduction rules for bubble sort",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 ,0
g,1
 the degree for any vertex in the dag is variable,0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"1; and for bubble sort, appendix a",0
 the program terminates when seeing no numbers in the current column,1
g,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 recursion enables provably perfect generalization,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
arg 2 (increment or decrement): up, down
swap",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" fa8750-15-2-0104, and berkeley deep drive",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
g,0
this material is in part based upon work supported by the national science foundation under grant no,0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
grade-school addition",1
5,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
arg 2 (increment or decrement): up, down
swap",0
3,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
g,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
move",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
g,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
move",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
3,1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 b1b0 where no carry operations occur,0
"
base cases and reduction rules for addition",1
"
training setup",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
grade-school addition",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 reset represents a −∞ value,0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
"
as in line 13 of the right-hand side of figure 1",1
as mentioned in section 2,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
", qstacklo or qstackhi) or to pointer (e",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 ,0
", the verification set",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 ,0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 ,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 ,1
", an array for quicksort or a dag for topological sort)",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
 npi then outputs the return probability and next program and arguments to execute,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
"
we experiment with two levels of recursion—partial and full",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
grade school addition",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" that is to say, the network does not learn the true program semantics",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
"
grade school addition",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
3,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
e,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
g,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
the npi accesses an external environment, q, which varies according to the task",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" each time a subprogram is called, the stack depth increases",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
we experiment with two levels of recursion—partial and full",0
", the verification set",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
as in line 13 of the right-hand side of figure 1",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" for each length, we test each program on 30 randomly generated problems",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 b1b0 where no carry operations occur,0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 we created a program set that reflects the semantics of algorithm 2,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" that is to say, the network does not learn the true program semantics",1
 b1b0 where no carry operations occur,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
g,0
 we outline how to construct this set,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
 the degree for any vertex in the dag is variable,0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
base cases and reduction rules for bubble sort",0
"
grade school addition",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
 b1b0 where no carry operations occur,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
g,1
"
quicksort",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 we adapt machinery from the original paper slightly to fit our needs,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
", to color a vertex) or variable (e",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" as aforementioned, the npi model naturally supports recursion",0
3,1
 we outline how to construct this set,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
g,1
"
base cases and reduction rules for addition",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
g,1
 18: push lo and p− 1 to slo and shi,0
 ,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
", the verification set",1
", the trace corresponding to the array [3,2])",0
 we created a program set that reflects the semantics of algorithm 2,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
we propose and describe our verification procedure",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" on the other hand, the recursive programs have learned the true program semantics",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" for each length, we test each program on 30 randomly generated problems",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" in particular, recursion can be implemented as a program calling itself",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
", to change the value of vactive) none described below move move a pointer (e",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
g,0
"
we propose and describe our verification procedure",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
 ,0
" et+1 ∼ fenv(et, pt, at)",0
g,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
training setup",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
3,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
g,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" in this architecture, we consider a core controller, e",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
as in line 13 of the right-hand side of figure 1",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" , a1a0 + b1b0} are added properly",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
arg 2 (increment or decrement): up, down
swap",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
g,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
 a1a0 + bnbn−1 ,1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"
quicksort",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
 the environment and return probability are omitted for readability,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
as mentioned in section 2,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 ,1
 the environment and return probability are omitted for readability,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
 a1a0 + bnbn−1 ,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
e,0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
g,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
bubble sort",1
", the trace corresponding to the array [3,2])",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" as with the others, we apply the procedure described in section 3",1
"1; and for bubble sort, appendix a",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
 we adapt machinery from the original paper slightly to fit our needs,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
", the verification set",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 the original version of the bubblesort implementation exposes the values within the array,0
"
the npi accesses an external environment, q, which varies according to the task",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" we call this set of inputs the verification set, sv ",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" lshift moves the four pointers to the left, to move to the next column",0
 ,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
the npi accesses an external environment, q, which varies according to the task",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 we found that changing the npi training traces is a simple way to enable this,0
 our experiments use a small number of training examples,0
" in this architecture, we consider a core controller, e",0
"
as in line 13 of the right-hand side of figure 1",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 ,0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
g,0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 indentation indicates the stack is one level deeper than before,0
 3: begin traversing from vertex 1 in the dag,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
grade school addition",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" lshift moves the four pointers to the left, to move to the next column",0
 ,0
 recursion can be implemented differently for different neural programming models,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" as aforementioned, the npi model naturally supports recursion",1
"
bubble sort",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" in all experiments, α is set to 0",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
"
we describe the details of the npi model relevant to our contributions",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
", to change the value of vactive) none described below move move a pointer (e",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 ,0
 almost all architectures train on program input/output pairs,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" in particular, recursion can be implemented as a program calling itself",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
arg 2 (increment or decrement): up, down
swap",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
 recursion can be implemented differently for different neural programming models,0
" in future work, we seek to enable more tasks with recursive structure",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
", an lstm in npi’s case, but possibly other networks in different cases",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" in this architecture, we consider a core controller, e",1
" in particular, recursion can be implemented as a program calling itself",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
2,0
 the training set for addition contains 200 traces,1
", pstart or childlist[vactive]) up or down none described belowwrite",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
 ,1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 these pointers are referred to as bubble pointers,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
 the program terminates when seeing no numbers in the current column,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
bubble sort",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" however, our concept of recursion for neural programs is general",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
", an array for quicksort or a dag for topological sort)",0
e,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
g,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 we created a program set that reflects the semantics of algorithm 2,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
 this algorithm is a variant of depth first search,1
" in future work, we seek to enable more tasks with recursive structure",0
 we choose to implement a topological sort task for graphs,0
", the trace corresponding to the array [3,2])",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
for addition, we analytically determine the verification set",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 ,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
"
as in line 13 of the right-hand side of figure 1",1
 these pointers are referred to as bubble pointers,1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" et+1 ∼ fenv(et, pt, at)",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
", qstacklo or qstackhi) or to pointer (e",1
"
for addition, we analytically determine the verification set",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
g,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
g,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
"
grade school addition",1
"
move",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" twc-1409915, darpa under grant no",0
" as with the others, we apply the procedure described in section 3",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 there is a (changing) list of neural programs used to accomplish a given task,0
 we outline how to construct this set,1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 b1b0 where no carry operations occur,1
"
for addition, we analytically determine the verification set",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
g,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" , n , where the dag contains n vertices",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" lshift moves the four pointers to the left, to move to the next column",0
 b1b0 where no carry operations occur,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
for addition, we analytically determine the verification set",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 our experiments use a small number of training examples,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 reset represents a −∞ value,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
as mentioned in section 2,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 reset represents a −∞ value,1
" on the other hand, the recursive programs have learned the true program semantics",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" in future work, we seek to enable more tasks with recursive structure",1
 18: push lo and p− 1 to slo and shi,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"
base cases and reduction rules for topological sort",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
 the degree for any vertex in the dag is variable,1
3,1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" for each length, we test each program on 30 randomly generated problems",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
g,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 we outline how to construct this set,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
quicksort",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
g,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
base cases and reduction rules for addition",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
as mentioned in section 2,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
e,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
g,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 we outline how to construct this set,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
"
arg 2 (increment or decrement): up, down
swap",1
"
training setup",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
g,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
inside bubble and reset, there are two operations that can be made recursive",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" as aforementioned, the npi model naturally supports recursion",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
 the training set for addition contains 200 traces,1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
" each time a subprogram is called, the stack depth increases",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in particular, recursion can be implemented as a program calling itself",1
g,0
 our experiments use a small number of training examples,1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
algorithm 2 shows the topological sort task of interest",1
 we created a program set that reflects the semantics of algorithm 2,1
e,1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" for each length, we test each program on 30 randomly generated problems",1
" that is to say, the network does not learn the true program semantics",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 the program terminates when seeing no numbers in the current column,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" in all experiments, α is set to 0",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 we found that changing the npi training traces is a simple way to enable this,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
 ,1
" as aforementioned, the npi model naturally supports recursion",1
" twc-1409915, darpa under grant no",1
 npi then outputs the return probability and next program and arguments to execute,1
 a1a0 + bnbn−1 ,0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" in particular, recursion can be implemented as a program calling itself",1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 indentation indicates the stack is one level deeper than before,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" lshift moves the four pointers to the left, to move to the next column",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
", to change the value of phi) none described belowstack",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 npi then outputs the return probability and next program and arguments to execute,1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
algorithm 2 shows the topological sort task of interest",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 we found that changing the npi training traces is a simple way to enable this,0
g,1
", qstacklo or qstackhi) or to pointer (e",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 ,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 we choose to implement a topological sort task for graphs,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
 we found that changing the npi training traces is a simple way to enable this,1
"
to perform the verification as described here, it is critical to construct v correctly",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
 recursion can be implemented differently for different neural programming models,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" in future work, we seek to enable more tasks with recursive structure",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 ,0
g,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
g,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
grade-school addition",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
 ,0
as mentioned in section 2,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 these pointers are referred to as bubble pointers,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
base cases and reduction rules for addition",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" et+1 ∼ fenv(et, pt, at)",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
g,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
base cases and reduction rules for topological sort",1
", to color a vertex) or variable (e",1
 u varies with the number of vertices in the graph,1
we now report on generalization for the varying tasks,0
 we outline how to construct this set,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" as aforementioned, the npi model naturally supports recursion",1
 3: begin traversing from vertex 1 in the dag,1
g,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
", to color a vertex) or variable (e",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" that is to say, the network does not learn the true program semantics",1
"
we propose and describe our verification procedure",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 we outline how to construct this set,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" , n , where the dag contains n vertices",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
as in line 13 of the right-hand side of figure 1",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" that is to say, the network does not learn the true program semantics",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
 the environment and return probability are omitted for readability,0
3,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" for each length, we test each program on 30 randomly generated problems",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
3,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
bubble sort",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 almost all architectures train on program input/output pairs,0
" , n , where the dag contains n vertices",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
" twc-1409915, darpa under grant no",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" , a1a0 + b1b0} are added properly",1
", an lstm in npi’s case, but possibly other networks in different cases",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
topological sort",1
"
as in line 13 of the right-hand side of figure 1",1
"
base cases and reduction rules for bubble sort",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
", to change the value of phi) none described belowstack",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
this material is in part based upon work supported by the national science foundation under grant no,1
 almost all architectures train on program input/output pairs,1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
"
the three environment observations aid with control flow in algorithm 2",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
base cases and reduction rules for topological sort",0
"1; and for bubble sort, appendix a",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 the maximum problem length in this training set is 3 (e,0
" , a1a0 + b1b0} are added properly",0
" et+1 ∼ fenv(et, pt, at)",1
"
algorithm 2 shows the topological sort task of interest",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 ,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 we created a program set that reflects the semantics of algorithm 2,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
base cases and reduction rules for quicksort",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
", qstacklo or qstackhi) or to pointer (e",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" in future work, we seek to enable more tasks with recursive structure",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" , a1a0 + b1b0} are added properly",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 indentation indicates the stack is one level deeper than before,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" in particular, recursion can be implemented as a program calling itself",1
 ,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"
topological sort",0
"
inside bubble and reset, there are two operations that can be made recursive",0
 the training set for addition contains 200 traces,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
g,0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
6,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
 this verification phase only needs to be performed once after training,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
g,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
 npi then outputs the return probability and next program and arguments to execute,1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 the original version of the bubblesort implementation exposes the values within the array,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
move",0
" as with the others, we apply the procedure described in section 3",1
 18: push lo and p− 1 to slo and shi,0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
e,1
g,0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
move",0
g,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 3: begin traversing from vertex 1 in the dag,0
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
", the verification set",1
" on the other hand, the recursive programs have learned the true program semantics",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 our experiments use a small number of training examples,1
 ,0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"
base cases and reduction rules for addition",1
"
base cases and reduction rules for addition",1
", the trace corresponding to the problem “109 + 101”)",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 recursion enables provably perfect generalization,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
 u varies with the number of vertices in the graph,1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
base cases and reduction rules for quicksort",1
"
we experiment with two levels of recursion—partial and full",1
"
we describe the details of the npi model relevant to our contributions",0
 figure 2 shows examples of traces for the different versions of bubble sort,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
", an lstm in npi’s case, but possibly other networks in different cases",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
"
grade school addition",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
 the first is the actual model architecture,0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
move",0
 the maximum problem length in this training set is 3 (e,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 the first is the actual model architecture,1
 ,0
g,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
we experiment with two levels of recursion—partial and full",0
5,0
" in all experiments, α is set to 0",0
"
inside bubble and reset, there are two operations that can be made recursive",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
 u varies with the number of vertices in the graph,1
"
in this general neural programming architecture, we show it is easy to support recursion",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 the original version of the bubblesort implementation exposes the values within the array,1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
g,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
g,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
base cases and reduction rules for addition",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
 the first is the actual model architecture,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 a1a0 + bnbn−1 ,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
 this verification phase only needs to be performed once after training,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
g,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
", an lstm in npi’s case, but possibly other networks in different cases",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
g,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
 we adapt machinery from the original paper slightly to fit our needs,1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
base cases and reduction rules for topological sort",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
topological sort",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" as aforementioned, the npi model naturally supports recursion",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 we adapt machinery from the original paper slightly to fit our needs,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
" in this architecture, we consider a core controller, e",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
"
bubble sort",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
bubble sort",0
2,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
 u varies with the number of vertices in the graph,1
" for each length, we test each program on 30 randomly generated problems",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
 ,1
 this verification phase only needs to be performed once after training,1
3 to construct v and then empirically create a verification set which covers v ,1
3 to construct v and then empirically create a verification set which covers v ,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
"
move",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
we describe the details of the npi model relevant to our contributions",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" however, our concept of recursion for neural programs is general",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" in all experiments, α is set to 0",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
bubble sort",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
 the core controller acts as a dispatcher for the programs,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
base cases and reduction rules for quicksort",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
6,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 ,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
 we found that changing the npi training traces is a simple way to enable this,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 the training set for addition contains 200 traces,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 the environment and return probability are omitted for readability,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
base cases and reduction rules for bubble sort",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
as in line 13 of the right-hand side of figure 1",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
 ,1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 this verification phase only needs to be performed once after training,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
", to change the value of phi) none described belowstack",0
" for each length, we test each program on 30 randomly generated problems",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
g,1
"
training setup",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
e,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" et+1 ∼ fenv(et, pt, at)",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" in particular, recursion can be implemented as a program calling itself",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
3,1
 ,0
 figure 2 shows examples of traces for the different versions of bubble sort,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 recursion can be implemented differently for different neural programming models,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 we found that changing the npi training traces is a simple way to enable this,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 we adapt machinery from the original paper slightly to fit our needs,0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 we choose to implement a topological sort task for graphs,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 u varies with the number of vertices in the graph,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
move",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
we describe the details of the npi model relevant to our contributions",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
g,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
g,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 ,1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"
topological sort",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,1
" fa8750-15-2-0104, and berkeley deep drive",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
3 to construct v and then empirically create a verification set which covers v ,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
 we choose to implement a topological sort task for graphs,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
3,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 ,0
" in particular, recursion can be implemented as a program calling itself",0
 we created a program set that reflects the semantics of algorithm 2,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
base cases and reduction rules for quicksort",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 this algorithm is a variant of depth first search,1
 ,0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
", the trace corresponding to the problem “109 + 101”)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 the core controller acts as a dispatcher for the programs,1
 this algorithm is a variant of depth first search,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
 the training set for addition contains 200 traces,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
bubble sort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 ,1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 we found that changing the npi training traces is a simple way to enable this,1
" et+1 ∼ fenv(et, pt, at)",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
 ,1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 ,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
 the environment and return probability are omitted for readability,0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
 a1a0 + bnbn−1 ,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 almost all architectures train on program input/output pairs,1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
move",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
g,1
", to change the value of phi) none described belowstack",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
", the trace corresponding to the array [3,2])",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
g,0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" lshift moves the four pointers to the left, to move to the next column",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
 ,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
3,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" that is to say, the network does not learn the true program semantics",0
"
grade school addition",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
move",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 indentation indicates the stack is one level deeper than before,0
" in particular, recursion can be implemented as a program calling itself",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" as with the others, we apply the procedure described in section 3",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
base cases and reduction rules for topological sort",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" as with the others, we apply the procedure described in section 3",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
", an array for quicksort or a dag for topological sort)",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
the three environment observations aid with control flow in algorithm 2",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
", qstacklo or qstackhi) or to pointer (e",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 almost all architectures train on program input/output pairs,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 the degree for any vertex in the dag is variable,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
bubble sort",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
 the degree for any vertex in the dag is variable,0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 indentation indicates the stack is one level deeper than before,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 b1b0 where no carry operations occur,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 ,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 ,0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
 ,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
this material is in part based upon work supported by the national science foundation under grant no,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
g,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
 the degree for any vertex in the dag is variable,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
" for each length, we test each program on 30 randomly generated problems",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 the training set for addition contains 200 traces,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
we experiment with two levels of recursion—partial and full",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" in future work, we seek to enable more tasks with recursive structure",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 this verification phase only needs to be performed once after training,0
 ,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
quicksort",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
e,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
quicksort",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
g,0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 the original version of the bubblesort implementation exposes the values within the array,1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
 ,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
5,0
"
the three environment observations aid with control flow in algorithm 2",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 b1b0 where no carry operations occur,0
 reset represents a −∞ value,1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"
move",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
 we outline how to construct this set,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
this material is in part based upon work supported by the national science foundation under grant no,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
6,0
"
we describe the details of the npi model relevant to our contributions",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 ,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
g,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" , a1a0 + b1b0} are added properly",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 there is a (changing) list of neural programs used to accomplish a given task,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
2,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
bubble sort",1
" that is to say, the network does not learn the true program semantics",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"
bubble sort",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
 18: push lo and p− 1 to slo and shi,0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" in this architecture, we consider a core controller, e",0
"
move",0
", the trace corresponding to the problem “109 + 101”)",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" in particular, recursion can be implemented as a program calling itself",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" we call this set of inputs the verification set, sv ",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
 reset represents a −∞ value,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 we created a program set that reflects the semantics of algorithm 2,0
 recursion enables provably perfect generalization,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
3,0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
 indentation indicates the stack is one level deeper than before,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 18: push lo and p− 1 to slo and shi,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 there is a (changing) list of neural programs used to accomplish a given task,1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
", the trace corresponding to the problem “109 + 101”)",1
 ,1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
grade school addition",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
", to color a vertex) or variable (e",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
", the verification set",0
g,1
" , n , where the dag contains n vertices",1
 ,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 a1a0 + bnbn−1 ,1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
g,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
", to color a vertex) or variable (e",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
g,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" in all experiments, α is set to 0",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
 ,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 ,1
g,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 we choose to implement a topological sort task for graphs,1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
3,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
", the trace corresponding to the array [3,2])",1
 we found that changing the npi training traces is a simple way to enable this,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
 we choose to implement a topological sort task for graphs,0
" each time a subprogram is called, the stack depth increases",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
3,0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
", to change the value of phi) none described belowstack",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
g,1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" in this architecture, we consider a core controller, e",0
 3: begin traversing from vertex 1 in the dag,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" fa8750-15-2-0104, and berkeley deep drive",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" et+1 ∼ fenv(et, pt, at)",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
move",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
", pstart or childlist[vactive]) up or down none described belowwrite",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
5,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
"
base cases and reduction rules for bubble sort",1
" however, our concept of recursion for neural programs is general",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
"
move",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 3: begin traversing from vertex 1 in the dag,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 recursion can be implemented differently for different neural programming models,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
the npi accesses an external environment, q, which varies according to the task",1
 the core controller acts as a dispatcher for the programs,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 ,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
"
quicksort",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 ,0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
we now report on generalization for the varying tasks,1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
", the trace corresponding to the array [3,2])",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
 the training set for addition contains 200 traces,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
g,1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 18: push lo and p− 1 to slo and shi,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
"
we propose and describe our verification procedure",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 a1a0 + bnbn−1 ,0
"1; and for bubble sort, appendix a",1
"
arg 2 (increment or decrement): up, down
swap",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
3,1
 3: begin traversing from vertex 1 in the dag,0
" for each length, we test each program on 30 randomly generated problems",0
 the program terminates when seeing no numbers in the current column,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for each length, we test each program on 30 randomly generated problems",1
"
base cases and reduction rules for topological sort",0
g,1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
as mentioned in section 2,0
6,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
 npi then outputs the return probability and next program and arguments to execute,0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
", an array for quicksort or a dag for topological sort)",1
 the environment and return probability are omitted for readability,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
we now report on generalization for the varying tasks,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
 the maximum problem length in this training set is 3 (e,0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
", the verification set",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" in future work, we seek to enable more tasks with recursive structure",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
training setup",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" as with the others, we apply the procedure described in section 3",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
g,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" using this modification, we constructed a verification set consisting of one array of size 10",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
3,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
base cases and reduction rules for topological sort",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
we now report on generalization for the varying tasks,1
", an array for quicksort or a dag for topological sort)",0
 the program terminates when seeing no numbers in the current column,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 the degree for any vertex in the dag is variable,1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" we call this set of inputs the verification set, sv ",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
"
for addition, we analytically determine the verification set",0
g,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
 ,1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
 18: push lo and p− 1 to slo and shi,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
g,0
"
we describe the details of the npi model relevant to our contributions",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
 the core controller acts as a dispatcher for the programs,0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
for addition, we analytically determine the verification set",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
3,1
" twc-1409915, darpa under grant no",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
"
move",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 these pointers are referred to as bubble pointers,1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" as with the others, we apply the procedure described in section 3",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
"
grade-school addition",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 these pointers are referred to as bubble pointers,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
 the core controller acts as a dispatcher for the programs,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
e,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
"
inside bubble and reset, there are two operations that can be made recursive",1
 3: begin traversing from vertex 1 in the dag,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
 the core controller acts as a dispatcher for the programs,1
"
move",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
we experiment with two levels of recursion—partial and full",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
bubble sort",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
 this verification phase only needs to be performed once after training,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
", the trace corresponding to the problem “109 + 101”)",0
 we created a program set that reflects the semantics of algorithm 2,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
bubble sort",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" twc-1409915, darpa under grant no",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
3,1
g,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 npi then outputs the return probability and next program and arguments to execute,0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" that is to say, the network does not learn the true program semantics",1
 ,0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
for addition, we analytically determine the verification set",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
we now report on generalization for the varying tasks,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" that is to say, the network does not learn the true program semantics",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
 ,0
g,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
 ,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 recursion enables provably perfect generalization,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" for each length, we test each program on 30 randomly generated problems",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
g,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 indentation indicates the stack is one level deeper than before,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
g,0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" , a1a0 + b1b0} are added properly",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
 3: begin traversing from vertex 1 in the dag,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
g,1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 our experiments use a small number of training examples,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 almost all architectures train on program input/output pairs,0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
3,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
g,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" et+1 ∼ fenv(et, pt, at)",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
", the trace corresponding to the array [3,2])",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 ,0
 b1b0 where no carry operations occur,1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" et+1 ∼ fenv(et, pt, at)",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
"
algorithm 2 shows the topological sort task of interest",1
 these pointers are referred to as bubble pointers,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
the three environment observations aid with control flow in algorithm 2",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
 our experiments use a small number of training examples,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
g,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 there is a (changing) list of neural programs used to accomplish a given task,1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
base cases and reduction rules for bubble sort",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
"
base cases and reduction rules for addition",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
", qstacklo or qstackhi) or to pointer (e",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" however, our concept of recursion for neural programs is general",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
algorithm 2 shows the topological sort task of interest",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
g,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"1; and for bubble sort, appendix a",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
3,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
"
grade school addition",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
3,1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" each time a subprogram is called, the stack depth increases",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
3 to construct v and then empirically create a verification set which covers v ,0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
6,1
 indentation indicates the stack is one level deeper than before,1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
"
arg 2 (increment or decrement): up, down
swap",1
 npi then outputs the return probability and next program and arguments to execute,1
 u varies with the number of vertices in the graph,1
"
training setup",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 ,0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
g,0
", the trace corresponding to the array [3,2])",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
we experiment with two levels of recursion—partial and full",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
g,1
g,0
" for each length, we test each program on 30 randomly generated problems",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" however, our concept of recursion for neural programs is general",0
 ,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
e,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
we now report on generalization for the varying tasks,0
 ,0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
"
move",1
" et+1 ∼ fenv(et, pt, at)",0
 ,0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
", the verification set",1
 we outline how to construct this set,0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
"
for addition, we analytically determine the verification set",0
 the original version of the bubblesort implementation exposes the values within the array,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 this verification phase only needs to be performed once after training,0
 our experiments use a small number of training examples,1
g,0
g,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 this algorithm is a variant of depth first search,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 recursion enables provably perfect generalization,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 the program terminates when seeing no numbers in the current column,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 ,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 recursion can be implemented differently for different neural programming models,0
 we outline how to construct this set,1
" on the other hand, the recursive programs have learned the true program semantics",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
grade-school addition",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 we adapt machinery from the original paper slightly to fit our needs,1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
g,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" in future work, we seek to enable more tasks with recursive structure",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
this material is in part based upon work supported by the national science foundation under grant no,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"
base cases and reduction rules for quicksort",0
" as aforementioned, the npi model naturally supports recursion",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" , n , where the dag contains n vertices",0
"
we describe the details of the npi model relevant to our contributions",0
 we created a program set that reflects the semantics of algorithm 2,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
"
topological sort",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
 we adapt machinery from the original paper slightly to fit our needs,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
3,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 we found that changing the npi training traces is a simple way to enable this,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 ,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
 18: push lo and p− 1 to slo and shi,0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
this material is in part based upon work supported by the national science foundation under grant no,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
5,0
"
quicksort",0
"
base cases and reduction rules for bubble sort",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" in this architecture, we consider a core controller, e",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 ,0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
", the trace corresponding to the array [3,2])",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
g,0
", an array for quicksort or a dag for topological sort)",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
 the program terminates when seeing no numbers in the current column,0
"
as in line 13 of the right-hand side of figure 1",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" each time a subprogram is called, the stack depth increases",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
base cases and reduction rules for topological sort",1
" in all experiments, α is set to 0",1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
"
base cases and reduction rules for addition",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 reset represents a −∞ value,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
the npi accesses an external environment, q, which varies according to the task",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
 the degree for any vertex in the dag is variable,1
g,0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
g,1
 18: push lo and p− 1 to slo and shi,0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
", an lstm in npi’s case, but possibly other networks in different cases",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" lshift moves the four pointers to the left, to move to the next column",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
", the trace corresponding to the problem “109 + 101”)",1
 our experiments use a small number of training examples,0
"
quicksort",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
 ,1
 figure 2 shows examples of traces for the different versions of bubble sort,1
 almost all architectures train on program input/output pairs,0
", the verification set",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
", to change the value of vactive) none described below move move a pointer (e",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 reset represents a −∞ value,0
 a1a0 + bnbn−1 ,1
 npi then outputs the return probability and next program and arguments to execute,0
e,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
quicksort",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
"
arg 2 (increment or decrement): up, down
swap",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
this material is in part based upon work supported by the national science foundation under grant no,1
g,0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
2,1
 the core controller acts as a dispatcher for the programs,1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
 the first is the actual model architecture,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
", to color a vertex) or variable (e",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
g,0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
3,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
"
algorithm 2 shows the topological sort task of interest",1
 the training set for addition contains 200 traces,1
 we outline how to construct this set,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
" for each length, we test each program on 30 randomly generated problems",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
topological sort",0
 indentation indicates the stack is one level deeper than before,0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
as in line 13 of the right-hand side of figure 1",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
e,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
"
we propose and describe our verification procedure",1
 ,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 the original version of the bubblesort implementation exposes the values within the array,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
3,0
3,1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" in this architecture, we consider a core controller, e",1
" for each length, we test each program on 30 randomly generated problems",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
 these pointers are referred to as bubble pointers,1
"
to perform the verification as described here, it is critical to construct v correctly",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
 npi then outputs the return probability and next program and arguments to execute,0
"
algorithm 2 shows the topological sort task of interest",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
 ,1
 we adapt machinery from the original paper slightly to fit our needs,1
", to change the value of phi) none described belowstack",1
"
to perform the verification as described here, it is critical to construct v correctly",1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" , a1a0 + b1b0} are added properly",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
g,0
3 to construct v and then empirically create a verification set which covers v ,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
 the original version of the bubblesort implementation exposes the values within the array,1
" in particular, recursion can be implemented as a program calling itself",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" on the other hand, the recursive programs have learned the true program semantics",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
", the trace corresponding to the problem “109 + 101”)",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 the program terminates when seeing no numbers in the current column,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 we found that changing the npi training traces is a simple way to enable this,1
" as with the others, we apply the procedure described in section 3",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 the environment and return probability are omitted for readability,0
", the verification set",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
"
bubble sort",1
"
the npi accesses an external environment, q, which varies according to the task",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
the three environment observations aid with control flow in algorithm 2",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
"1; and for bubble sort, appendix a",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
quicksort",1
", to change the value of vactive) none described below move move a pointer (e",1
 ,1
 a1a0 + bnbn−1 ,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
"
base cases and reduction rules for topological sort",1
 u varies with the number of vertices in the graph,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" we call this set of inputs the verification set, sv ",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 ,0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 u varies with the number of vertices in the graph,1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" in particular, recursion can be implemented as a program calling itself",1
", to change the value of phi) none described belowstack",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
"
algorithm 2 shows the topological sort task of interest",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 the maximum problem length in this training set is 3 (e,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" in all experiments, α is set to 0",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
bubble sort",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
 the degree for any vertex in the dag is variable,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
 the core controller acts as a dispatcher for the programs,1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" fa8750-15-2-0104, and berkeley deep drive",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" for each length, we test each program on 30 randomly generated problems",1
 ,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" however, our concept of recursion for neural programs is general",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
the three environment observations aid with control flow in algorithm 2",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
move",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 figure 2 shows examples of traces for the different versions of bubble sort,1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" for each length, we test each program on 30 randomly generated problems",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
5,1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
arg 2 (increment or decrement): up, down
swap",1
 almost all architectures train on program input/output pairs,1
 18: push lo and p− 1 to slo and shi,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
e,1
"
move",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"
training setup",1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
"1; and for bubble sort, appendix a",0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
 we found that changing the npi training traces is a simple way to enable this,1
as mentioned in section 2,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 recursion can be implemented differently for different neural programming models,0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
", to change the value of vactive) none described below move move a pointer (e",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
we now report on generalization for the varying tasks,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
we describe the details of the npi model relevant to our contributions",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
g,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the first is the actual model architecture,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
 the environment and return probability are omitted for readability,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
3,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
3,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
 our experiments use a small number of training examples,1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
" et+1 ∼ fenv(et, pt, at)",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
 this verification phase only needs to be performed once after training,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
 we outline how to construct this set,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
g,0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
3 to construct v and then empirically create a verification set which covers v ,0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" as aforementioned, the npi model naturally supports recursion",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
we now report on generalization for the varying tasks,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
g,0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 npi then outputs the return probability and next program and arguments to execute,1
6,1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 3: begin traversing from vertex 1 in the dag,1
e,1
 the training set for addition contains 200 traces,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" however, our concept of recursion for neural programs is general",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
", to change the value of vactive) none described below move move a pointer (e",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
 recursion can be implemented differently for different neural programming models,1
 a1a0 + bnbn−1 ,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
3,1
" on the other hand, the recursive programs have learned the true program semantics",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
", an array for quicksort or a dag for topological sort)",1
" in this architecture, we consider a core controller, e",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
"1; and for bubble sort, appendix a",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
 a1a0 + bnbn−1 ,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
the npi accesses an external environment, q, which varies according to the task",1
g,1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
3,1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
"
we describe the details of the npi model relevant to our contributions",1
3,0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
g,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
move",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
the three environment observations aid with control flow in algorithm 2",1
", to change the value of phi) none described belowstack",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" on the other hand, the recursive programs have learned the true program semantics",1
 the maximum problem length in this training set is 3 (e,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 this algorithm is a variant of depth first search,0
"
algorithm 2 shows the topological sort task of interest",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
", to change the value of vactive) none described below move move a pointer (e",1
"
bubble sort",0
 the environment and return probability are omitted for readability,0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
"
move",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 this verification phase only needs to be performed once after training,0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" in future work, we seek to enable more tasks with recursive structure",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
 recursion can be implemented differently for different neural programming models,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
 the core controller acts as a dispatcher for the programs,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
we describe the details of the npi model relevant to our contributions",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
g,1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 npi then outputs the return probability and next program and arguments to execute,1
"
arg 2 (increment or decrement): up, down
swap",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
training setup",1
this material is in part based upon work supported by the national science foundation under grant no,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
", an lstm in npi’s case, but possibly other networks in different cases",0
this material is in part based upon work supported by the national science foundation under grant no,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
 ,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
move",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
" , n , where the dag contains n vertices",0
"
we propose and describe our verification procedure",1
", the trace corresponding to the array [3,2])",0
g,1
 a1a0 + bnbn−1 ,0
 we outline how to construct this set,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
e,1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
grade-school addition",1
e,1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
bubble sort",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 ,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
"
base cases and reduction rules for addition",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
6,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 we choose to implement a topological sort task for graphs,1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
"
grade-school addition",0
 a1a0 + bnbn−1 ,0
g,0
"
as in line 13 of the right-hand side of figure 1",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" each time a subprogram is called, the stack depth increases",0
g,0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
g,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
 ,0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" we call this set of inputs the verification set, sv ",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
6,1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" lshift moves the four pointers to the left, to move to the next column",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" in this architecture, we consider a core controller, e",0
g,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" that is to say, the network does not learn the true program semantics",0
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" on the other hand, the recursive programs have learned the true program semantics",1
"
the three environment observations aid with control flow in algorithm 2",1
", the verification set",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
 b1b0 where no carry operations occur,1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
"
training setup",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
 the training set for addition contains 200 traces,1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
", the verification set",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
"
we experiment with two levels of recursion—partial and full",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
as mentioned in section 2,0
"
base cases and reduction rules for quicksort",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 ,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
 ,1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 there is a (changing) list of neural programs used to accomplish a given task,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
g,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
g,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" , a1a0 + b1b0} are added properly",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",1
" for each length, we test each program on 30 randomly generated problems",1
 npi then outputs the return probability and next program and arguments to execute,0
"
move",0
"
inside bubble and reset, there are two operations that can be made recursive",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
 recursion enables provably perfect generalization,1
 ,1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
as mentioned in section 2,0
" as aforementioned, the npi model naturally supports recursion",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
3 to construct v and then empirically create a verification set which covers v ,0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
", the verification set",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
e,1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" that is to say, the network does not learn the true program semantics",0
g,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
 the environment and return probability are omitted for readability,0
", the trace corresponding to the array [3,2])",0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
"
base cases and reduction rules for topological sort",0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
"
quicksort",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" that is to say, the network does not learn the true program semantics",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
3,0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 the environment and return probability are omitted for readability,1
", to change the value of phi) none described belowstack",0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
"
base cases and reduction rules for topological sort",0
 this algorithm is a variant of depth first search,1
", qstacklo or qstackhi) or to pointer (e",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 there is a (changing) list of neural programs used to accomplish a given task,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
"
base cases and reduction rules for quicksort",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
 there is a (changing) list of neural programs used to accomplish a given task,0
g,1
6,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
g,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 18: push lo and p− 1 to slo and shi,1
", an array for quicksort or a dag for topological sort)",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" in future work, we seek to enable more tasks with recursive structure",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
", the trace corresponding to the array [3,2])",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" fa8750-15-2-0104, and berkeley deep drive",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
we now report on generalization for the varying tasks,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 the maximum problem length in this training set is 3 (e,1
3 to construct v and then empirically create a verification set which covers v ,0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
 these pointers are referred to as bubble pointers,0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
bubble sort",1
"
for addition, we analytically determine the verification set",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" we call this set of inputs the verification set, sv ",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
" in future work, we seek to enable more tasks with recursive structure",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
 this algorithm is a variant of depth first search,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
"
the three environment observations aid with control flow in algorithm 2",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
"
training setup",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
g,0
 the original version of the bubblesort implementation exposes the values within the array,0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
 the first is the actual model architecture,0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" et+1 ∼ fenv(et, pt, at)",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
", the trace corresponding to the array [3,2])",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
 the original version of the bubblesort implementation exposes the values within the array,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
", to change the value of vactive) none described below move move a pointer (e",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
we now report on generalization for the varying tasks,0
 recursion enables provably perfect generalization,1
"
we experiment with two levels of recursion—partial and full",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
base cases and reduction rules for bubble sort",0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
 this verification phase only needs to be performed once after training,1
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
algorithm 2 shows the topological sort task of interest",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" in all experiments, α is set to 0",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
"1; and for bubble sort, appendix a",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
grade school addition",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 this verification phase only needs to be performed once after training,0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
 we adapt machinery from the original paper slightly to fit our needs,0
" in future work, we seek to enable more tasks with recursive structure",0
3 to construct v and then empirically create a verification set which covers v ,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
", qstacklo or qstackhi) or to pointer (e",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
"
algorithm 2 shows the topological sort task of interest",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
g,1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" for each length, we test each program on 30 randomly generated problems",1
"
we propose and describe our verification procedure",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" as with the others, we apply the procedure described in section 3",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
 ,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
 ,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
 these pointers are referred to as bubble pointers,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
", an array for quicksort or a dag for topological sort)",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
"
we experiment with two levels of recursion—partial and full",0
 18: push lo and p− 1 to slo and shi,0
g,0
g,0
" using this modification, we constructed a verification set consisting of one array of size 10",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
 the original version of the bubblesort implementation exposes the values within the array,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
 ,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
3,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 this verification phase only needs to be performed once after training,0
", to color a vertex) or variable (e",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
g,1
g,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
3,1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
", the verification set",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 we outline how to construct this set,0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 ,0
"
for addition, we analytically determine the verification set",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
"
grade school addition",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
 this makes it difficult to reason about what the model will do when given complex inputs,0
"
bubble sort",0
"
base cases and reduction rules for quicksort",0
"
the npi accesses an external environment, q, which varies according to the task",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
g,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" , a1a0 + b1b0} are added properly",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
 indentation indicates the stack is one level deeper than before,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
base cases and reduction rules for quicksort",0
", the trace corresponding to the array [3,2])",1
"
we experiment with two levels of recursion—partial and full",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" for each length, we test each program on 30 randomly generated problems",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 the core controller acts as a dispatcher for the programs,0
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
"
we describe the details of the npi model relevant to our contributions",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
algorithm 2 shows the topological sort task of interest",0
 u varies with the number of vertices in the graph,1
"
in this paper, we propose that recursion is an important concept for neural programs as well",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
 this algorithm is a variant of depth first search,0
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
the three environment observations aid with control flow in algorithm 2",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
to perform the verification as described here, it is critical to construct v correctly",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
the npi accesses an external environment, q, which varies according to the task",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
"
base cases and reduction rules for topological sort",0
 the first is the actual model architecture,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 ,0
 18: push lo and p− 1 to slo and shi,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
training setup",0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 we created a program set that reflects the semantics of algorithm 2,1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
e,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" , a1a0 + b1b0} are added properly",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
", the trace corresponding to the problem “109 + 101”)",1
 18: push lo and p− 1 to slo and shi,1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
"
bubble sort",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 almost all architectures train on program input/output pairs,0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"
base cases and reduction rules for topological sort",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
3 to construct v and then empirically create a verification set which covers v ,1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
we now report on generalization for the varying tasks,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
g,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" we call this set of inputs the verification set, sv ",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" for each length, we test each program on 30 randomly generated problems",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
"
quicksort",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
 the degree for any vertex in the dag is variable,1
"
we propose and describe our verification procedure",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
"
algorithm 2 shows the topological sort task of interest",0
"
grade-school addition",0
", qstacklo or qstackhi) or to pointer (e",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
", the trace corresponding to the array [3,2])",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
", to change the value of phi) none described belowstack",0
e,0
2,0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
g,1
" , a1a0 + b1b0} are added properly",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
5,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
 we created a program set that reflects the semantics of algorithm 2,0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
3,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" lshift moves the four pointers to the left, to move to the next column",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 there is a (changing) list of neural programs used to accomplish a given task,0
" in all experiments, α is set to 0",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
 reset represents a −∞ value,1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
"
grade school addition",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"
the npi accesses an external environment, q, which varies according to the task",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"
base cases and reduction rules for quicksort",0
", the trace corresponding to the problem “109 + 101”)",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
 we found that changing the npi training traces is a simple way to enable this,1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
move",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
this material is in part based upon work supported by the national science foundation under grant no,1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
 ,1
g,1
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
g,1
"
bubble sort",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
bubble sort",0
"6) on the verification set, and ensure they match the traces produced by the true program p ",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 the maximum problem length in this training set is 3 (e,0
 3: begin traversing from vertex 1 in the dag,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
", qstacklo or qstackhi) or to pointer (e",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
base cases and reduction rules for quicksort",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" twc-1409915, darpa under grant no",0
 indentation indicates the stack is one level deeper than before,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" however, our concept of recursion for neural programs is general",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"
the npi accesses an external environment, q, which varies according to the task",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
" in particular, recursion can be implemented as a program calling itself",0
"
we propose and describe our verification procedure",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
3 to construct v and then empirically create a verification set which covers v ,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
g,0
" for each length, we test each program on 30 randomly generated problems",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
"
base cases and reduction rules for bubble sort",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 b1b0 where no carry operations occur,0
", the trace corresponding to the array [3,2])",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
"
base cases and reduction rules for addition",1
 we adapt machinery from the original paper slightly to fit our needs,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
 u varies with the number of vertices in the graph,0
 18: push lo and p− 1 to slo and shi,0
 the program terminates when seeing no numbers in the current column,0
"
arg 2 (increment or decrement): up, down
swap",0
"
we experiment with two levels of recursion—partial and full",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 we outline how to construct this set,0
g,1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
 indentation indicates the stack is one level deeper than before,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
 reset represents a −∞ value,0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" as aforementioned, the npi model naturally supports recursion",0
 the maximum problem length in this training set is 3 (e,0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
"
quicksort",0
"
grade school addition",0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
 recursion can be implemented differently for different neural programming models,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" that is to say, the network does not learn the true program semantics",1
" in particular, recursion can be implemented as a program calling itself",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 reset represents a −∞ value,0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
as mentioned in section 2,1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" twc-1409915, darpa under grant no",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
6,1
 ,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
3,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
"
the three environment observations aid with control flow in algorithm 2",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
e,1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
base cases and reduction rules for topological sort",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
", to change the value of phi) none described belowstack",0
g,1
"
topological sort",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"
topological sort",1
 b1b0 where no carry operations occur,1
 ,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
g,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
 we found that changing the npi training traces is a simple way to enable this,0
3,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"
bubble sort",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",1
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
"
grade school addition",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
", to change the value of vactive) none described below move move a pointer (e",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
" as with the others, we apply the procedure described in section 3",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" for each length, we test each program on 30 randomly generated problems",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
g,0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" fa8750-15-2-0104, and berkeley deep drive",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
we now report on generalization for the varying tasks,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
"
as in line 13 of the right-hand side of figure 1",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
"
bubble sort",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
 this algorithm is a variant of depth first search,0
" for each length, we test each program on 30 randomly generated problems",0
g,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
g,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",1
 indentation indicates the stack is one level deeper than before,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
e,0
"
we describe the details of the npi model relevant to our contributions",0
g,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" lshift moves the four pointers to the left, to move to the next column",1
 a1a0 + bnbn−1 ,0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" , n , where the dag contains n vertices",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
3 to construct v and then empirically create a verification set which covers v ,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"1; and for bubble sort, appendix a",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
", to change the value of phi) none described belowstack",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
 b1b0 where no carry operations occur,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
 ,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
g,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
" for each length, we test each program on 30 randomly generated problems",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
"
quicksort",0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 the original version of the bubblesort implementation exposes the values within the array,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
3 to construct v and then empirically create a verification set which covers v ,0
"
training setup",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
"
the npi accesses an external environment, q, which varies according to the task",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
g,1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
g,0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
" , n , where the dag contains n vertices",0
 the core controller acts as a dispatcher for the programs,1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
" in future work, we seek to enable more tasks with recursive structure",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
"
the npi accesses an external environment, q, which varies according to the task",0
"
we propose and describe our verification procedure",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
 we adapt machinery from the original paper slightly to fit our needs,0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
", to change the value of vactive) none described below move move a pointer (e",1
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",1
6,1
 we leave this as future work to devise a verification procedure more appropriate to this setting,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
e,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
 the original version of the bubblesort implementation exposes the values within the array,0
 reset represents a −∞ value,1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
6,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"1; and for bubble sort, appendix a",0
 almost all architectures train on program input/output pairs,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 ,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" in future work, we seek to enable more tasks with recursive structure",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
" however, our concept of recursion for neural programs is general",0
"
grade school addition",1
" in this architecture, we consider a core controller, e",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
"
as in line 13 of the right-hand side of figure 1",0
 figure 2 shows examples of traces for the different versions of bubble sort,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
 ,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
"
for addition, we analytically determine the verification set",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"
move",1
 reset represents a −∞ value,1
"
as in line 13 of the right-hand side of figure 1",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" however, our concept of recursion for neural programs is general",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
g,0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
 the environment and return probability are omitted for readability,1
" in all experiments, α is set to 0",1
", the verification set",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
 the first is the actual model architecture,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
the npi accesses an external environment, q, which varies according to the task",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
" for each length, we test each program on 30 randomly generated problems",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
grade school addition",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
", to change the value of phi) none described belowstack",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
"
training setup",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
"
the non-recursive trace loops on cycles of add1 and lshift",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
 the training set for addition contains 200 traces,0
", the trace corresponding to the array [3,2])",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
quicksort",1
 our experiments use a small number of training examples,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
g,1
"
move",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
 ,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" we call this set of inputs the verification set, sv ",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
6,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
we describe the details of the npi model relevant to our contributions",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
g,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 the core controller acts as a dispatcher for the programs,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
"
base cases and reduction rules for topological sort",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
 b1b0 where no carry operations occur,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
 almost all architectures train on program input/output pairs,1
3 to construct v and then empirically create a verification set which covers v ,0
 we choose to implement a topological sort task for graphs,1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,1
 almost all architectures train on program input/output pairs,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
3,0
 we adapt machinery from the original paper slightly to fit our needs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
"
base cases and reduction rules for quicksort",0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
g,1
" as with the others, we apply the procedure described in section 3",0
" fa8750-15-2-0104, and berkeley deep drive",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
g,1
g,1
" in future work, we seek to enable more tasks with recursive structure",0
" however, our concept of recursion for neural programs is general",0
 ,0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
" et+1 ∼ fenv(et, pt, at)",0
"
base cases and reduction rules for topological sort",0
g,0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
", qstacklo or qstackhi) or to pointer (e",1
"
base cases and reduction rules for addition",0
"
grade school addition",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
topological sort",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
", an lstm in npi’s case, but possibly other networks in different cases",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
g,1
 indentation indicates the stack is one level deeper than before,1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
", the trace corresponding to the array [3,2])",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
", the verification set",1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
e,0
"
base cases and reduction rules for topological sort",0
" in this architecture, we consider a core controller, e",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 the program terminates when seeing no numbers in the current column,0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" for each length, we test each program on 30 randomly generated problems",0
 recursion can be implemented differently for different neural programming models,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
"
for addition, we analytically determine the verification set",0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
 this verification phase only needs to be performed once after training,1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
 18: push lo and p− 1 to slo and shi,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 3: begin traversing from vertex 1 in the dag,0
"
topological sort",0
", an array for quicksort or a dag for topological sort)",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 ,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
 we found that changing the npi training traces is a simple way to enable this,1
" et+1 ∼ fenv(et, pt, at)",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
 ,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
"1; and for bubble sort, appendix a",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 ,0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
g,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"1; and for bubble sort, appendix a",1
" in future work, we seek to enable more tasks with recursive structure",1
 we choose to implement a topological sort task for graphs,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" in this architecture, we consider a core controller, e",1
g,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
"
algorithm 2 shows the topological sort task of interest",0
" twc-1409915, darpa under grant no",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" however, our concept of recursion for neural programs is general",0
" we call this set of inputs the verification set, sv ",1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
 we found that changing the npi training traces is a simple way to enable this,1
 we adapt machinery from the original paper slightly to fit our needs,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" lshift moves the four pointers to the left, to move to the next column",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",0
 this verification phase only needs to be performed once after training,1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
algorithm 2 shows the topological sort task of interest",1
"
we propose and describe our verification procedure",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" lshift moves the four pointers to the left, to move to the next column",1
 u varies with the number of vertices in the graph,1
"
bubble sort",0
"
base cases and reduction rules for quicksort",1
 ,0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" for each graph size, we test the learned programs on 30 randomly generated dags",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" fa8750-15-2-0104, and berkeley deep drive",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" as with the others, we apply the procedure described in section 3",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
the npi accesses an external environment, q, which varies according to the task",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
2,1
 the first is the actual model architecture,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
", to change the value of vactive) none described below move move a pointer (e",0
"
quicksort",1
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 ,1
this material is in part based upon work supported by the national science foundation under grant no,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
g,1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
", qstacklo or qstackhi) or to pointer (e",1
"
move",0
" in future work, we seek to enable more tasks with recursive structure",0
" in future work, we seek to enable more tasks with recursive structure",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
3,0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 ,1
 almost all architectures train on program input/output pairs,0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
 ,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
" for each length, we test each program on 30 randomly generated problems",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
"
topological sort",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",1
 u varies with the number of vertices in the graph,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
"
the three environment observations aid with control flow in algorithm 2",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
figure 1 shows examples of non-recursive and recursive addition traces",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
"
quicksort",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 almost all architectures train on program input/output pairs,0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 the maximum problem length in this training set is 3 (e,1
 b1b0 where no carry operations occur,0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
bubble sort",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
g,1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
", the trace corresponding to the array [3,2])",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
e,0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" each time a subprogram is called, the stack depth increases",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",0
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
for addition, we analytically determine the verification set",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
", to color a vertex) or variable (e",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" that is to say, the network does not learn the true program semantics",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" on the other hand, the recursive programs have learned the true program semantics",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"
topological sort",0
 indentation indicates the stack is one level deeper than before,1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
 these pointers are referred to as bubble pointers,1
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
"
base cases and reduction rules for quicksort",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
", to change the value of phi) none described belowstack",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",0
"
as in line 13 of the right-hand side of figure 1",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
", an lstm in npi’s case, but possibly other networks in different cases",1
 the core controller acts as a dispatcher for the programs,1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
to perform the verification as described here, it is critical to construct v correctly",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
g,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
 we choose to implement a topological sort task for graphs,0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
g,0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 this verification phase only needs to be performed once after training,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
we propose and describe our verification procedure",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
arg 2 (increment or decrement): up, down
swap",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",0
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
" , a1a0 + b1b0} are added properly",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" twc-1409915, darpa under grant no",0
"
base cases and reduction rules for addition",0
"
to perform the verification as described here, it is critical to construct v correctly",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",1
"
there are 6 pointers (plo, phi, pstacklo, pstackhi, ppivot, pj)",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" as with the others, we apply the procedure described in section 3",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",1
", to change the value of phi) none described belowstack",1
" we call this set of inputs the verification set, sv ",0
 ,1
this material is in part based upon work supported by the national science foundation under grant no,1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
"
quicksort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" for each length, we test each program on 30 randomly generated problems",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 we choose to implement a topological sort task for graphs,1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 this algorithm is a variant of depth first search,0
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
"
grade-school addition",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 our experiments use a small number of training examples,1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
" however, our concept of recursion for neural programs is general",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
 the environment and return probability are omitted for readability,1
"
to perform the verification as described here, it is critical to construct v correctly",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 the maximum problem length in this training set is 3 (e,0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
"
base cases and reduction rules for quicksort",1
 recursion enables provably perfect generalization,0
 3: begin traversing from vertex 1 in the dag,1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
"
quicksort",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
"
to perform the verification as described here, it is critical to construct v correctly",0
" provably perfect generalization implies the model will behave correctly, given any valid input",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
", an array for quicksort or a dag for topological sort)",1
 the original version of the bubblesort implementation exposes the values within the array,1
"
the non-recursive trace loops on cycles of add1 and lshift",0
6,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" , n , where the dag contains n vertices",1
 the degree for any vertex in the dag is variable,0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" , a1a0 + b1b0} are added properly",0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"1; and for bubble sort, appendix a",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
g,0
 recursion enables provable guarantees on neural programs’ behavior without needing to exhaustively enumerate all possible inputs to the programs,1
 u varies with the number of vertices in the graph,0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
", to color a vertex) or variable (e",0
3 to construct v and then empirically create a verification set which covers v ,0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
move",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
we now report on generalization for the varying tasks,0
" as aforementioned, the npi model naturally supports recursion",0
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
"
inside bubble and reset, there are two operations that can be made recursive",1
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" fa8750-15-2-0104, and berkeley deep drive",0
" for each length, we test each program on 30 randomly generated problems",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
"
we describe the details of the npi model relevant to our contributions",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
"
base cases and reduction rules for addition",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" for example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
"
move",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
to perform the verification as described here, it is critical to construct v correctly",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",1
", the verification set",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
g,0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",0
"
topological sort",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
3,0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
g,0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
"
for addition, we analytically determine the verification set",0
 this verification phase only needs to be performed once after training,1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
3,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
 we outline how to construct this set,0
 this makes it difficult to reason about what the model will do when given complex inputs,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" in this architecture, we consider a core controller, e",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
 a1a0 + bnbn−1 ,1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
3,0
 3: begin traversing from vertex 1 in the dag,1
"1; and for bubble sort, appendix a",0
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
we propose and describe our verification procedure",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",1
"
inside bubble and reset, there are two operations that can be made recursive",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
we now report on generalization for the varying tasks,1
", pstart or childlist[vactive]) up or down none described belowwrite",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
3,0
 3: begin traversing from vertex 1 in the dag,0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" et+1 ∼ fenv(et, pt, at)",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 the original version of the bubblesort implementation exposes the values within the array,0
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",0
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
", the trace corresponding to the problem “109 + 101”)",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
base cases and reduction rules for bubble sort",1
"
quicksort",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" for each length, we test each program on 30 randomly generated problems",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
2,1
"
grade-school addition",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
grade-school addition",1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 b1b0 where no carry operations occur,0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
 this algorithm is a variant of depth first search,1
 ,0
e,1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
e,1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
", to color a vertex) or variable (e",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
g,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",1
 this makes it difficult to reason about what the model will do when given complex inputs,0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" in order to compensate for this, ppivot and pj require special functions (move pivot lo and move j lo) to properly set them to lo in lines 11 and 12 of the partition function in algorithm 3",0
3,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
"
grade school addition",0
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" for each length, we test each program on 30 randomly generated problems",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" as aforementioned, the npi model naturally supports recursion",0
3,0
g,0
g,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
 the training set for addition contains 200 traces,0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
g,0
" twc-1409915, darpa under grant no",0
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
" that is to say, the network does not learn the true program semantics",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
g,0
 ,0
 indentation indicates the stack is one level deeper than before,0
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",0
g,1
 this algorithm is a variant of depth first search,1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" , n , where the dag contains n vertices",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
 the environment and return probability are omitted for readability,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
this material is in part based upon work supported by the national science foundation under grant no,0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
"
base cases and reduction rules for addition",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
" using this modification, we constructed a verification set consisting of one array of size 10",1
 almost all architectures train on program input/output pairs,0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
g,0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" on the other hand, the recursive programs have learned the true program semantics",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
e,0
"
topological sort",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
" as aforementioned, the npi model naturally supports recursion",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 the program terminates when seeing no numbers in the current column,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",0
 this modification also enables us to sort arrays containing arbitrary comparable elements,1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
"
move",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
"
note that the recursion for quicksort is not purely tail recursive and therefore represents a more complex kind of recursion that is harder to learn than in the previous tasks",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
"
quicksort",0
"
bubble sort",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 ,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
5,1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 we outline how to construct this set,1
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
 ,1
"6) on the verification set, and ensure they match the traces produced by the true program p ",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
g,0
2,0
", qstacklo or qstackhi) or to pointer (e",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
"
inside bubble and reset, there are two operations that can be made recursive",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",0
" for each length, we test each program on 30 randomly generated problems",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 we adapt machinery from the original paper slightly to fit our needs,1
"
the non-recursive trace loops on cycles of add1 and lshift",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 the first is the actual model architecture,1
 ,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" for each graph size, we test the learned programs on 30 randomly generated dags",1
", the trace corresponding to the problem “109 + 101”)",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 the core controller acts as a dispatcher for the programs,1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
g,1
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
" we can obtain this mapping by first considering the possible observations that can arise at the beginning of the entry function (add, bubblesort, toposort, and quicksort) for some valid program input, and iteratively applying the observation-to-observation mapping implied by the reference implementation’s step output at that point in the execution",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
", pstart or childlist[vactive]) up or down none described belowwrite",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
 this algorithm is a variant of depth first search,0
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
g,1
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",1
e,0
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",1
we now report on generalization for the varying tasks,1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
g,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
 b1b0 where no carry operations occur,1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
"
algorithm 2 shows the topological sort task of interest",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
algorithm 2 shows the topological sort task of interest",0
"
bubble sort",1
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,1
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 ,1
" also, compared to the bubble pointers in bubble sort, the pointers that perform the comparison for quicksort (the compswap function) are usually not adjacent to each other, making quicksort less local than bubble sort",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
3 to construct v and then empirically create a verification set which covers v ,1
"
quicksort",1
 the program terminates when seeing no numbers in the current column,1
e,0
 the program terminates when seeing no numbers in the current column,0
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
 3: begin traversing from vertex 1 in the dag,0
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
 ,0
" in this architecture, we consider a core controller, e",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
grade school addition",0
3,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" given a precise definition of p , it may be possible to automate the generation of v from p in future work",1
"
for addition, we analytically determine the verification set",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",1
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",0
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" for these programs, we re-use the appropriate program sets (the associated subprograms), and we refer the reader to the appendix of reed & de freitas (2016) for further details on the subprograms used in addition and bubble sort",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
"
the three environment observations aid with control flow in algorithm 2",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" observe that the non-recursive program’s correctness degrades for length 11 and beyond, while the recursive program can sort any given array",1
 ,1
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" lshift moves the four pointers to the left, to move to the next column",1
" , n , where the dag contains n vertices",1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
this material is in part based upon work supported by the national science foundation under grant no,0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
"
grade-school addition",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
" in this architecture, we consider a core controller, e",1
g,0
", to color a vertex) or variable (e",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" fa8750-15-2-0104, and berkeley deep drive",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
"
bubble sort",0
" as before, the non-recursive learned program lacks a provable guarantee of generalization, whereas we show later that the recursive learned program has one",1
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
 our experiments use a small number of training examples,0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
g,1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
 the degree for any vertex in the dag is variable,0
"
algorithm 2 shows the topological sort task of interest",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
5,0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
g,1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
as mentioned in section 2,0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",1
 the original version of the bubblesort implementation exposes the values within the array,0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",1
 3: begin traversing from vertex 1 in the dag,1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
 the program terminates when seeing no numbers in the current column,0
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
" that is to say, the network does not learn the true program semantics",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",1
", an array for quicksort or a dag for topological sort)",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" , n , where the dag contains n vertices",1
" for each length, we test each program on 30 randomly generated problems",1
"
quicksort",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" however, our concept of recursion for neural programs is general",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" however, our concept of recursion for neural programs is general",0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
quicksort",0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 npi then outputs the return probability and next program and arguments to execute,0
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",1
 u varies with the number of vertices in the graph,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
 ,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
"
algorithm 2 shows the topological sort task of interest",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" lshift, used in reset, shifts the pointers left until reaching the start token",0
g,0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
2,1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 reset represents a −∞ value,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
g,0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" each time a subprogram is called, the stack depth increases",1
 ,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
 3: begin traversing from vertex 1 in the dag,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",1
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",0
"
in this general neural programming architecture, we show it is easy to support recursion",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,1
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 we adapt machinery from the original paper slightly to fit our needs,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
 our experiments use a small number of training examples,0
 ,0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
 reset represents a −∞ value,1
 almost all architectures train on program input/output pairs,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
arg 2 (increment or decrement): up, down1 // top level topological sort call 2 toposort() { 3 while (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 } 0 11 traverse() { 12 check_child() 13 explore() 14 } 15 16 check_child() { 17 while (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 18 move(childlist[vactive], up) 19 } 20 21 explore() { 22 do 23 if (qcolor(dag[vactive][childlist[vactive]]) is white): 24 write(color_next, color_grey) 25 stack(push) 26 write(save) 27 write(active_neighb) 28 move(childlist[vsave], up) 29 else: 30 write(color_curr, color_black) 31 write(result) 32 move(presult, up) 33 if(pstack == 1): 34 break 35 else: 36 stack(pop) 37 check_child() 38 while (true) 39 } 40 41 stack(op) { 42 if (op == push): 43 write(stack_push) 44 move(pstack, up) 45 46 if (op == pop): 47 write(active_stack) 48 write(stack_pop) 49 move(pstack, down) 50 } 51 52 next_start() { 53 while(qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 54 move(pstart, up) 55 }altered recursive functions  // top level topological sort call 2 toposort() { 3 if (qcolor(pstart) is a valid color): // color invalid when all vertices explored 4 write(active_start) 5 write(color_curr, color_grey) 6 traverse() 7 move(pstart, up) 8 next_start() 9 toposort() // recursive call 0 } 11 12 check_child() { 13 if (qcolor(dag[vactive][childlist[vactive]]) is not white and is not invalid): // color invalid when all children explored 14 move(childlist[vactive], up) 15 check_child() // recursive call 16 } 17 18 explore() { 19 if (qcolor(dag[vactive][childlist[vactive]]) is white): 20 write(color_next, color_grey) 21 stack(push) 22 write(save) 23 write(active_neighb) 24 move(childlist[vsave], up) 25 else: 26 write(color_curr, color_black) 27 write(result) 28 move(presult, up) 29 if(pstack == 1): 30 return 31 else: 32 stack(pop) 33 check_child() 34 explore() // recursive call 35 } 36 37 next_start() { 38 if (qcolor(pstart) is not white and is not invalid): // color invalid when all vertices explored 39 move(pstart, up) 40 next_start() // recursive call 41 }algorithm 4 iterative quicksort 1: initialize an array a to sort and two empty stacks slo and shi",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",0
 u varies with the number of vertices in the graph,0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" lshift moves the four pointers to the left, to move to the next column",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 our experiments use a small number of training examples,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
 ,0
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
 we created a program set that reflects the semantics of algorithm 2,0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 this procedure verifies that all base cases and reductions are handled properly by the model via explicit tests,0
", to change the value of phi) none described belowstack",1
" each time a subprogram is called, the stack depth increases",0
" in this pair, the step input runs a subprogram add1 that has no arguments, and the step output contains a program write that has arguments of out and 1",0
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" in fact, we argue that recursion is an essential element for neural programs to generalize, and makes it tractable to prove the generalization of neural programs",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 recursion can be implemented differently for different neural programming models,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
 recursion can be implemented differently for different neural programming models,1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" for each function we use to implement the recursive version of topological sort, we need to consider the set of possible environment observation sequences we can create from all valid inputs and test that the learned program produces the correct behavior on each of these inputs",0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
 ,1
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" lshift moves the four pointers to the left, to move to the next column",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
", an lstm in npi’s case, but possibly other networks in different cases",0
6,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
", the trace corresponding to the problem “109 + 101”)",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
 ,0
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",1
 ,1
" for each length, we test each program on 30 randomly generated problems",0
"
bubble sort",0
"
we describe the details of the npi model relevant to our contributions",0
" , a1a0 + b1b0} are added properly",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",1
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",0
g,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
"
quicksort",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" we show that by modifying the training procedure, we enable the npi model to learn recursive neural programs",1
", to color a vertex) or variable (e",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",0
"
the three environment observations aid with control flow in algorithm 2",1
"
in order to demonstrate that recursion can help learn and generalize better, for addition, we trained only on traces for 5 arbitrarily chosen 1-digit addition sum examples",0
as mentioned in section 2,1
 ,1
"
as in line 13 of the right-hand side of figure 1",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",1
" we further have qresult ∈ nu , a scratch-pad which contains the sorted list of vertices at the end of execution, and qstack ∈ nu , which serves the role of the stack s in algorithm 2",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
", to change the value of vactive) none described below move move a pointer (e",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" the move operation has the following arguments:
arg 1 (pointer): pstacklo, pstackhi, pj , ppivot
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values",0
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" in all experiments, α is set to 0",1
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
we describe the details of the npi model relevant to our contributions",0
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",0
g,0
" in future work, we seek to enable more tasks with recursive structure",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" in this architecture, we consider a core controller, e",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
 the first is the actual model architecture,0
 the core controller acts as a dispatcher for the programs,0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
"
grade-school addition",1
 ,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 this makes it difficult to reason about what the model will do when given complex inputs,1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
"
the non-recursive trace loops on cycles of add1 and lshift",1
" as with the others, we apply the procedure described in section 3",0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
 we found that changing the npi training traces is a simple way to enable this,1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" in our experiments, we only present dag’s as inputs and represent the vertices as values ranging from 1, ",0
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",0
5,1
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
quicksort",1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
" ppivot and pj point to the pivot and j indices of the array, used in the partition function in algorithm 3",1
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" each time a subprogram is called, the stack depth increases",1
 this verification phase only needs to be performed once after training,1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" each step during an execution of the program does one of three things: (1) another subprogram along with associated arguments is called, as in line 10, (2) the program writes to the environment if it is primitive, as in line 8, or (3) the loop is terminated if the return probability exceeds a threshold α, after which the stack frame is popped and control is returned to the caller",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",0
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
 ,1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
"1; and for bubble sort, appendix a",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",1
 u varies with the number of vertices in the graph,1
" in all experiments, α is set to 0",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
"
training setup",0
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the maximum problem length in this training set is 3 (e,1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
the three environment observations aid with control flow in algorithm 2",0
" however, our concept of recursion for neural programs is general",1
 recursion can be implemented differently for different neural programming models,1
"
algorithm 2 depth first search topological sort 1: color all vertices white",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" in this architecture, we consider a core controller, e",1
" it is straightforward to deal with all other operations, which do not induce partial environment states",1
"
quicksort",0
" training on the full recursive trace leads to perfect generalization, as shown in section 4",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",1
", the verification set",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
 we choose to implement a topological sort task for graphs,1
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
g,0
g,1
 the environment and return probability are omitted for readability,0
"
we refer the reader to the appendix for the non-recursive trace generating functions",1
 18: push lo and p− 1 to slo and shi,0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",0
 recursion enables provably perfect generalization,1
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"
bubble sort",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" lshift, used in reset, shifts the pointers left until reaching the start token",1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
 recursion can be implemented differently for different neural programming models,0
" as aforementioned, the npi model naturally supports recursion",0
this material is in part based upon work supported by the national science foundation under grant no,0
" note that recursion helps make this process tractable, because we only need to test a finite number of inputs to show that the model will work correctly on inputs of unbounded complexity",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
base cases and reduction rules for addition",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
 recursion enables provably perfect generalization,1
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
g,1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" twc-1409915, darpa under grant no",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 ,0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",0
 table 3 presents results on randomly generated arrays of varying length for the learned non-recursive and recursive programs,1
 indentation indicates the stack is one level deeper than before,0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" for each length, we test each program on 30 randomly generated problems",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
 indentation indicates the stack is one level deeper than before,1
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",1
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
e,1
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",0
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
 we created a program set that reflects the semantics of algorithm 2,0
" in particular, recursion can be implemented as a program calling itself",0
"
as in line 13 of the right-hand side of figure 1",1
 the maximum problem length in this training set is 3 (e,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
6,0
 3: begin traversing from vertex 1 in the dag,1
" in this architecture, we consider a core controller, e",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 we found that changing the npi training traces is a simple way to enable this,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,1
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 this algorithm is a variant of depth first search,1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
g,0
g,1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",1
5,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
6,0
 ,0
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",0
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
" each time a subprogram is called, the stack depth increases",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
 ,1
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",1
 the logic for the non-recursive trace is shown in algorithm 4 in the appendix,0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 while (pstacklo 6= 1): 6 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 7 stack(stack_pop) 8 else: 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 stack(stack_pop) 12 partition() 13 stack(stack_push_call2) 14 stack(stack_push_call1) 15 } 16 17 partition() { 18 set_pivot_lo() 19 set_j_lo() 20 compswap_loop() 21 swap(ppivot, phi) 22 set_j_null() 23 } 24 25 compswap_loop() { 26 while (pj 6= phi): 27 compswap() 28 move(pj, up) 29 } 30 31 compswap() { 32 if (a[pj ] ≤ a[phi]): 33 swap(ppivot, pj) 34 move(ppivot, up) 35 } 36 37 stack(op) { 38 if (op == stack_push_call1): 39 write(env_stack_lo, plo) 40 write(env_stack_hi, ppivot − 1) 41 move(pstacklo, up) 42 move(pstackhi, up) 43 44 if (op == stack_push_call2): 45 write(env_stack_lo, ppivot + 1) 46 write(env_stack_hi, phi) 47 move(pstacklo, up) 48 move(pstackhi, up) 49 50 if (op == stack_pop): 51 write(env_stack_lo, reset) 52 write(env_stack_hi, reset) 53 move(pstacklo, down) 54 move(pstackhi, down) 55 }altered recursive functions 1 initialize plo to 1 and phi to n (length of array) 2 initialize pj to −∞ 3 4 quicksort() { 5 if (qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1)): 6 partition() 7 stack(stack_push_call2) 8 stack(stack_push_call1) 9 write(phi, env_stack_hi_peek) 0 write(plo, env_stack_lo_peek) 11 quicksort() // recursive call 12 stack(stack_pop) 13 write(phi, env_stack_hi_peek) 14 write(plo, env_stack_lo_peek) 15 quicksort() // recursive call 16 stack(stack_pop) 17 } 18 19 compswap_loop() { 20 if (pj 6= phi): 21 compswap() 22 move(pj, up) 23 compswap_loop() // recursive call 24 }in this section, we describe the space of base cases and reduction rules that must be covered for each of the four sample tasks, in order to create the verification set",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" , n , where the dag contains n vertices",0
 the training set for addition contains 200 traces,1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
" k is set to 11, to represent the range of 10 possible digits, along with a token representing the end of input",1
" this agrees with the generalization of non-recursive addition in reed & de freitas (2016), where they reported generalization up to 3000 digits",1
 ,1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
3,0
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",0
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" table 1 presents results on randomly generated arrays of varying length for the learned non-recursive, partially recursive, and full recursive programs",0
" the write operation has the following arguments:
arg 1 (main action): color curr, color next, active start, active neighb, active stack, save, stack push, stack pop, result
color curr colors vactive, color next colors vertex dag[vactive][childlist[vactive]], active start writes pstart to vactive, active neighb writes dag[vactive][childlist[vactive]] to vactive, active stack writes qstack(pstack) to vactive, save writes vactive to vsave, stack push pushes vactive to the top of the stack, stack pop writes a null value to the top of the stack, and result writes vactive to qresult(presult)",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
g,0
 the program terminates when seeing no numbers in the current column,1
"
base cases and reduction rules for addition",1
 ,1
" as with the others, we apply the procedure described in section 3",1
 ,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
we describe the details of the npi model relevant to our contributions",1
"
we refer the reader to the appendix for the non-recursive trace generating functions",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
", an array for quicksort or a dag for topological sort)",0
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,1
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" as this complexity interfered with determining the base cases and reductions, we changed the algorithm to its current form",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",1
"
topological sort",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
", to color a vertex) or variable (e",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",1
 u varies with the number of vertices in the graph,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
" the non-recursive and partially recursive versions are unable to sort long arrays, beyond length 8",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 the program terminates when seeing no numbers in the current column,0
 ,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
g,1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
arg 2 (object to copy): env stack lo peek, env stack hi peek, phi, plo, ppivot − 1, ppivot + 1, reset
env stack lo peek and env stack hi peek represent qstacklo(pstacklo − 1) and qstackhi(pstackhi − 1), respectively",0
" it is straightforward to deal with all other operations, which do not induce partial environment states",0
" as with the others, we apply the procedure described in section 3",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",0
"
the operations we need to be concerned most about are carry and lshift, which induce partial environment states spanning two columns",1
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
"
move",0
" there are 3 pointers (presult, pstack, pstart), presult points to the next empty location in qresult,
pstack points to the top of the stack in qstack, and pstart points to the candidate starting node for a connected component",0
" provably perfect generalization implies the model will behave correctly, given any valid input",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
 a1a0 + bnbn−1 ,0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 this paper is the first (to our knowledge) to investigate the important problem of provable generalization properties of neural programs,0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
 18: push lo and p− 1 to slo and shi,0
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
 the first is the actual model architecture,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
 we adapt machinery from the original paper slightly to fit our needs,1
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" however, our concept of recursion for neural programs is general",1
" twc-1409915, darpa under grant no",1
"
an alternative method is to run p on many different program inputs and then observe step input sequences which occur, to create v ",1
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
", the trace corresponding to the array [3,2])",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
"
given a verification set, we can then run the model on the verification set to check if the produced traces and results are correct",0
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
" the arrow in the theorem refers to evaluation, as in big-step semantics",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
training neural networks to synthesize robust programs from a small number of examples is a challenging task,1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
" in particular, recursion can be implemented as a program calling itself",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",0
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
 stack pop pushes −∞ values to qstacklo and qstackhi,1
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
 our experiments use a small number of training examples,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
"1; and for bubble sort, appendix a",0
" on the other hand, the recursive programs have learned the true program semantics",0
"
one common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
 b1b0 where no carry operations occur,1
"
as in line 13 of the right-hand side of figure 1",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
we now report on generalization for the varying tasks,1
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
grade school addition",0
" we call this set of inputs the verification set, sv ",0
3,0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
 recursion can be implemented differently for different neural programming models,1
"
base cases and reduction rules for addition",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
grade school addition",1
" m is considered to have perfect generalization if m can give the right answer for any input, such as inputs of arbitrary length",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
 the degree for any vertex in the dag is variable,1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" each time a subprogram is called, the stack depth increases",0
 we created a program set that reflects the semantics of algorithm 2,1
" the arrow in the theorem refers to evaluation, as in big-step semantics",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
 the environment and return probability are omitted for readability,0
", the trace corresponding to the array [3,2])",1
g,1
" partial recursion only adds a tail recursive call to bubblesort after bubble and reset, similar to the tail recursive call described previously for addition",1
" we note that an earlier version of quicksort we tried lacked primitive operations to directly move a pointer to another, and therefore needed more functions and observations",0
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
 the first is the actual model architecture,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",1
 we choose to implement a topological sort task for graphs,1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" fa8750-15-2-0104, and berkeley deep drive",0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" fa8750-15-2-0104, and berkeley deep drive",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",1
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
 ,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",1
" for each length, we test each program on 30 randomly generated problems",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
"
grade school addition",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,1
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 ,1
 there is a (changing) list of neural programs used to accomplish a given task,1
" without using a recursive program, such a proof is not possible, because the non-recursive program runs on an arbitrarily long addition problem that creates correspondingly long sequences of step inputs; in the non-recursive formulation of addition, add calls add1 a number of times that is dependent on the length of the input",0
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",1
 ,0
g,0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
 3: begin traversing from vertex 1 in the dag,1
" 2: initialize lo and hi to be 1 and n, where n is the length of a",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
 the maximum problem length in this training set is 3 (e,1
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
 npi then outputs the return probability and next program and arguments to execute,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
"1; and for bubble sort, appendix a",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
"
we describe the details of the npi model relevant to our contributions",0
as mentioned in section 2,0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
"
grade school addition",0
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,1
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
 the environment and return probability are omitted for readability,1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
 this algorithm is a variant of depth first search,0
" for each length, we test each program on 30 randomly generated problems",1
 the core controller acts as a dispatcher for the programs,1
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",1
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",0
" in all experiments, α is set to 0",0
 npi then outputs the return probability and next program and arguments to execute,0
 ,1
this material is in part based upon work supported by the national science foundation under grant no,1
 we outline how to construct this set,1
" if the step output specifies a primitive function call, we need to reason about how it can affect the environment so as to change the observation in the next step input",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" for each length, we test each program on 30 randomly generated problems",0
 ,0
we emphasize the overall goal of this work is to enable the learning of a recursive program,1
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
"
bubble sort",1
 this is the first time one can provide provable guarantees of perfect generalization for neural programs,0
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
" numerous models have been proposed for learning programs; to name a few, this includes the differentiable neural computer (graves  , 2016), neural turing machine (graves  , 2014), neural gpu (kaiser & sutskever, 2015), neural programmer (neelakantan  , 2015), pointer network (vinyals  , 2015), hierarchical attentive memory (andrychowicz & kurach, 2016), and neural random access machine (kurach  , 2016)",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",0
" on the other hand, the recursive programs have learned the true program semantics",1
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",0
g,1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
"
after finding v , we construct a set of problem inputs which, when executed on p , create exactly the step input sequences which make up v ",0
" if yes, then this indicates that the learned neural program achieves provably perfect generalization",1
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",0
 we use the lomuto partition scheme; the logic for the recursive trace is shown in algorithm 3,1
g,0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",0
", pstart or childlist[vactive]) up or down none described belowwrite",0
"
note that the training set can often be considerably smaller than the verification set, and despite this, the learned model can still pass the entire verification set",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
 we choose to implement a topological sort task for graphs,0
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
6,0
 we choose to implement a topological sort task for graphs,0
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 recursion can be implemented differently for different neural programming models,1
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" for each length, we test each program on 30 randomly generated problems",0
" using this modification, we constructed a verification set consisting of one array of size 10",0
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",1
", to color a vertex) or variable (e",0
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",1
" in particular, this condition is satisfied by npi, and thus the npi model naturally supports recursion (even though the authors of npi did not consider this aspect explicitly)",1
" hence, if all subproblems in s are added correctly, we have proven that any member of f will be added correctly, thus eliminating an infinite family of inputs that need to be tested",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" as described in the verification procedure, it is possible to prove our learned recursive program generalizes perfectly by testing on an appropriate set of problem inputs, i",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" using this modification, we constructed a verification set consisting of one array of size 10",0
" the verification set can be very small, as we found a 10-element array ([8,2,1,2,0,8,5,8,3,7]) is sufficient to cover all of v ",0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",1
 figure 2 shows examples of traces for the different versions of bubble sort,0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",0
" 4: function toposort(dag) 5: while there is still a white vertex u: do 6: color[u] = grey 7: vactive = u 8: do 9: if vactive has a white child v then 10: color[v] = grey 11: push vactive onto s 12: vactive = v 13: else 14: color[vactive] = black 15: write vactive to result 16: if s is empty then pass 17: else pop the top vertex off s and set it to vactive 18: while s is not empty
topological sort",0
" the stack operation has the following arguments:
arg 1 (operation): stack push call1, stack push call2, stack pop
stack push call1 pushes lo and pivot−1 toqstacklo andqstackhi",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
we experiment with two levels of recursion—partial and full",0
 u varies with the number of vertices in the graph,1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",0
", the verification set",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
e,0
" et+1 ∼ fenv(et, pt, at)",0
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,0
" the swap operation has the following arguments:
arg 1 (swap object 1): ppivot
arg 2 (swap object 2): phi, pj
write",1
", an lstm in npi’s case, but possibly other networks in different cases",0
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",1
" for each length, we test each program on 30 randomly generated problems",0
 npi then outputs the return probability and next program and arguments to execute,0
 figure 2 shows examples of traces for the different versions of bubble sort,0
"
grade school addition",0
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",0
" recursion is an important concept in programming languages and a critical tool to
reduce the complexity of programs",0
g,1
"
inside bubble and reset, there are two operations that can be made recursive",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
3,0
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
 ,0
g,0
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
 ,0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
 the environment and return probability are omitted for readability,1
" naı̈vely, we might expect to synthesize and test an input for any sequence created by combining the four possible colors in two variables and another boolean variable for whether the stack is empty (so 32 possible observations at any point), but for various reasons, most of these combinations are impossible to occur at any given point in the execution trace",0
" any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of national science foundation and darpa",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"we train using the adam optimizer and use a 2-layer lstm and task-specific state encoders for the external environments, as described in reed & de freitas (2016)",0
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",1
" fa8750-15-2-0104, and berkeley deep drive",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",0
" in future work, we seek to enable more tasks with recursive structure",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
 indentation indicates the stack is one level deeper than before,0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
e,0
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",1
"
training setup",1
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",1
"
the non-recursive trace loops on cycles of add1 and lshift",0
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
" if the program is primitive, the next environmental state et+1 will be affected by pt and at, i",1
" for many problems, the base cases and reduction rules usually consist of a finite (often small) number of cases",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",1
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,1
 we created a program set that reflects the semantics of algorithm 2,1
g,1
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,1
" the move operation has the following arguments:
arg 1 (pointer): presult, pstack, pstart, childlist[vactive], childlist[vsave]
note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 5 values",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
g,1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",1
" lshift moves the four pointers to the left, to move to the next column",0
5,1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
"
inside bubble and reset, there are two operations that can be made recursive",1
 we describe the recursive re-formulation of traces for two tasks from the original npi paper—grade-school addition and bubble sort,0
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",0
"
we experiment with two levels of recursion—partial and full",0
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
"
we experiment with two levels of recursion—partial and full",1
" on the other hand, the non-recursive version has low accuracy, beginning from size 5, and fails completely for graphs of size 8 and beyond",1
"
grade school addition",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",1
" for example, a step input-step output pair in lines 2 and 3 of the left-hand side of figure 1 is (add1, write out 1)",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",0
" fa8750-15-2-0104, and berkeley deep drive",0
we now report on generalization for the varying tasks,0
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",1
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
" for tasks other than addition, it is difficult to analytically determine the verification set, so instead, we randomly generate input candidates until they completely cover the base cases and reduction rules",0
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
" empirically, we observe that the learned recursive programs solve all valid inputs with 100% accuracy after training on a very small number of examples, out-performing previous generalization results",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
 the degree for any vertex in the dag is variable,1
 ,0
g,1
" the pointers at index i1 and i2 are used to compare the pair of numbers considered during the bubble sweep, swapping them if the number at i1 is greater than that in i2",0
" in this version, there is a dependence on length: bstep and lshift are called a number of times equivalent to one less than the length of the input array, in bubble and reset respectively",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
e,1
"
the npi accesses an external environment, q, which varies according to the task",1
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
 the program terminates when seeing no numbers in the current column,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
" at end, pointer ppivot is moved to the pivot compswap loop, move pivot lo, move j lo, swap
none
compswap loop runs the for loop inside the partition function compswap, move none compswap compares a[pivot] ≤ a[j]; if so, perform a swap and increment ppivot swap, move none set pivot lo sets ppivot to lo index none none set j lo sets pj to lo index none none set j null sets pj to −∞ none none stack pushes lo/hi states
onto stacks slo and shi according to argument (described below)
write, move described below
move moves pointer one unit up or down none described below swap swaps elements at given array indices none described below write write a value either to stack (e",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
"1; and for bubble sort, appendix a",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",0
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",1
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",0
" the only model, to our knowledge, that does not train on input-output pairs is the neural programmer-interpreter (reed & de freitas, 2016), which trains on synthetic execution traces",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",1
"
base cases and reduction rules for addition",0
"
by nature, recursion reduces the complexity of a problem to simpler instances",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
", qstacklo or qstackhi) or to pointer (e",1
we emphasize the overall goal of this work is to enable the learning of a recursive program,0
g,1
" the general notion of recursion has been an important concept in many domains, including mathematics and computer science",1
 reset represents a −∞ value,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",0
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
"
topological sort",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" however, our concept of recursion for neural programs is general",1
" to the best of our knowledge, this is the first time verification has been applied to a neural program, providing provable guarantees about its behavior",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
" more specifically, when m is trained on simpler inputs, such as inputs of a small length, the generalization metric evaluates how well m will do on more complex inputs, such as inputs of much longer length",0
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",0
"
algorithm 2 shows the topological sort task of interest",1
" in contrast, each call to the recursive add always runs for a fixed number of steps, even on arbitrarily long problems in f , so we can test that it performs correctly on a small, fixed number of step input sequences",1
 we choose to implement a topological sort task for graphs,0
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",0
" on the other hand, the recursive programs have learned the true program semantics",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
" this makes it so that we only need to consider the vertices in the subgraph that are currently relevant for computing the sort, allowing simpler reasoning about behavior for large graphs",1
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",0
 the memory updates of these neural programs are so complex and interdependent that it is difficult to reason about the behaviors of the learned neural program under previously unseen situations (such as problems with longer inputs),1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",1
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
e,1
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
 18: push lo and p− 1 to slo and shi,0
"
an alternative way of representing the environment slice is to expose the values of the absolute vertices to the model; however, this makes it difficult to scale the model to larger graphs, since large vertex values are not seen during training time",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",1
"program descriptions calls arguments toposort perform topological
sort on graph traverse, next start, write, move
none
traverse traverse graph until stack is empty check child, explore none check child check if a white child exists; if so, set childlist[vactive] to point to it move none explore repeatedly traverse subgraphs until stack is empty stack, check child, write, move none stack interact with stack, either pushing or popping write, move push, pop next start move pstart until reaching a white vertex",1
" in this section, we give a brief review of the npi architecture from reed & de freitas (2016) as background",0
"
in this paper, we propose to resolve these issues by explicitly incorporating recursion into neural architectures",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",1
 this verification phase only needs to be performed once after training,1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
"
the non-recursive trace loops on cycles of add1 and lshift",1
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" for these models, table 2 presents results on randomly generated dags of varying graph sizes (varying in the number of vertices)",0
"
the training data for the neural programmer-interpreter consists of full execution traces for the program of interest",1
"as discussed in section 2, the neural programmer-interpreter (npi) is an instance of a neural programmer architecture and hence it naturally supports recursion",0
" we call this set of inputs the verification set, sv ",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
 we find that recursion makes it easier for the network to learn the right program and generalize to unknown situations,0
we now report on generalization for the varying tasks,1
"
in what follows, we describe the way in which we constructed npi training traces so as to make them contain recursive elements and thus enable npi to learn recursive programs",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
" however, our concept of recursion for neural programs is general",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",0
" the core module of the npi is an lstm controller that takes as input a slice of the current external environment, via a set of pointers, and a program and arguments to execute",1
5,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",0
 ,0
"
we propose and describe our verification procedure",0
as mentioned in section 2,0
" however, models that make use of this strategy eventually fail after a certain level of complexity (e",0
"as there is no public implementation of npi, we implemented a version of it in keras that is as faithful to the paper as possible",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",1
" thus, any general neural programming architecture supporting such a call structure can be made to support recursion",0
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
" this is possible if and only if the graph has no directed cycles; that is to say, it must be a directed acyclic graph (dag)",0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" for each graph size, we test the learned programs on 30 randomly generated dags",1
 there is a (changing) list of neural programs used to accomplish a given task,1
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",0
 the core controller acts as a dispatcher for the programs,0
", an lstm in npi’s case, but possibly other networks in different cases",1
" if a white vertex is found, set pstart to point to it; this signifies the start of a traversal of a new connected component",1
 3: begin traversing from vertex 1 in the dag,0
" full recursion, in addition to making the aforementioned tail recursive call, adds two additional recursive calls; bstep and lshift are made tail recursive",0
 indentation indicates the stack is one level deeper than before,0
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
"
the training set for topological sort contains 6 traces, with one synthesized from a graph of size 5 and the rest synthesized from graphs of size 7",1
g,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" as an application, we incorporate recursion into the neural programmer-interpreter architecture and consider four sample tasks: grade-school addition, bubble sort, topological sort, and quicksort",0
 the environment and return probability are omitted for readability,1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
3,0
 ,0
 2: initialize an empty stack s and a directed acyclic graph dag to traverse,0
", qstacklo or qstackhi) or to pointer (e",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" for bubble sort, the domain-specific encoder is
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1), q(1, i2), i3 == length, at(1), at(2), at(3)]),
where the environment q ∈ r1×n×k is a scratch-pad that contains 1 row, to represent the state of the array as sorting proceeds in-place, andn columns",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",0
" , n , where the dag contains n vertices",0
 almost all architectures train on program input/output pairs,1
 there are 2 variables (vactive and vsave); vactive holds the active vertex (as in algorithm 2) and vsave holds the value of vactive before executing line 12 of algorithm 2,1
" however, to be sure that the generated v is complete (covers all the cases needed), we need to check all pairs of observations seen in adjacent step inputs (in particular, those before and after a primitive function call), in a similar way as if we were constructing v from scratch",1
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
this material is in part based upon work supported by the national science foundation under grant no,1
 reset represents a −∞ value,0
" for brevity, we refer the reader to the appendix for information about the program set and non-recursive and recursive trace-generating functions for quicksort",0
", to change the value of phi) none described belowstack",0
" empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity",1
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"program descriptions calls arguments quicksort run the quicksort
routine in place for the array a, for indices from lo to hi non-recursive: partition, stack, write recursive: same as non-recursive version, along with quicksort implicitly: array a to sort, lo, hi
partition runs the partition function",0
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
", an array for quicksort or a dag for topological sort)",0
" fa8750-15-2-0104, and berkeley deep drive",1
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"
it is sufficient to construct problems where every transition between two adjacent columns is covered",0
" however, the authors of npi did not consider explicitly the notion of recursion and as a consequence, did not learn recursive programs",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
g,1
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",0
" , a1a0 + b1b0} are added properly",1
g,1
 we instantiated recursion for the neural programmerinterpreter by changing the training traces,0
" formally, the npi is represented by the following set of equations:
st = fenc(et, at)
ht = flstm(st, pt, ht−1)
rt = fend(ht), pt+1 = fprog(ht), at+1 = farg(ht)
t is a subscript denoting the time-step; fenc is a domain-specific encoder (to be described later) that takes in the environment slice et and arguments at; flstm represents the core module, which takes in the state st generated by fenc, a program embedding pt ∈ rp , and hidden lstm state ht; fend decodes the return probability rt; fprog decodes a program key embedding pt+1;1 and farg decodes arguments at+1",1
"
is critical for implementing recursion, since it permits us to restrict our attention to the currently relevant recursive call, ignoring irrelevant details about other contexts",0
 some functional programming languages go so far as not to define any looping constructs but rely solely on recursion to enable repeated execution of the same code,1
 ,0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,1
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
"we describe how models trained with recursive traces can be proven to generalize, by using the verification procedure described in section 3",1
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",1
" a single element of an execution trace consists of a step input-step output pair, which can be synthesized from algorithm 1: this corresponds to, for a given time-step, the step input tuple (e, p, a) and step output tuple (r, p2, a2)",0
" 9: else 10: function run(e, p2, a2)
a description of the inference procedure is given in algorithm 1",0
" for each task, given the verification set, we check the traces and results of the learned, to-be-verified neural program (described in section 4",1
 ,0
" each time a subprogram is called, the stack depth increases",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",0
"
we describe the details of the npi model relevant to our contributions",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
", an array for quicksort or a dag for topological sort)",1
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",1
" qcolor(pstart) contains the color of the current start vertex, used in the evaluation of the condition in the while loop in line 5 of algorithm 2",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
"
arg 2 (auxiliary variable): color grey, color black
color grey and color black color the given vertex grey and black, respectively",1
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 recursion can be implemented differently for different neural programming models,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",1
 18: push lo and p− 1 to slo and shi,0
 ,1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",1
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",1
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
"
as in line 13 of the right-hand side of figure 1",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
" qcolor(dag[vactive][childlist[vactive]]) refers to the color of the next child of vactive, used in the evaluation of the condition in the if branch in line 9 of algorithm 2",0
g,1
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
 we then construct a verification set of size 73 by ensuring that randomly generated graphs cover the analytically derived v ,1
g,1
" on the other hand, the recursive programs have learned the true program semantics",0
 almost all architectures train on program input/output pairs,1
 errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state,0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
"
as in line 13 of the right-hand side of figure 1",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",0
" in the non-recursive trace, there are four functions that can be made recursive—toposort, check child, explore, and next start, and we add a tail recursive call to each of these functions in order to make the recursive trace",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
", qstacklo or qstackhi) or to pointer (e",0
 we leave this as future work to devise a verification procedure more appropriate to this setting,0
" both the non-recursive and recursive learned programs generalize on all input lengths we tried, up to 5000 digits",1
g,1
" a topological sort is a linear ordering of vertices such that for every directed edge (u, v) from u to v, u comes before v in the ordering",0
 our experiments use a small number of training examples,0
"
the non-recursive trace loops on cycles of bubble and reset, which logically represents one bubble sweep through the array and reset of the two bubble pointers to the very beginning of the array, respectively",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",1
 stack push call2 pushes pivot + 1 and hi to qstacklo and qstackhi,0
" finally, the boolean pstack == 1 is used to check whether the stack is empty in line 18 of algorithm 2",0
"
we describe the base cases, reduction rules, and the verification set for each task in appendix a",0
 this verification phase only needs to be performed once after training,1
"
it is important to emphasize that at inference time in the npi, the hidden state of the lstm controller is reset (to zero) at each subprogram call, as in line 3 of algorithm 1 (h ← 0)",0
" on the other hand, the recursive programs have learned the true program semantics",1
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"
we experiment with two levels of recursion—partial and full",0
3 to construct v and then empirically create a verification set which covers v ,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
 we created a program set that reflects the semantics of algorithm 2,0
 the original version of the bubblesort implementation exposes the values within the array,0
" the theorem states that for the same sequence of step inputs, the model produces the exact same step output as the target program it aims to learn",0
" for brevity, we refer the reader to the appendix for further details on the program set and non-recursive and recursive trace-generating functions used for topological sort",1
"
as in line 13 of the right-hand side of figure 1",1
"
in this general neural programming architecture, we show it is easy to support recursion",1
 recursion enables provably perfect generalization,0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
g,1
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",1
"
as a concrete instantiation, we show in this paper that we can enable recursive neural programs in the npi model, and thus enable perfectly generalizable neural programs for tasks such as sorting where the original, non-recursive npi program fails",0
" we make the trace recursive by adding a tail recursive call into the trace for the add program after calling add1 and lshift, the original paper uses k = 10, but we found it necessary to augment the range with an end token, in order to terminate properly",0
" for the recursive formulation of addition, we analytically construct the set of input problems that cover all base cases and reduction rules",1
 ,1
"
base cases and reduction rules for bubble sort",0
" the outputs rt, pt+1, at+1 are used to determine the next action, as described in algorithm 1",0
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
"1, we hypothesize the non-recursive programs do not generalize well because they have learned spurious dependencies specific to the training set, such as length of the input problems",0
"1; and for bubble sort, appendix a",1
"
directed acyclic graphs are structurally more diverse than inputs in the two tasks of grade-school addition and bubble sort",1
g,0
"
for addition, we analytically determine the verification set",1
"
as mentioned in section 1, all approaches to neural programming today fare poorly on this generalization issue",1
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,1
"
algorithm 3 recursive quicksort 1: initialize an array a to sort",0
" 2: initialize lo and hi to be 1 and n, where n is the length of a",1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",1
"
we propose and describe our verification procedure",0
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
"
we construct input problems by splitting into two cases: one case in which the left column contains a null value and another in which the left column does not contain any null values",0
g,0
" 3: 4: function quicksort(a, lo, hi) 5: if lo < hi: then 6: p = partition(a, lo, hi) 7: quicksort(a, lo, p− 1) 8: quicksort(a, p+ 1, hi) 9: 10: function partition(a, lo, hi) 11: pivot = lo 12: for j ∈ [lo, hi− 1] : do 13: if a[j] ≤ a[hi] then 14: swap a[pivot] with a[j] 15: pivot = pivot+ 1 16: swap a[pivot] with a[hi] 17: return pivot
for quicksort, the domain-specific encoder is
fenc(qarray, qstacklo, qstackhi, plo, phi, pstacklo, pstackhi, ppivot, pj , at) =
mlp ([qarray(pj) ≤ qarray(phi), pj == phi, qstacklo(pstacklo − 1) < qstackhi(pstackhi − 1), pstacklo == 1, at(1), at(2), at(3)]),
whereqarray ∈ ru×11 is a scratch-pad that contains u rows, each containing one of 11 values (one of the numbers 0 through 9 or an invalid state)",0
" both the non-recursive and recursive learned programs generalize on all graphs we tried, up to 120 vertices",0
g,1
" the core lstm module’s hidden state is preserved over all these add1 calls, and it is difficult to interpret with certainty what happens over longer timesteps without concretely evaluating the lstm with an input of that length",1
" fa8750-15-2-0104, and berkeley deep drive",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
" lshift moves the four pointers to the left, to move to the next column",1
"
base cases and reduction rules for quicksort",0
" the write operation has the following arguments:
arg 1 (object to write): env stack lo, env stack hi, phi, plo
env stack lo and env stack hi represent qstacklo(pstacklo) and qstackhi(pstackhi), respectively",1
" for non-primitive subprograms, we can update the observation-to-observation mapping currently associated with the subprogram and then apply that mapping to the current set",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",1
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" furthermore, given a verification input set that covers all base cases and reduction rules, we can formally prove that the learned neural programs achieve perfect generalization after verifying its behavior on the verification input set",0
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
in this paper, we propose that recursion is an important concept for neural programs as well",1
"
arg 2 (increment or decrement): up, down
swap",1
" the space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",1
training neural networks to synthesize robust programs from a small number of examples is a challenging task,0
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",0
 the environment and return probability are omitted for readability,1
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",0
"
base cases and reduction rules for bubble sort",1
" for each length, we test each program on 30 randomly generated problems",0
"
to evaluate a neural network that learns a neural program to accomplish a certain task, one common evaluation metric is how well the learned model m generalizes",0
 the degree for any vertex in the dag is variable,0
", the verification set",0
" formally, a function exhibits recursive behavior when it possesses two properties: (1) base cases— terminating scenarios that do not use recursion to produce answers; (2) a set of rules that reduces all other problems toward the base cases",1
 the core controller acts as a dispatcher for the programs,0
"
bubble sort",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" because the context of the caller is stored on a stack when it calls another program and the callee starts in a fresh context, this enables recursion simply by allowing a program to call itself",1
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" lshift, used in reset, shifts the pointers left until reaching the start token",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
" thus, recursion helps decompose a problem and makes it easier to reason about a program’s behavior for previously unseen situations such as longer inputs",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",0
" this is highly undesirable, since being able to provide the correct answer in all possible settings is one of the most important aspects of any learned neural program",1
 b1b0 where no carry operations occur,0
 u varies with the number of vertices in the graph,0
" as with the original npi architecture, the experiments for this paper always used a 3-tuple of integers at = (at(1), at(2), at(3))",0
" in particular, given that a recursion is defined by two properties as mentioned before, the base cases and the set of reduction rules, we can prove a recursive neural program generalizes perfectly if we can prove that (1) it performs correctly on the base cases; (2) it learns the reduction rules correctly",1
"
algorithm 1 neural programming inference 1: inputs: environment observation e, program p, arguments a, stop threshold α 2: function run(e, p, a) 3: h← 0, r ← 0 4: while r < α do 5: s← fenc(e, a), h← flstm(s, p, h) 6: r ← fend(h), p2 ← fprog(h), a2 ← farg(h) 7: if p is a primitive function then 8: e← fenv(e, p, a)",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",1
"
the npi accesses an external environment, q, which varies according to the task",0
"
the same set of problems was used to generate the training traces for all formulations of the task, for non-recursive and recursive versions",0
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
"
note that v should also contain the necessary reductions, which corresponds to making the recursive calls at the correct time, as indicated by p ",1
" in this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change",1
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",0
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
 table 4 demonstrates that the accuracy of the non-recursive program degrades sharply when moving from arrays of length 7 to arrays of length 8,0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
" childlist ∈ nu is a vector of pointers, where childlist[i] points to the next child under consideration for vertex i",1
" in future work, we seek to enable more tasks with recursive structure",1
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",1
 we choose to implement a topological sort task for graphs,0
" that is to say, the network does not learn the true program semantics",1
 the maximum problem length in this training set is 3 (e,1
" the recursive version of topological sort solves all graph instances we tried, from graphs of size 5 through 70",1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
 add1 is a subprogram that adds the current column (writing the appropriate digit to the output row and carrying a bit to the next column if needed),1
"
we note that for tasks with very large input domains, such as ones involving mnist digits or speech samples, the state space of base cases and reduction rules could be prohibitively large, possibly infinite",0
"
formally, verification consists of proving the following theorem:
∀i ∈ v,m(i) ⇓ p (i) where i denotes a sequence of step inputs (within one function call), v denotes the set of valid sequences of step inputs, m denotes the neural network model, p denotes the correct program, and p (i) denotes the next step output from the correct program",1
 this verification phase only needs to be performed once after training,0
"
move",1
", an array for quicksort or a dag for topological sort)",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
" we performed experiments on the partially recursive version in order to examine what happens when only one recursive call is implemented, when in reality three are required for perfect generalization",0
 we found that changing the npi training traces is a simple way to enable this,0
"
to perform the verification as described here, it is critical to construct v correctly",1
 ,1
" to make an analogy to mdps, this procedure is analogous to how value iteration obtains the correct value for each state starting from any initialization",0
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",0
 the first is the actual model architecture,1
g,0
2,0
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",1
" lshift moves the four pointers to the left, to move to the next column",0
"
we also report on generalization results for the non-recursive and recursive versions of this variant of bubble sort",1
" we have three observations: the color of the start node, the color of the active node’s next child to be considered, and whether the stack is empty",1
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",0
"2 at any given time, the npi has access to values pointed to by four pointers in each of the four rows, represented by q(1, i1), q(2, i2), q(3, i3), and q(4, i4)",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
3,0
" k is set to 11, to denote the range of possible numbers (0 through 9), along with the start/end token (represented with the same encoding) which is observed when a pointer reaches beyond the bounds of the input",0
g,0
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
" the architecture usually possesses some form of memory, which could be internal (such as the hidden state of a recurrent neural network) or external (such as a discrete “scratch pad” or a memory block with differentiable access)",0
" the add reduction rule ensures that each call to add only covers two adjacent columns, and so the lstm only ever runs for a fixed number of steps necessary to process these two columns",0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
 almost all architectures train on program input/output pairs,0
" as a consequence, our learned neural programs empirically achieve perfect generalization from a very small number of training examples",1
 table 4 also demonstrates that the (verified) recursive program generalizes perfectly,1
5,1
"1; and for bubble sort, appendix a",1
"
algorithm 2 shows the topological sort task of interest",0
" recall that this verification procedure cannot be performed for the non-recursive versions, since the propagation of the hidden state in the core lstm module makes reasoning difficult and so we would need to check an unbounded number of examples",0
"
the dag is represented as an adjacency list where dag[i][j] refers to the j-th child of vertex i",0
" m , as described in algorithm 1, processes the sequence of step inputs by using an lstm",1
"we show that if we incorporate recursion, the learned npi programs can achieve provably perfect generalization for different tasks",0
" the second is the training procedure, which consists of the form of the training data and the optimization process",0
"
algorithm 2 depth first search topological sort 1: color all vertices white",0
" the single-digit multiplication task in zaremba   (2016), the bubble sort task in reed & de freitas (2016), and the graph tasks in graves   (2016))",1
" the pointer at index i3 represents a counter internal to the environment that is incremented once after each pass of the algorithm (one cycle of bubble and reset); when incremented a number of times equal to the length of the array, the flag i3 == length becomes true and terminates the entire algorithm ",0
" here as a concrete and general example, we consider a general neural programming architecture (npa), similar to neural programmer-interpreter (npi) in reed & de freitas (2016)",0
 18: push lo and p− 1 to slo and shi,0
e,1
 stack pop pushes −∞ values to qstacklo and qstackhi,1
 we found that changing the npi training traces is a simple way to enable this,1
" this functionality the original npi paper decodes to a program key embedding kt ∈ rk and then computes a program embedding pt+1, which we also did in our implementation, but we omit this for brevity",0
" in computer science, recursion (as opposed to iteration) involves solving a larger problem by combining solutions to smaller instances of the same problem",0
" consequently, it is infeasible to construct a verification set that covers all cases, and the verification procedure we have described is inadequate",1
"
to perform the verification as described here, it is critical to construct v correctly",1
" bstep, used in bubble, compares pairs of numbers, continuously moving the bubble pointers once to the right each time until reaching the end of the array",0
" in practice, we can additionally use tail recursion optimization to avoid problems with the call stack growing too deep",0
" however, note that there is no provable guarantee that the non-recursive learned program will generalize to all inputs, whereas we show later that the recursive learned program has a provable guarantee of perfect generalization",0
"
in this general neural programming architecture, we show it is easy to support recursion",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",1
 the original version of the bubblesort implementation exposes the values within the array,1
" the learned recursive program is different from neural programs learned in all previous work in an important aspect: previous approaches do not explicitly incorporate this abstraction, and hence generalize poorly, whereas our learned neural programs incorporate recursion and achieve perfect generalization",0
" for problems where the base cases may be extremely large or infinite, such as certain forms of motor control, recursion can still help reduce the problem of generalization to these two aspects and make the generalization problem significantly simpler to handle and reason about",1
"
since npi naturally supports the notion of recursion, a key question is how to enable npi to learn recursive programs",1
"
bubble sort",0
"
in addition, none of the current approaches to neural programming provide a method or even aim to enable provable guarantees about generalization",1
"
by reasoning about the possible set of environment observations created by all valid inputs, we construct v using the procedure described in section 3",0
 indentation indicates the stack is one level deeper than before,1
 we choose to implement a topological sort task for graphs,0
" for purposes of verification, we replace the domain-specific encoder with the following:
fenc(q, i1, i2, i3, at) =mlp ([q(1, i1) ≤ q(1, i2), 1 ≤ i1 ≤ length, 1 ≤ i2 ≤ length, i3 == length, at(1), at(2), at(3)]),which directly exposes which of the two values pointed to is larger",1
 reset represents a −∞ value,1
" on the other hand, the recursive programs have learned the true program semantics",1
" finally, we implement recursive traces for our own topological sort and quicksort tasks",1
 we choose to implement a topological sort task for graphs,1
"
move",0
" we also hope to decrease supervision, for example by training with only partial or non-recursive traces, and to develop novel neural programming architectures integrated directly with a notion of recursion",1
" the 4 environment observations aid with control flow; qstacklo(pstacklo− 1) < qstackhi(pstackhi− 1) implements the lo < hi comparison in line 5 of algorithm 3, pstacklo == 1 checks if the stacks are empty in line 18 of algorithm 4, and the other observations (all involving ppivot or pj) deal with logic in the partition function",0
"
base cases and reduction rules for quicksort",0
" consequently, there is no concept of length relevant to the problem, which has traditionally been an important focus of length-based curriculum learning",0
" at each time step, the core controller can decide to select one of the programs to call with certain arguments",0
 a1a0 + bnbn−1 ,0
", an lstm in npi’s case, but possibly other networks in different cases",0
 our result shows that the training procedure and the npi architecture is capable of generalizing from the step input-output pairs seen in the training data to the unseen ones present in the verification set,0
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" observe that partially recursive does slightly better than non-recursive for the setting in which the length of the array is 3, and that the fully recursive version is able to sort every array given to it",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",1
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",1
"
in this general neural programming architecture, we show it is easy to support recursion",0
", the trace corresponding to the problem “109 + 101”)",0
" for instance, for recursive addition, consider the family f of addition problems anan−1 ",0
" thus, we demonstrate that recursion enables provably perfect generalization for different tasks, including addition, topological sort, quicksort, and a variant of bubble sort",0
 stack pop pushes −∞ values to qstacklo and qstackhi,0
"
figure 1 shows examples of non-recursive and recursive addition traces",1
" in this architecture, we consider a core controller, e",1
we emphasize that the notion of a neural recursive program has not been presented in the literature before: this is our main contribution,0
"
move",1
"
base cases and reduction rules for bubble sort",1
 figure 2 shows examples of traces for the different versions of bubble sort,1
" in order to claim a proof, we must verify the model produces correct behavior over all base cases and reductions, as described in section 2",1
" in future work, we would like to decrease supervision and construct models that are capable of coming up with recursive abstractions themselves",1
"
recursion drastically reduces the number of configurations we need to consider during the verification phase and makes the proof tractable, because it introduces structure that eliminates infinitely long sequences of step inputs that would otherwise need to be considered",1
 we adapt machinery from the original paper slightly to fit our needs,1
", to change the value of vactive) none described below move move a pointer (e",0
" the partial recursion is not enough for perfect generalization, as will be presented later in section 4",0
"
we describe the details of the npi model relevant to our contributions",0
"
under the assumption that there are no leading 0’s (except in the case of single digits) and the two numbers to be added have the same number of digits, the verification set for addition contains 20,181 input problems",1
"
the training set for bubble sort contains 100 traces, with maximum problem length of 2 (e",0
"
the training set for quicksort contains 4 traces, synthesized from arrays of length 5",0
" on the other hand, the recursive programs have learned the true program semantics",0
" note that the argument is the identity of the pointer, not what the pointer points to; in other words, arg 1 can only take one of 4 values, and arg 2 can only take one of 7 values",0
 we adapt machinery from the original paper slightly to fit our needs,0
as mentioned in section 2,0
" in future work, we seek to enable more tasks with recursive structure",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",1
" twc-1409915, darpa under grant no",1
 ,1
 this modification also enables us to sort arrays containing arbitrary comparable elements,0
" in all experiments, α is set to 0",0
" even though the earlier version also generalized just as well in practice, relatively small differences in the formulation of the traces and the environment observations can drastically change the difficulty of verification",1
" our implementation uses two stacks qstacklo and
qstackhi, each in ru , that store the arguments to the recursive quicksort calls in algorithm 3; before each recursive call, the appropriate arguments are popped off the stack and written to plo and phi",1
e,0
" when the program is called, the current context including the caller’s memory state is stored on a stack; when the program returns, the stored context is popped off the stack to resume execution in the previous caller’s context",1
" also the dag can have potentially more than one connected component, meaning it is necessary to transition between these components appropriately",1
g,0
 the model described in the training setup of section 4 (trained on 6 traces) was verified to be correct via the matching procedure described in section 4,0
"
quicksort",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",0
" if it is too large, then the semantics of p might not be well-defined on some elements in v , or the spurious step input sequences may not be reachable from any valid problem input (e",1
" this guarantees that the step input sequences considered during verification contain all step input sequences which arise during execution of an unseen problem in f , leading to generalization to any problem in f ",0
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" 3: 4: function partition(a, lo, hi) 5: pivot = lo 6: for j ∈ [lo, hi− 1] : do 7: if a[j] ≤ a[hi] then 8: swap a[pivot] with a[j] 9: pivot = pivot+ 1 0: swap a[pivot] with a[hi] 11: return pivot 12: 13: function quicksort(a, lo, hi) 14: while slo and shi are not empty: do 15: pop states off slo and shi, writing them to lo and hi",0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",0
5,0
"
bubble sort",1
 our experiments use a small number of training examples,0
" we implement a quicksort task, in order to demonstrate that recursion helps with learning divide-and-conquer algorithms",1
" via the recursive call, we effectively forget that the column just added exists, since the recursive call to add starts with a new hidden state for the lstm controller",0
"
we propose and describe our verification procedure",0
"
in order to demonstrate that recursion can help learn and generalize better, we trained a non-recursive and recursive model on just a single execution trace generated from a graph containing 5 nodes3 for the topological sort task",0
"
base cases and reduction rules for quicksort",1
 this is due to the properties of the training set – we trained on 2 traces synthesized from arrays of length 7 and 1 trace synthesized from an array of length 6,1
" at any given time, the npi has access to the values referred to by two pointers, represented by q(1, i1) and q(1, i2),",1
" while this matches the description from reed & de freitas (2016), we found that this causes an unnecessary blowup in the size of v and makes it much more difficult to construct the verification set",1
" we prove every member of f is added properly, given that subproblems s = {anan−1 + bnbn−1, an−1an−2 + bn−1bn−2, ",1
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",1
"
to construct this set, by using the reference implementation of each subprogram, we construct a mapping between two sets of environment observations: the first set consists of all observations that can occur at the beginning of a particular subprogram’s invocation, and the second set contains the observations at the end of that subprogram",0
"
the npi accesses an external environment, q, which varies according to the task",1
" the recursive version can generalize perfectly to long problems constructed from these components (such as the sum “822+233”, where “8+2” and “2+3” are in the training set), but the non-recursive version fails to sum these long problems properly",0
"
for topological sort, the domain-specific encoder is
fenc(dag,qcolor, pstack, pstart, vactive, childlist, at)
=mlp ([qcolor(pstart), qcolor(dag[vactive][childlist[vactive]]), pstack == 1, at(1), at(2), at(3)]),
where qcolor ∈ ru×4 is a scratch-pad that contains u rows, each containing one of four colors (white, gray, black, invalid) with one-hot encoding",1
" in particular, in the explore function, adding a tail recursive call resets and stores the hidden states associated with vertices in a stack-like fashion",1
g,1
" the corresponding edge list is [(1, 2), (1, 5), (2, 4), (2, 5), (3, 5)]",1
" nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them",0
"
grade-school addition",0
" if no white vertex is found, the entire execution is terminated move none write write a value either to environment (e",0
" 16: p = partition(a, lo, hi) 17: push p+ 1 and hi to slo and shi",1
" by iterating with this procedure, and then running p on the input observation set that we obtain for the entry point function, we can obtain v precisely",0
" the contents ofqresult andqstack are not exposed directly through the domain-specific encoder; rather, we define primitive functions which manipulate these scratch-pads",1
" plo and phi point to the lo and hi indices of the array, as in algorithm 3",0
"in this paper, we propose that the key abstraction of recursion is necessary for neural programs to generalize",0
 the sequence of primitive operations (move and write operations) for the non-recursive and recursive versions are exactly the same,0
 ,1
" in particular, we construct new training traces which explicitly contain recursive elements and show that with this type of trace, npi easily learns recursive programs",1
", an array for quicksort or a dag for topological sort)",0
" the assumption of leading 0’s can be easily removed, at the cost of slightly increasing the size of the verification set",0
" finally, we implement recursive traces for our own topological sort and quicksort tasks",0
" we made the assumption of equivalent lengths in order to parametrize the input format with respect to length, but this assumption can be removed as well",0
"
base cases and reduction rules for quicksort",0
we now report on generalization for the varying tasks,0
"
through careful reasoning about the possible set of environment observations created by all valid inputs, and how each of the operations in the execution trace affects the environment, we can construct v using the procedure described in section 3",1
"when constructing a neural network for the purpose of learning a program, there are two orthogonal aspects to consider",0
" the npi model has three learnable components: a task-agnostic core, a program-key embedding, and domain-specific encoders that allow the npi to operate in diverse environments",1
" an example of part of an addition task trace, written in shorthand, is given in figure 1",1
3,0
" if it is too small, then execution of the program on some input might require evaluation of m(i) on some i /∈ v , and so the behavior ofm(i) might deviate from p (i)",0
 u varies with the number of vertices in the graph,0
" for grade-school addition, the domain-specific encoder is
fenc(q, i1, i2, i3, i4, at) =mlp ([q(1, i1), q(2, i2), q(3, i3), q(4, i4), at(1), at(2), at(3)]),
where the environment q ∈ r4×n×k is a scratch-pad that contains four rows (the first input number, the second input number, the carry bits, and the output) and n columns",0
" although the model is exposed to more and more data, it might learn spurious and overly complex representations of the program, as suggested in zaremba   (2016)",1
" we hypothesize that the reason for this is that the neural network learns to spuriously depend on specific characteristics of the training examples that are irrelevant to the true program semantics, such as length of the training inputs, and thus fails to generalize to more complex inputs",1
 pstacklo and pstackhi point to the top (empty) positions in qstacklo and qstackhi,0
" we then construct problem configurations that span all possible valid environment states (for instance, in order to force the carry bit in a column to be 1, one can add the sum “1+9” in the column to the right)",0
" given verification sets that cover all the base cases and reduction rules, we can provide proofs that these learned programs generalize perfectly",1
" in fact, it is one of our future directions to explore new ways to train a recursive neural program without providing explicit training execution traces or with only partial or non-recursive traces",0
"
thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (vinyals   (2015), kaiser & sutskever (2015), reed & de freitas (2016), graves   (2016), zaremba   (2016))",1
"
base cases and reduction rules for quicksort",0
"
we would also like to point out that in this paper, we provide as an example one way to train a recursive neural program, by providing a certain training execution trace to the npi model",1
" our results show that for all learned, to-be-verified neural programs, they all produced the same traces as those produced by p on the verification set",1
"
base cases and reduction rules for quicksort",0
